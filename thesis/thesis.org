#+TITLE: Achieving Portable, Responsive and Robust Real-Time Collaborative Editing
#+AUTHOR: Lars Tveito
#+EMAIL: larstvei@ifi.uio.no
#+DATE: August 2016
#+OPTIONS: num:3 H:5 todo:nil title:nil toc:nil ':t
#+LaTeX_CLASS_OPTIONS: [USenglish, hidelinks]
#+LaTeX_CLASS: ifimaster
#+LATEX_HEADER: \usepackage{tikz}
#+LATEX_HEADER: \usetikzlibrary{shapes, arrows, arrows.meta, positioning}
#+LATEX_HEADER: \usepackage[scale=0.85]{sourcecodepro}
#+LATEX_HEADER: \usepackage[backend=biber,bibencoding=utf8]{biblatex}
#+LATEX_HEADER: \usepackage{amsthm, centernot, parskip, multicol, subcaption}
#+LATEX_HEADER: \bibliography{ref}
#+LaTeX_HEADER: \urlstyle{sf}

#+LaTeX_HEADER: \newcommand{\ins}[2]{ins(#1,\ \texttt{#2})}
#+LaTeX_HEADER: \newcommand{\del}[2]{del(#1,\ \texttt{#2})}
#+LATEX_HEADER: \newcommand{\tuple}[1]{\ensuremath{\langle #1\rangle}}
#+LATEX_HEADER: \let\oldcirc\circ
#+LATEX_HEADER: \renewcommand{\circ}{\oldcirc\,}
#+LaTeX_HEADER: \newenvironment{ritemize}{\begin{itemize}\raggedright}{\end{itemize}}
#+LaTeX_HEADER: \theoremstyle{definition}
#+LaTeX_HEADER: \newtheorem{definition}{Definition}[section]

#+LaTeX: \pgfdeclarelayer{bg}    % declare background layer
#+LaTeX: \pgfsetlayers{bg,main}  % set the order of the layers (main is the standard layer)

#+LaTeX: \ififorside{}
#+LaTeX: \frontmatter{}
#+LaTeX: \maketitle{}

#+BEGIN_abstract
Placeholder for abstract.
#+END_abstract

#+LaTeX: \tableofcontents{}
#+LaTeX: \listoffigures{}
#+LaTeX: \listoftables{}
* Acknowledgements
  :PROPERTIES:
  :UNNUMBERED: t
  :END:

Thanks to Rudi and Martin, Tore, Sigurd, Stian, Carl Martin, Kai, Jarle, Joshi,
Fui, Sigmund, Jonny, Simen, my family, and so many more.

* Preface
  :PROPERTIES:
  :UNNUMBERED: t
  :END:
  In 2013 [[http://lispnyc.org][LispNYC]], [[http://www.meetup.com/Clojure-NYC/][ClojureNYC]] and [[http://alu.org][Association of Lisp Users]] hosted a
  programming competition called [[http://lispinsummerprojects.org/][LISP In Summer Projects]], awarding cash prizes
  for Lisp-related projects. They gathered some great finalist judges: Matthias
  Felleisen, Richard Gabriel, Rich Hickey, Peter Norvig, Christian Queinnec and
  Taiichi Yuasa.

  Around the time of the announcement of the competition, I attended a course
  on functional programming, in which we were to collaborate on programming
  assignments in small teams (of two or three participants). Mostly, we
  programmed together whilst in the same room (physically), and at any given
  moment, the one with the most promising idea held the keyboard. Sometimes we
  all wanted to explore some idea, and we would have to type it out on separate
  computers, and synchronize our changes thereafter.

  At times we (or at least I) felt it broke our flow. I started investigating
  how to allow separate Emacs sessions communicate using network processes, and
  realized it was completely plausible to enable real-time collaboration in
  Emacs.

  Seeing the aforementioned competition announcement, I immediately decided
  that implementing real-time collaboration in Emacs would make the perfect
  project.

  My approach was quite naïve, and it was developed using a trial and error
  approach. By the end of the summer I had a rough prototype that worked for
  what I deemed "the most common use-cases". It had a very serious problem: All
  changes were applied under the assumption of consistency between clients, but
  this assumption proved false in non-trivial use-cases. There was no recovery
  mechanism in place, and if consistency was breached, then it would be up to
  the user to detect this, and reconnect.

  Still, the judges of the competition deemed the program worthy of second
  prize, awarding me $500 for my efforts.

  It was by far the most ambitious project I've embarked on, and also the most
  rewarding. I was greatly honored for receiving the prize, and feel my
  gratitude should be expressed in elegant Lisp code, that compose a working
  implementation of the program I wished I had written back in 2013.

  #+LaTeX: \mainmatter{}
* Introduction

  A real-time collaborative editor enables multiple users, at (potentially)
  different locations, to work on the same document /simultaneously/. The idea
  has been around for a long time, and was demoed by Douglas Engelbart in the
  Mother of All Demos cite:engelbart1968mother already in 1968. In this thesis
  we aim to formally verify and develop a system for real-time collaboration.

  First, let us make it clear what we will characterize as a real-time
  collaborative editor. An /editor/ is a program that allows a user to
  manipulate a document. The editor is considered /collaborative/ if it has
  features that makes it easier for multiple users to form a document together.
  Furthermore, it is considered /real-time/ if multiple users can edit the
  document simultaneously cite:ellis1989concurrency, and that changes are
  propagated to the other users within a reasonably short amount of time.

  The first actual implementation of such an editor that was documented in the
  literature, came with GROVE (GROUP Outline Viewing Editor)
  cite:ellis1989concurrency, which introduced the concept of /Operational
  Transformation/ (OT) which we will cover in Chapter [[Related Work]]. Previous
  systems
  cite:Greif:1986:ADA:512644.512659,Fish:1988:QCT:45410.45414,Lewis:1988:SBC:45410.45431
  that provided collaborative capabilities were not considered /real-time/
  systems by cite:ellis1989concurrency, because users could not edit the same
  /section/ of the document simultaneously.

  The reader might be familiar with [[https://www.google.com/docs/about/][Google Docs]], which is an example of a
  modern real-time collaborative document WYSIWYG (What You See Is What You
  Get) editor with over 240 million monthly active users cite:NextWeb2014. It
  is largely based on OT cite:WaveOT, but has also initiated research in a
  technique called Differential Synchronization cite:Fraser:09. Through its
  integration with [[https://www.google.com/drive/][Google Drive]], it offers a collaborative platform, where
  users can both store and manipulate their documents, as long as they have an
  internet connection and a (fairly modern) browser.

  We present a tool for real-time collaborative editing called Shared Buffer,
  which is designed with developers in mind. What most developers have in
  common is that they spend a lot of time manipulating /plain text/, yet they
  use a lot of different tools to do so cite:stackoverflowdevelopersurvey. We
  therefore aim at enabling real-time collaboration in /existing/ text editors,
  as opposed to developing an editor with real-time collaborative features. As
  a means to this end, we develop a protocol which, ideally, should be portable
  to any text editor, or any program that embeds a text editor.

  A client-server model is chosen, as opposed to a fully decentralized
  solution. We consequently move complexity to the server, if this can simplify
  the client-side algorithm; this is chosen in order to ensure portability.
  Furthermore, proving correctness for a fully decentralized solution has
  proven to be very difficult
  cite:formalOT,DBLP:journals/corr/abs-1302-3292,Imine2003.

  Our prototype client is for the text editor Emacs. The name Shared Buffer
  reflects a choice in design; in Emacs, text is stored in a /buffer/; when a
  file is opened, its contents is put inside a buffer which the user can
  manipulate. You may also have buffers that are not associated with any file.
  In Shared Buffer, there is no notion of a file, meaning there is no centrally
  stored copy of the document.

  The server is written in a dialect of Lisp called [[https://clojure.org/][Clojure]], a modern
  functional programming language with strong concurrency semantics
  cite:Emerick2012. Being hosted on the JVM, Clojure offers full Java
  interoperability, meaning that we can leverage the vast collection of Java
  libraries.

** The Naïve Algorithm

   Let us now consider two cases that illustrates how a naïve implementation
   (like the one briefly described in the [[Preface]]) might work, and where it
   fails to produce a desirable result.

   Say we have two users, our European friend $u_0$ and $u_1$, the American,
   who are both communicating with a server $S$. They each have a copy of a
   shared buffer. Both may either insert a character, or delete one from the
   buffer, and they may do so at any time. When a user performs an operation
   (meaning insertion or deletion) on its local buffer, then this should be
   communicated to $S$. When $S$ receives an operation, it should communicate
   this to the other user.

   We represent scenarios that can occur in the system graphically by using a
   variation of message sequence charts. The diagrams are read from top to
   bottom with regards to time, where directed edges represents the transfer of
   a message.

   #+BEGIN_EXPORT latex
   \begin{figure}[h]
     \centering
     \begin{tikzpicture}[>=stealth, shorten >= 5pt, node distance=1em, scale=1]
       \tikzstyle{vertex} = [circle, scale=0.5]
       \tikzstyle{O_0} = [vertex, fill=black!30!green]
       \tikzstyle{O_1} = [vertex, fill=black!30!blue]

       \tikzstyle{to} = [-{Stealth[scale=1.2]}]
       \tikzstyle{toO_0} = [to, color=black!30!green]
       \tikzstyle{toO_1} = [to, color=black!30!blue]

       \tikzstyle{op} = [midway, above=-3pt, sloped, text=black, font=\small]

       %% Server receives operations in this order
       \node (s) at (3, 4) {$S$};
       \coordinate (se) at (3, 0) {};
       \node[O_0, below = 2em of s] (s1) {};
       \node[O_1, below = 3.2em of s1] (s2) {};

       %% User 0 generates/receives in this order
       \node (u0) at (0, 4) {$u_0$};
       \node (u0e) at (0, 0) {};
       \node[O_0, below = of u0, label=left:{\texttt{a}}] (u00) {};
       \node[O_1, above = 2em of u0e, label=left:{\texttt{ba}}] (u01a) {};

       %% User 1 generates/receives in this order
       \node (u1) at (6, 4) {$u_1$};
       \node (u1e) at (6, 0) {};
       \node[O_0, below = 3em of u1, label=right:{\texttt{a}}] (u10a) {};
       \node[O_1, below = 1em of u10a, label=right:{\texttt{ba}}] (u11) {};

       \begin{pgfonlayer}{bg} % select the background layer
         \draw[to, color=black!30] (s) -- (s1)  -- (s2) -- (se);
         \draw[to, color=black!30] (u0) -- (u00) -- (u01a) -- (u0e);
         \draw[to, color=black!30] (u1) -- (u11) -- (u10a) -- (u1e);

         % Life of O_0
         \draw[toO_0] (u00) -- (s1) node [op] {$\overbrace{\ins{0}{a}}^{O_0}$};
         \draw[toO_0] (s1) -- (u10a) node [op, near end] {$O_0$};

         % Life of O_1
         \draw[toO_1] (u11) -- (s2) node [op] {$\overbrace{\ins{0}{b}}^{O_1}$};
         \draw[toO_1] (s2) -- (u01a) node [op, near end] {$O_1$};
       \end{pgfonlayer}
     \end{tikzpicture}
     \caption{A conflict-free scenario with two clients.}
     \label{fig:noconflict0}
   \end{figure}
   #+END_EXPORT

   Figure [[ref:fig:noconflict0]] describes a very simple scenario. Imagine that
   $u_0$ has an empty buffer which she precedes to insert an ="a"= into.
   Meanwhile, $u_1$ inserts a ="b"= in front of the ="a"= that just popped up
   in her buffer. The ="b"= eventually reaches $u_0$, and the end result of the
   interaction is that they both will be looking at a buffer containing ="ba"=.
   In this scenario the buffers ended up identical, so we say that we have
   reached a /consistent state/.

   Simple scenarios like the one we saw, where only one message is "in flight"
   at any one time, would be gracefully handled by even the naïve approach. We
   can see that ="a"= was inserted prior to the ="b"= at both $u_0$ and $u_1$,
   hence they cannot have been applied concurrently. We will now demonstrate
   that the approach does not work when we introduce concurrent edits.

   Let us return to the example from Figure [[ref:fig:noconflict0]], with a slight
   modification, visualized in Figure [[ref:fig:conflict0]]. The scenario is
   unchanged at $u_0$, where she first inserts an ="a"=, and later receives the
   ="b"= which leaves her with a buffer containing ="ba"=. Now say that $u_1$
   inserts her ="b"= /before/ having received the ="a"=. When she has already
   typed a ="b"=, she receives a message saying that she should place an ="a"=
   at the first point in her buffer. The resulting buffer is ="ab"=. Now they
   are looking at different buffers, so we say we have reached an /inconsistent
   state/.

   #+BEGIN_EXPORT latex
   \begin{figure}[h]
     \centering
     \begin{tikzpicture}[>=stealth, shorten >= 5pt, node distance=1em, scale=1]
       \tikzstyle{vertex} = [circle, scale=0.5]
       \tikzstyle{O_0} = [vertex, fill=black!30!green]
       \tikzstyle{O_1} = [vertex, fill=black!30!blue]

       \tikzstyle{to} = [-{Stealth[scale=1.2]}]
       \tikzstyle{toO_0} = [to, color=black!30!green]
       \tikzstyle{toO_1} = [to, color=black!30!blue]

       \tikzstyle{op} = [midway, above=-3pt, sloped, text=black, font=\small]

       %% Server receives operations in this order
       \node (s) at (3, 4) {$S$};
       \coordinate (se) at (3, 0) {};
       \node[O_0, below = 3em of s] (s1) {};
       \node[O_1, below = 1em of s1] (s2) {};

       %% User 0 generates/receives in this order
       \node (u0) at (0, 4) {$u_0$};
       \node (u0e) at (0, 0) {};
       \node[O_0, below = of u0, label=left:{\texttt{a}}] (u00) {};
       \node[O_1, above = 2em of u0e, label=left:{\texttt{ba}}] (u01a) {};

       %% User 1 generates/receives in this order
       \node (u1) at (6, 4) {$u_1$};
       \node (u1e) at (6, 0) {};
       \node[O_1, below = 1.5em of u1, label=right:{\texttt{b}}] (u11) {} ;
       \node[O_0, below = 3em of u11, label=right:{\texttt{ab}}] (u10a) {};

       \begin{pgfonlayer}{bg} % select the background layer
         \draw[to, color=black!30] (s) -- (s1)  -- (s2) -- (se);
         \draw[to, color=black!30] (u0) -- (u00) -- (u01a) -- (u0e);
         \draw[to, color=black!30] (u1) -- (u11) -- (u10a) -- (u1e);

         % Life of O_0
         \draw[toO_0] (u00) -- (s1) node [op] {$\overbrace{\ins{0}{a}}^{O_0}$};
         \draw[toO_0] (s1) -- (u10a) node [op, near end] {$O_0$};

         % Life of O_1
         \draw[toO_1] (u11) -- (s2) node [op] {$\overbrace{\ins{0}{b}}^{O_1}$};
         \draw[toO_1] (s2) -- (u01a) node [op, near end] {$O_1$};
       \end{pgfonlayer}
     \end{tikzpicture}
     \caption{A minimal conflict with two clients.}
     \label{fig:conflict0}
   \end{figure}
   #+END_EXPORT

   In this thesis we introduce and discuss a new protocol which guarantees
   /eventual consistency/ cite:Vogels:2009:EC:1435417.1435432 between
   participating clients. Intuitively, this means that if all users stop typing
   at some point, then given enough time for traveling messages to reach their
   destination, they will all be looking at the same buffer. In later chapters
   we will come to realize that is not at all trivial, considering the highly
   concurrent and distributed nature of the problem. In order to handle this
   level of complexity we will rely heavily on the use of formal methods.

** Method

   In this thesis we use a formal verification technique called /model
   checking/ cite:Clarke:2000:MC:332656. This technique requires us to obtain a
   mathematical model of the system we wish to validate. A model is represented
   as a set of states, and transitions between these states. We can think of
   model checking as a graph search, where the states acts as nodes, and edges
   represent the possibility of going from one state to another. If the graph
   is finite, we can prove that the model has a certain property by checking
   whether the property holds true in every state. Furthermore, we want to use
   Linear Temporal Logic (LTL) to express properties over paths, which are
   sequences of states.

   The model is generally an abstraction of a given system, where one carefully
   chooses what parts of the system is necessary to represent, in order to
   prove the properties that are of interest.

   Moreover, we use the model as a way of driving the development process, or
   rather, solving the problem. When model checking a property, a counter
   example is given if the property does not hold. By studying the example, we
   can change the model in hope of resolving the issue, and see the effects of
   the change. This resembles Test Driven Development (TDD), but instead of
   testing our actual system we perform tests on a model, and rather than
   testing a few selected scenarios, we check all possible scenarios.

   [[http://maude.cs.illinois.edu/][The Maude System]] is our chosen modeling language and verification tool. It
   provides an expressive language, that is well suited for modeling concurrent
   and distributed systems [[cite:DBLP:conf/maude/2007]]. In addition, it provides
   The LTL Model Checker cite:Eker2004162, which allows us to specify and
   verify LTL properties.

** Contributions

   The main result of this thesis is a protocol that enables real-time
   collaborative editing. Both a client- and server-side algorithm have been
   modeled and implemented. The model has been formally verified to guarantee
   eventual consistency for a limited number of clients and operations.

   In the process we have:
   - provided a mathematical description of our system based on OT,
   - demonstrated the how modeling has been used to drive the development,
   - presented a representation of the system in Maude,
   - performed LTL model checking on our model in Maude,
   - provided a client as an extension for Emacs,
   - provided an implementation of the server-side algorithm in Clojure.

* Formal Semantics of Editing Operations

  #+BEGIN_EXPORT latex
  \begin{wrapfigure}[14]{r}{0pt}
    \begin{tikzpicture}[>=stealth, shorten >= 5pt, node distance=1em, scale=1]
        \tikzstyle{vertex} = [circle, scale=0.5]
        \tikzstyle{O_0} = [vertex, fill=black!30!green]
        \tikzstyle{O_1} = [vertex, fill=black!30!blue]

        \tikzstyle{to} = [-{Stealth[scale=1.2]}]
        \tikzstyle{toO_0} = [to, color=black!30!green]
        \tikzstyle{toO_1} = [to, color=black!30!blue]

        \tikzstyle{op} = [midway, above=-3pt, sloped, text=black, font=\small]

        %% Server receives operations in this order
        \node[color=black!20] (s) at (3, 3.5) {$S$};
        \coordinate (se) at (3, 0) {};
        \node[O_0, color=black!20, below = 2em of s] (s1) {};
        \node[O_1, color=black!20, below = 1.5em of s1] (s2) {};

        %% User 0 generates/receives in this order
        \node (u0) at (0, 3.5) {$u_0$};
        \node (u0e) at (0, 0) {};
        \node[O_0, below = of u0, label=left:{\texttt{a}}] (u00) {};
        \node[O_1, above = 2em of u0e, label=left:{\texttt{ba}}] (u01a) {};

        \begin{pgfonlayer}{bg} % select the background layer
          \draw[to, color=black!20] (s) -- (s1)  -- (s2) -- (se);
          \draw[to, color=black!30] (u0) -- (u00) -- (u01a) -- (u0e);

          % Life of O_0
          \draw[toO_0] (u00) -- (s1) node [op] {$\overbrace{\ins{0}{a}}^{O_0}$};

          % Life of O_1
          \draw[toO_1] (s2) -- (u01a) node [op] {$\overbrace{\ins{0}{b}}^{O_1}$};
        \end{pgfonlayer}
    \end{tikzpicture}
    \caption{Our focus is on the operations of a single user.}
    \label{fig:focusclient}
  \end{wrapfigure}
  #+END_EXPORT

  A model of a given system is an abstraction of that system cite:Lamport:2002,
  which means only some aspects of the system are described. In our case, the
  fundamental capabilities of a text editor, namely the insertion and
  deletions of characters in a buffer, should be captured, along with the order
  in which they are performed. The time between operations is an example of
  something /not/ represented in the model; as a result the model cannot be
  used to analyze the real time performance of the system. Other features of a
  text editor, like "search and replace", are also omitted, because such
  features can be represented as a series of deletions and insertions.

  In this chapter we introduce a formal definition of editing operations. The
  definitions are based on
  cite:ellis1989concurrency,DBLP:journals/corr/abs-1302-3292, but we provide
  more formal definitions, in the sense that the semantics of editing
  operations are described as a set of equations. This chapter is only
  concerned with events at a single client. We assume that every event is
  simply an operation being applied, and do not differentiate between an
  operation originating locally or remotely.

** Operations and Buffers

   The operations we are concerned with is the /insertion/ and /deletion/ of a
   character in a buffer.
   #+BEGIN_EXPORT latex
   \\
   \begin{definition}[Operations]
     The set $\mathcal O$ is inductively defined as the smallest set such that
     the following holds:
     \begin{itemize}
     \item \(nop \in \mathcal O\),
     \item \(ins(i,\ c) \in \mathcal O\) for any \(i \in \mathbb{N}\) and \(c \in Unicode\),
     \item \(del(i) \in \mathcal O\) for any \(i \in \mathbb{N}\),
     \item for any two \(O_i, O_j \in \mathcal O\) then \(O_j \circ O_i \in \mathcal O\).\hfill$\dashv$
     \end{itemize}
   \end{definition}
   #+END_EXPORT

   The semantics of an operation is defined in terms of how it is applied to a
   buffer, where a buffer is simply defined as a 0-indexed string of UTF-8
   encoded characters. The set $Unicode$ is our alphabet, which contains every
   character defined by the Unicode standard cite:unicode-standard. We let
   $\mathcal B$ constitute the set of all possible buffers --- this set could
   also be expressed as $Unicode^{*}$.

   An operation can be applied to a buffer, which in turn yields a new buffer.
   Consequently all $O \in \mathcal O$ are partial unary operations $O :
   \mathcal B \rightarrow \mathcal B$. The operations are partial because a
   given operation cannot necessarily be applied to all buffers; as an example,
   no delete operation can be applied to the empty buffer $\epsilon$. We assume
   that no text-editor are able to produce an operation which is ill-defined on
   its current buffer.
   #+BEGIN_EXPORT latex
   \\
   \begin{definition}{(Semantics of Operations).}
     Let $B \in \mathcal{B}$. The $nop$ operation is the operation that does
     nothing, and applying it is defined as:
     \begin{align*}
       nop(B) &= B
     \end{align*}
     Let $i \in \mathbb{N}$, and both $c, c' \in Unicode$. We let a single space
     represent concatenation, where characters are treated like strings of length
     one. Applying an insertion is then defined as follows:
     \begin{align*}
       ins(0, c)(B) &= c\ B \\
       ins(i + 1, c)(c'\ B) &= c'\ ins(i, c)(B)
     \end{align*}
     Similarly, applying a deletion is defined as:
     \begin{align*}
       del(0)(c\ B) &= B \\
       del(i + 1)(c\ B) &= c\ del(i)(B)
     \end{align*}
     Let $O_i, O_j \in \mathcal O$, and let $O_j \circ O_i$ represent the
     \textit{composition} of $O_i$ and $O_j$. Applying a composed operation to a buffer
     is defined as:
     \begin{align*}
       O_j \circ O_i(B) &= O_j(O_i(B))
     \end{align*}\hfill$\dashv$
   \end{definition}
   #+END_EXPORT
   Note that composition of operations is no different from regular function
   composition.

** Scenarios Described in Terms of Operations and Their Application

   In the previous section we formalized
   - what operations are,
   - how operations are applied to buffers, and
   - how operations are combined.

   Let us try to bridge the gap between the formal notion of an editing
   operation, and scenarios that involves a user typing on a keyboard. Imagine
   that a user types the word ~"hello"~ --- this is modeled as a single
   operation:
   \[ \ins{4}{o} \circ \ins{3}{l} \circ \ins{2}{l} \circ \ins{1}{e} \circ \ins{0}{h} \]
   The result of applying the operation to the empty buffer $\epsilon$
   evaluates to the buffer that only contains the word ~"hello"~, and can be
   calculated as so:
   #+BEGIN_EXPORT latex
   \begin{align*}
     \ins{4}{o} \circ \ins{3}{l} \circ \ins{2}{l} \circ \ins{1}{e} \circ \ins{0}{h} (\epsilon) &= \\
     \ins{4}{o} \circ \ins{3}{l} \circ \ins{2}{l} \circ \ins{1}{e} (\texttt{"h"}) &= \\
     \ins{4}{o} \circ \ins{3}{l} \circ \ins{2}{l} (\texttt{"he"}) &= \\
     \ins{4}{o} \circ \ins{3}{l} (\texttt{"hel"}) &= \\
     \ins{4}{o} (\texttt{"hell"}) &= \texttt{"hello"}
   \end{align*}
   #+END_EXPORT
   Now we will expand from the case where a single user types on a keyboard,
   and include operations that can be received from a server. In the scenario
   best described by Figure [[ref:fig:noconflict0]] (page pageref:fig:noconflict0),
   we saw two operations $\ins{0}{a}$ and $\ins{0}{b}$, named $O_0$ and $O_1$
   respectively, being applied in the same order at two different locations.
   #+BEGIN_EXPORT latex
   \begin{multicols}{2}
     From the perspective of $u_0$:
     \begin{itemize}
     \item $O_0$ is generated locally,
     \item $O_1$ is received from the server.
     \end{itemize}
     \columnbreak
     From the perspective of $u_1$:
     \begin{itemize}
     \item $O_0$ is received from the server,
     \item $O_1$ is generated locally.
     \end{itemize}
   \end{multicols}
   #+END_EXPORT
   Common to both $u_0$ and $u_1$ is their initial buffer (the empty buffer
   $\epsilon$) and the operation they apply is $O_1 \circ O_0$. Because they
   perform the same operation to the same initial buffer, they must necessarily
   end up in a consistent state (i.e. end up with the same buffer).

   The scenario from Figure [[ref:fig:conflict0]] (page pageref:fig:conflict0) is
   almost identical to the scenario above, but the operations are applied in
   different orders.
   #+BEGIN_EXPORT latex
   \begin{multicols}{2}
     From the perspective of $u_0$:
     \begin{itemize}
     \item $O_0$ is generated locally,
     \item $O_1$ is received from the server.
     \end{itemize}
     \columnbreak
     From the perspective of $u_1$:
     \begin{itemize}
     \item $O_1$ is generated locally,
     \item $O_0$ is received from the server.
     \end{itemize}
   \end{multicols}
   #+END_EXPORT
   $u_0$ and $u_1$ have the same initial buffer, but the composed operation of
   $u_0$ is $O_1 \circ O_0$ and the composed operation of $u_1$ is $O_0 \circ
   O_1$. By applying these operations to the empty buffer $\epsilon$ we show
   that $u_0$ and $u_1$ end up in an inconsistent state (i.e. end up with
   different buffers).
   #+BEGIN_EXPORT latex
   \begin{multicols}{2}
     Operation applied by $u_0$:
     \begin{align*}
       \overbrace{\ins{0}{b}}^{O_1} \circ \overbrace{\ins{0}{a}}^{O_0}(\epsilon) &= \\
       \ins{0}{b}(\texttt{"a"}) &= \texttt{"ba"}
     \end{align*}

     \columnbreak
     Operation applied by $u_1$:
     \begin{align*}
       \overbrace{\ins{0}{a}}^{O_0} \circ \overbrace{\ins{0}{b}}^{O_1}(\epsilon) &= \\
       \ins{0}{a}(\texttt{"b"}) &= \texttt{"ab"}
     \end{align*}
   \end{multicols}
   #+END_EXPORT

** Algebraic Properties

   An algebraic structure is a set along with one or more operations
   cite:antonsen2014logiske. The set of operations $\mathcal O$ under
   composition $\circ : \mathcal O \times \mathcal O \rightarrow \mathcal O$
   forms an algebraic structure, denoted $\langle \mathcal O, \circ \rangle$.

   The previous section contains a proof that $\circ$ is /not/ commutative,
   meaning that $O_j \circ O_i = O_i \circ O_j$ is not the case for all $O_i,
   O_j \in \mathcal O$.
   \begin{proof}
   As examplified in the previous section:
   \[
   ins(0, b) \circ ins(0, a) \neq ins(0, a) \circ ins(0, b)
   \]
   \end{proof}

   The fact that $\circ$ is not commutative is precisely the problem with the
   naïve algorithm (Section [[The Naïve Algorithm]]); in other words, the naïve
   algorithm would guarantee eventual consistency if the order of which
   operations are applied does not affect the end result. In the next chapter
   we will introduce /Operational Transformation/ which, at its core, is a
   technique for restoring commutativity for operations.

   Furthermore, it is worth noting that the structure $\langle \mathcal O,
   \circ \rangle$ is a /monoid/ because it satisfies the following properties:

   - $nop$ is the identity element of $\circ$.
     \begin{proof}
     Let $O \in \mathcal O$, then
     \begin{itemize}
       \item $nop \circ O(B) = nop(O(B)) = O(B)$
       \item $O \circ nop(B) = O(nop(B)) = O(B)$
     \end{itemize}
     for any $B \in \mathcal B$. It follows that $nop \circ O = O \circ nop = O$.
     \end{proof}
   - $\circ$ is associative.
     \begin{proof}
     Let $O_i, O_j, O_k \in \mathcal O$, then
     \begin{itemize}
       \item $((O_k \circ O_j) \circ O_i)(B) = (O_k \circ O_j)(O_i(B)) = O_k(O_j(O_i(B)))$
       \item $(O_k \circ (O_j \circ O_i))(B) = O_k((O_j \circ O_i)(B)) = O_k(O_j(O_i(B)))$
     \end{itemize}
     for any $B \in \mathcal B$. It follows that $O_k \circ (O_j \circ O_i) =
     (O_k \circ O_j) \circ O_i$.
     \end{proof}
   - $\circ$ is closed under $\mathcal O$.
     \begin{proof}
     By definition.
     \end{proof}

   There are two main reasons for noting these algebraic properties; one is
   that it is helpful when writing a formal specification in Maude, because
   Maude is an /algebraic/ specification language; the other is that it helps
   when translating the structure to a given programming language, by making
   sure the selected representation preserves the properties of a monoid.

*** Invertibility

    A /group/ can be described as a monoid with /invertibility/, meaning every
    element in $\mathcal O$ has an inverse. More formally, for $\langle
    \mathcal O, \circ \rangle$ to be a group, it must satisfy that for any $O_i
    \in \mathcal O$ there exists a $O_j \in \mathcal O$ such that:
    #+BEGIN_EXPORT latex
    \[ O_j \circ O_i = O_i \circ O_j = nop \]
    #+END_EXPORT
    The inverse of an operation $O \in \mathcal O$ is denoted $O^{-1}$, and so
    the equation can be restated as:
    #+BEGIN_EXPORT latex
    \[ O \circ O^{-1} = O^{-1} \circ O = nop \]
    #+END_EXPORT
    /Undo/ is a common feature in text editors, and should guide us in
    constructing an inverse function for $\mathcal O$. Intuitively it seem to
    satisfy the equation, in the sense that adding a character to a buffer,
    followed by an undo is the same as having done nothing at all.

    Guided by this intuition, the inverse of $\ins{0}{a}$ should be $del(0)$,
    because applying $del(0) \circ \ins{0}{a}$ to a buffer will always yield
    the same buffer. We can make the exact same argument for $\ins{0}{b}$; its
    inverse should be $del(0)$. What should then be the inverse of $del(0)$? It
    cannot be both $\ins{0}{a}$ and $\ins{0}{b}$, which poses a problem.

    The problem is solved by extending the delete operations with what
    character is deleted, and so we redefine delete operations as so:
    - $del(i,\ c) \in \mathcal O$ for any $i \in \mathbb{N}$ and $c \in Unicode$.

    With the information of what character was deleted in the operation, we
    disambiguate what the inverse of a deletion should be. The inverse of
    $\ins{0}{a}$ should be $\del{0}{a}$, and the inverse of $\ins{0}{b}$ should
    be $\del{0}{b}$, where the inverse of each deletion should be $\ins{0}{a}$
    and $\ins{0}{b}$ respectively.

    Inverting composed operations is analogous with undoing multiple steps. Say
    a user types an =a= followed by a =b=, then undoing it would be to first
    delete the =b=, then delete the =a=. So for instance, the inverse of
    $\ins{1}{b} \circ \ins{0}{a}$ should be $\del{0}{a} \circ \del{1}{b}$.
    #+BEGIN_EXPORT latex
    \\
    \begin{definition}[Inverse of an Operation]
      The inverse of the $nop$ element is the $nop$ element itself:
      \[ nop^{-1} = nop \]
      The inverse of an insertion of a character $c \in Unicode$ at position $i
      \in \mathbb{N}$, is the deletion of that character at that position:
      \[ ins(i,\ c)^{-1} = del(i,\ c) \]
      Similarly for deletions:
      \[ del(i,\ c)^{-1} = ins(i,\ c) \]
      For a composed operation $O_j \circ O_i \in \mathcal{O}$, the order of the
      operations is reversed, and the operations are inverted:
      \[ (O_j \circ O_i)^{-1} = O_i^{-1} \circ O_j^{-1} \]\hfill$\dashv$
    \end{definition}
    #+END_EXPORT
    Now that we have defined an inverse for all operations, we can check if the
    invertibillity axiom holds. Say we have the operation $\ins{0}{a}$, then
    its inverse is $\del{0}{a}$. We apply $\del{0}{a} \circ \ins{0}{a}$ to the
    empty buffer $\epsilon$:
    #+BEGIN_EXPORT latex
    \begin{align*}
      \del{0}{a} \circ \ins{0}{a} (\epsilon) &= \\
      \del{0}{a} (\texttt{"a"}) &= \epsilon
    \end{align*}
    #+END_EXPORT
    In order to satisfy the invertibility axiom, the reverse should be true as
    well. It is not because applying $\ins{0}{a} \circ \del{0}{a}$ on the empty
    buffer $\epsilon$, because it is not well defined. Consequently the
    invertibility axiom does not hold, and so $\langle \mathcal O, \circ
    \rangle$ is not a group.

    Inverting operations is an essential part of the Shared Buffer algorithm,
    and we rely on the definition above even though the invertibillity axiom
    does not hold. Notice that the counter example $\ins{0}{a} \circ \del{0}{a}
    (\epsilon)$ expresses that a deletion is applied to the empty buffer and
    then undone. It seems fair to question if that situation could really
    occur, because there is no reasonably defined way for an editor to perform
    the deletion in the first place.

    We have to ensure that the algorithm never construct an operation that
    cannot be applied to a given client's buffer. We rely on the model checker
    to provide a counter example, if we were to construct such an operation.
* Related Work

  In this chapter we present some of the work of Ellis and Gibbs
  cite:ellis1989concurrency, the pioneers of /Operational Transformation/ (OT)
  and the very interesting work of Imine et al. on proving correctness for
  transformation functions using formal verification techniques
  cite:DBLP:conf/ecscw/ImineMOR03,DBLP:journals/corr/abs-1302-3292,formalOT.
  The chapter should sufficiently convay the basic idea of OT and how it
  works, without going into the finer details. We use notation estabelished in
  Chapter [[Formal Semantics of Editing Operations]] to describe the workings of
  OT.

** Basics of OT

   Ellis and Gibbs introduced the dOPT (Distributed Operational Transformation)
   algorithm cite:ellis1989concurrency, and with it, /Operational
   Transformation/ (OT), which tries to solve the problem of diverging copies
   of a buffer, in a fully distributed setting. The main idea is to construct a
   /transformation function/ where remote operations are transformed with
   regards to conflicting local operations in a way that guarantees
   consistency.

   In order to achieve this, an additional parameter, /priority/, is added to
   insertions and deletions; the priority is a unique identifier for a given
   client, represented as a number, and is used in order to break ties. The
   transformation function $T: \mathcal O \times \mathcal O \rightarrow
   \mathcal O$, proposed by Ellis and Gibbs, is restated in Figure
   [[ref:fig:transformation-function]].

   #+BEGIN_EXPORT latex
   \begin{figure}[h]
     \begin{align*}
       T(ins(p1,c1,pr1), ins(p2,c2,pr2)) &=
       \begin{cases}
         ins(p1,c1,pr1)      & \text{if }      p1 < p2 \\
         ins(p1+1,c1,pr1)    & \text{else if } p1 > p2 \\
         nop                 & \text{else if } c1 = c2 \\
         ins(p1+1,c1,pr1)    & \text{else if } pr1 > pr2 \\
         ins(p1,c1,pr1)      & \text{otherwise}
       \end{cases}
       \\\\
       T(ins(p1,c1,pr1), del(p2,pr2)) &=
       \begin{cases}
         ins(p1,c1,pr1)      & \text{if } p1 < p2 \\
         ins(p1-1,c1,pr1)    & \text{otherwise}
       \end{cases}
       \\\\
       T(del(p1,pr1), ins(p2,c2,pr2)) &=
       \begin{cases}
         del(p1,pr1)         & \text{if } p1 < p2 \\
         del(p1+1,pr1)       & \text{otherwise}
       \end{cases}
       \\\\
       T(del(p1,pr1), del(p2,pr2)) &=
       \begin{cases}
         del(p1,pr1)         & \text{if }      p1 < p2 \\
         del(p1-1,pr1)       & \text{else if } p1 > p2 \\
         nop                 & \text{otherwise}
       \end{cases}
     \end{align*}
     \caption{The transformation function from \cite{ellis1989concurrency}.}
     \label{fig:transformation-function}
   \end{figure}
   #+END_EXPORT
   Let us again consider the example described in Figure [[ref:fig:conflict0]]
   (page pageref:fig:conflict0), where two operations $O_0 = ins(0,\
   \texttt{a},\ 0)$ and $O_1 = ins(0,\ \texttt{b},\ 1)$ are performed
   concurrently, leading to an inconsistent state. Rather than applying
   operations directly, remote operations are transformed with regards to
   (potential) concurrent local operations, before they are applied.
   Communication is done directly between clients (as opposed to going via a
   server).
   #+BEGIN_EXPORT latex
   \begin{multicols}{2}
     From the perspective of $u_0$:
     \begin{ritemize}
     \item $O_0$ is generated locally,
     \item $O_1$ is received from $u_1$, $T(O_1, O_0)$ is applied.
     \end{ritemize}
     \columnbreak
     From the perspective of $u_1$:
     \begin{ritemize}
     \item $O_1$ is generated locally,
     \item $O_0$ is received from $u_0$, $T(O_0, O_1)$ is applied.
     \end{ritemize}
   \end{multicols}
   #+END_EXPORT
   The scenario is illustrated in Figure
   [[ref:fig:conflict-resolved-transformation]]. By composing the operations at
   each user and applying that operation to the empty buffer $\epsilon$, the
   resulting buffer is found.
   #+BEGIN_EXPORT latex
   \begin{multicols}{2}
     Operation applied by $u_0$:
     \begin{align*}
       T(O_1, O_0) \circ ins(0,\ \texttt{a},\ 0) (\epsilon) &= \\
       T(ins(0,\ \texttt{b},\ 1), ins(0,\ \texttt{a},\ 0)) (\epsilon) &= \\
       ins(1,\ \texttt{b},\ 1)(\texttt{"a"}) &= \texttt{"ab"}
     \end{align*}

     \columnbreak
     Operation applied by $u_1$:
     \begin{align*}
       T(O_0, O_1) \circ ins(0,\ \texttt{b},\ 1) (\epsilon) &= \\
       T(ins(0,\ \texttt{a},\ 0), ins(0,\ \texttt{b},\ 1)) (\epsilon) &= \\
       ins(0,\ \texttt{a},\ 0)(\texttt{"b"}) &= \texttt{"ab"}
     \end{align*}
   \end{multicols}
   #+END_EXPORT
   #+BEGIN_EXPORT latex
   \begin{figure}[h]
     \centering
     \begin{tikzpicture}[>=stealth, shorten >= 5pt, node distance=1em, scale=1]
       \tikzstyle{vertex} = [circle, scale=0.5]
       \tikzstyle{O_0} = [vertex, fill=black!30!green]
       \tikzstyle{O_1} = [vertex, fill=black!30!blue]

       \tikzstyle{to} = [-{Stealth[scale=1.2]}]
       \tikzstyle{toO_0} = [to, color=black!30!green]
       \tikzstyle{toO_1} = [to, color=black!30!blue]

       \tikzstyle{op} = [above=-3pt, sloped, text=black]

       %% User 0 generates/receives in this order
       \node (u0) at (0, 5) {$u_0$};
       \node (u0e) at (0, 0) {};
       \node[O_0, below = of u0, label=left:{\texttt{a}}] (u00) {};
       \node[O_1, above = 2em of u0e, label=left:{\texttt{ab}}] (u01a) {};

       %% User 1 generates/receives in this order
       \node (u1) at (7, 5) {$u_1$};
       \node (u1e) at (7, 0) {};
       \node[O_1, below = 4em of u1, label=right:{\texttt{b}}] (u11) {} ;
       \node[O_0, below = 1em of u11, label=right:{\texttt{ab}}] (u10a) {};

       \draw[to, color=black!30] (u0) -- (u00) -- (u01a) -- (u0e);
       \draw[to, color=black!30] (u1) -- (u11) -- (u10a) -- (u1e);

       % Life of O_0
       \draw[toO_0] (u00) -- (u10a) node [op, pos=0.4] {$\overbrace{T(ins(0,\ \texttt{a},\ 0), ins(0,\ \texttt{b},\ 1))}^{ins(0,\ \texttt{a},\ 0)}$};

       % Life of O_1
       \draw[toO_1] (u11) -- (u01a) node [op, pos=0.6] {$\overbrace{T(ins(0,\ \texttt{b},\ 1), ins(0,\ \texttt{a},\ 0))}^{ins(1,\ \texttt{b},\ 1)}$};

     \end{tikzpicture}
     \caption{Conflict resolved using $T$.}
     \label{fig:conflict-resolved-transformation}
   \end{figure}
   #+END_EXPORT
   Note that $T(O_1, O_0) \circ O_0 \neq T(O_0, O_1) \circ O_1$ (i.e. the
   operations are not /equal/), but they are /equivalent/ in the sense that
   applying them to the same buffer yields the same result, denoted:
   #+BEGIN_EXPORT latex
   \[ T(O_1, O_0) \circ O_0 \equiv T(O_0, O_1) \circ O_1 \]
   #+END_EXPORT
   As shown, the transformation function $T$ can be used to resolve a conflict.
   However, the algorithm should be able to handle any number of concurrent
   operations, from an arbitrary number of clients, which may lead to conflicts
   of great complexity --- it is not given that the transformation function can
   resolve every conflict that can arise.

** Discussing Consistency in OT

   This section introduces some consistency models that have been used to
   describe correctness of OT algorithms, and achievements in trying to verify
   these algorithms. In OT it is common to refer to a /site/ as an uniquely
   identified object with a data segment (for example a document) which a user
   can manipulate. When no messages are "in flight" the system is said to be
   /quiescence/.

   The consistency model of cite:ellis1989concurrency, is defined by the
   following two properties:

   - *Causality*[fn:1]: If $O_i$ was executed before $O_j$ at one site, then
     $O_i$ must be executed before $O_j$ on all sites.
   - *Convergence*: At quiescence, all copies are identical.

   Sun et al. cite:DBLP:journals/tochi/SunJZYC98 expanded the consistency model
   of cite:ellis1989concurrency with:

   - *Intention preservation*: If an operation $O_i$ has been transformed to
     $O_i'$, then the effects of applying $O_i'$ must be equivalent of that of
     applying $O_i$.

   dOPT is a fully distributed algorithm, where determining temporal
   relationships between events (i.e. generation and reception of operations)
   is a more challenging task than when leveraging a centralized server. It
   uses a /state vector/ (also referred to as a /vector clock/) which is
   essentially an extension of Lamport clocks cite:lamport1978time, yielding a
   partial order of events. An ordering being partial means that there exists
   events where neither event precedes the other, which means the events are
   /concurrent/.

   The dOPT algorithm ensures that operations are applied according to the
   partial order of events, where an event is either the generation of an
   operation or the reception of one. This ensures causality, but not
   convergence. Because the order is partial there are events that are
   concurrent; instead of trying to order these events /totally/ (i.e. ensure
   that for any two events, one will precede the other) a transformation
   function is used. Given two concurrent operations $O_i, O_j$, where $O_i$
   has already been applied, $O_j$ must be transformed with regards to $O_i$
   before it is applied.

   A transformation function $T$ must satisfy:
   #+BEGIN_EXPORT latex
   \begin{equation*}
     \tag{$C_1$}
     T(O_j, O_i) \circ O_i \equiv T(O_i, O_j) \circ O_j
     \label{eqn:C1}
   \end{equation*}
   #+END_EXPORT
   for all $O_i, O_j \in \mathcal O$ in order to guarantee convergence; this is
   a necessary, but not a sufficient condition cite:ellis1989concurrency. The
   transformation function $T$ from Figure [[ref:fig:transformation-function]] does
   not satisfy the condition, which has been shown by
   cite:DBLP:conf/ecscw/ImineMOR03.

   We have been able to reproduce the result by model checking our Maude
   specification. A minimal counter example, as shown in Figure
   [[ref:fig:disprove-c1]], involves two operations, $O_0 = \ins{0}{b}$ and $O_1 =
   del(0)$, applied to an initially non-empty buffer. The priority parameter is
   omitted in this example, because it has no effect on the outcome. Assume
   that both $u_0$ and $u_1$ initially has a buffer containing ~"a"~.
   #+BEGIN_EXPORT latex
   \begin{multicols}{2}
     From the perspective of $u_0$:
     \begin{ritemize}
     \item $\ins{0}{b}$ is generated locally,
     \item $O_1$ is received from $u_1$, $T(O_1, O_0)$ is applied.
     \end{ritemize}
     \columnbreak
     From the perspective of $u_1$:
     \begin{ritemize}
     \item $del(0)$ is generated locally,
     \item $O_0$ is received from $u_0$, $T(O_0, O_1)$ is applied.
     \end{ritemize}
   \end{multicols}
   #+END_EXPORT
   Again, the resulting buffer can be calculated by applying the respective
   operations to the buffer ~"a"~.
   #+BEGIN_EXPORT latex
   \begin{multicols}{2}
     Operation applied by $u_0$:
     \begin{align*}
       T(O_1, O_0) \circ \ins{0}{b} (\texttt{"a"}) &= \\
       T(del(0), \ins{0}{b}) (\texttt{"ba"}) &= \\
       del(1) (\texttt{"ba"}) &= \texttt{"b"}
     \end{align*}

     \columnbreak
     Operation applied by $u_1$:
     \begin{align*}
       T(O_0, O_1) \circ del(0) (\texttt{"a"}) &= \\
       T(\ins{0}{b}, del(0)) (\epsilon) &= \\
       \ins{-1}{b} (\epsilon) &= \textcolor{black!15!red}{error}
     \end{align*}
   \end{multicols}
   #+END_EXPORT
   #+BEGIN_EXPORT latex
   \begin{figure}[h]
     \centering
     \begin{tikzpicture}[>=stealth, shorten >= 5pt, node distance=1em, scale=1]
       \tikzstyle{vertex} = [circle, scale=0.5]
       \tikzstyle{O_0} = [vertex, fill=black!30!green]
       \tikzstyle{O_1} = [vertex, fill=black!30!blue]

       \tikzstyle{to} = [-{Stealth[scale=1.2]}]
       \tikzstyle{toO_0} = [to, color=black!30!green]
       \tikzstyle{toO_1} = [to, color=black!30!blue]

       \tikzstyle{op} = [above=-3pt, sloped, text=black]

       %% User 0 generates/receives in this order
       \node (u0) at (0, 5) {$u_0$};
       \node (u0e) at (0, 0) {};
       \node[draw=none, below = of u0, label=left:{\texttt{a}}] (u0l) {};
       \node[O_0, below = of u0l, label=left:{\texttt{ba}}] (u00) {};
       \node[O_1, above = 2em of u0e, label=left:{\texttt{b}}] (u01a) {};

       %% User 1 generates/receives in this order
       \node (u1) at (6, 5) {$u_1$};
       \node (u1e) at (6, 0) {};
       \node[draw=none, below = of u1, label=right:{\texttt{a}}] (u1l) {};
       \node[O_1, below = 5em of u1, label=right:{$\epsilon$}] (u11) {} ;
       \node[O_0, below = 1em of u11, label=right:{$\textcolor{black!15!red}{error}$}] (u10a) {};

       \draw[to, color=black!30] (u0) -- (u00) -- (u01a) -- (u0e);
       \draw[to, color=black!30] (u1) -- (u11) -- (u10a) -- (u1e);

       % Life of O_0
       \draw[toO_0] (u00) -- (u10a) node [op, pos=0.4] {$\overbrace{T(\ins{0}{b}, del(0))}^{\ins{-1}{b}}$};

       % Life of O_1
       \draw[toO_1] (u11) -- (u01a) node [op, pos=0.6] {$\overbrace{T(del(0), \ins{0}{b})}^{del(1)}$};

     \end{tikzpicture}
     \caption{Disproving \ref{eqn:C1}.}
     \label{fig:disprove-c1}
   \end{figure}
   #+END_EXPORT
   Here we demonstrate two problems with the transformation function. One is
   that the buffers diverged, seeing that $u_0$ and $u_1$ does not end up in
   the same final state. Secondly, the transformation function returns
   $\ins{-1}{b}$ which is not well defined, and is not in the set of operations
   $\mathcal O$. The problem is manifested in the second equation from Figure
   [[ref:fig:transformation-function]], where $<$ must be replaced with $\le$. The
   equation is restated correctly for completeness:
   #+BEGIN_EXPORT latex
     \[
     T(ins(p1,c1,pr1), del(p2,pr2)) =
     \begin{cases}
       ins(p1,c1,pr1)   & \text{if } p1 \le p2 \\
       ins(p1-1,c1,pr1) & \text{otherwise}
     \end{cases}
     \]
   #+END_EXPORT
   From what we can tell, the bug went unnoticed for many years[fn:2], which
   shows the subtleness of the bug --- uncovering bugs like this is hard, and
   is part of our motivation for using formal methods.

   The corrected version of $T$ satisfies ref:eqn:C1, but this is not
   sufficient for guaranteeing convergence. It handles all conflicts where only
   two operations are involved; in order to handle any number of concurrent
   operations, being executed in arbitrary order, $T$ must also satisfy:
   #+BEGIN_EXPORT latex
   \begin{equation*}
     \tag{$C_2$}
     T(T(O_k, O_i), O_j') = T(T(O_k, O_j), O_i')\\
     \label{eqn:C2}
   \end{equation*}
   #+END_EXPORT
   where $O_j' = T(O_j, O_i)$ and $O_i' = T(O_i, O_j)$ for all $O_i, O_j, O_k
   \in \mathcal O$. It has been proved that a transformation function $T$ that
   satisfies [[ref:eqn:C1]] and ref:eqn:C2 is sufficient in order to guarantee
   convergence cite:DBLP:conf/icde/SuleimanCF98,Lushman2003303.

   In cite:DBLP:conf/ecscw/ImineMOR03, Imine et al. show, using a theorem
   prover, that neither the corrected version of $T$ from
   cite:ellis1989concurrency, or any of transformation functions from
   cite:DBLP:conf/cscw/ResselNG96,DBLP:journals/tochi/SunJZYC98,DBLP:conf/group/SuleimanCF97
   satisfies [[ref:eqn:C1]] and ref:eqn:C2. Furthermore, they propose a
   transformation of their own, which was proved correct by their theorem
   prover. Yet, in cite:DBLP:journals/corr/abs-1302-3292, they prove their own
   proposed transformation function wrong. This paper also shows that there
   does not exist a transformation function that satisfies [[ref:eqn:C1]] and
   ref:eqn:C2 without adding additional parameters to the operations.

   To the best of our knowledge, there has not been found a transformation
   function that satisfies the consistency model of Sun et al.
   cite:DBLP:journals/tochi/SunJZYC98.

[fn:1] Referred to as the /Precedence Property/ in cite:ellis1989concurrency.
[fn:2] In cite:DBLP:conf/ecscw/ImineMOR03 Imine et al. credits the finding to
cite:DBLP:journals/tochi/SunJZYC98,DBLP:conf/icde/SuleimanCF98,DBLP:conf/cscw/ResselNG96,
but we have not been able to confirm that any of them uncovered that $T$ does
not satisfy ref:eqn:C1.

** Operational Transformation with a Client-Server Architecture

   In cite:nichols95, Nichols et al. introduces a simplified algorithm for OT
   in the Jupiter Collaboration System, based on GROVE
   cite:ellis1989concurrency, leveraging a centralized server. It is a
   symmetric algorithm, in the sense that the core algorithm is the same at the
   client and the server. As in GROVE, the document is replicated at every
   client, but the server keeps an additional copy of the document. Each client
   synchronizes its changes with the server, yielding a two-way synchronization
   protocol, as opposed to the fully distributed $N\text{-way}$ synchronization
   of GROVE.

   When a client generates an operation, it is communicated to the server. On
   reception of an operation, the server applies it to its document,
   transforming it if necessary, and sends the transformed operation to the
   other clients. When a client receives an operation from the server, the
   operation is transformed if necessary, and then applied to the client's
   local copy.

   Having a server guarantees that causality violation never occurs
   cite:ellis-ot, without the need for maintaining a state vector. This is
   because all communication is done via the server, so a client will receive
   all remotely generated operations (i.e. operations it did not generate
   itself) in the order the server received them.

   In the Jupiter Collaboration System each client-server pair must store the
   operations sent until they are acknowledged by their counterpart. This is
   because new operations might need to be transformed with regards to
   non-acknowledged operations.

   The Google Wave protocol is largely based on the Jupiter Collaboration
   System cite:WaveOT. In contrast to the Jupiter Collaboration System, the
   Google Wave protocol requires that clients wait for acknowldgement before
   sending new operations. Clients may still apply changes to their local copy,
   but need to queue the operations, and send them on reception of an
   acknowldgement. This reduces the memory consumption at the server, because
   the server will only need to keep one history of operations.

* Client-side Specification and Maude

  The Shared Buffer System is formally modeled using The Maude System. Modeling
  a system is in essence capturing what can occur in the system in a precise
  manner, at a suitable level of abstraction. For instance, it is important to
  model that clients can send messages concurrently, and that there is no way
  to a priori determine the order of which they are received by the server. On
  the other hand, we merely assume that messages between a given client and the
  server are delivered in order, undamaged and without duplication, and make no
  attempt to model how this is achieved.

  Earlier work on formal verification of /Operational Transformation/ (OT)
  algorithms has been focused on verifying properties of the /transformation
  functions/ (as discussed in Section [[Discussing Consistency in OT]]), which is
  an essential part of all OT algorithms. However, there are other aspects of
  the algorithms, that are left unverified, leaning on analytical proofs by the
  original authors. Instead of writing analytical proofs we leverage formal
  methods to ensure robustness of the system.

  We aim at modeling the clients, the server and the communication between
  these, but restrict ourselves to editing sessions where all the clients have
  the same initial buffer and a constant number of connected clients. The
  Shared Buffer Algorithm is deeply embedded in the model, and therefore also
  subject of verification. To the best of our knowledge, formal verification
  techniques has not been applied on a complete real-time collaboration
  algorithm in the literature before.

  The verification technique we have chosen to apply is model checking. Proving
  properties of a finite-state system using model checking is /decidable/, but
  if the system has an infinite number of reachable states, there is no
  guarantee that the model checker will terminate. Our system is infinite as
  there can be an arbitrary number of operations, an arbitrary number of
  clients, with an infinite number of different initial buffers. If we were to
  model the system without limitations, the model checker would not necessarily
  terminate. In order to deal with this the system is modeled as a finite
  system, where the number of operations, the number of clients and an initial
  buffer are given as parameters when model checking.

  # We need to emphasize that model checking prove properties for finite-state
  # models. A buffer can be in an infinite number of states, seeing that
  # nothing prevents the user from adding another character to its buffer. If
  # our model has no bounds on the number of operations then there would be an
  # infinite number unique reachable states. This means we cannot possibly
  # prove properties of the system by model checking. However, by adding
  # boundaries to the number of operations and to the number of clients, we can
  # prove properties of the system under that that restriction. Thus, we will
  # not provide a proof that the Shared Buffer Algorithm is correct.

  # Dette avsnittet suger:
  This chapter starts of by giving a short introduction to the Maude language.
  We will then go on to describe our model; by describing the model we will
  also describe the Shared Buffer Algorithm in detail. The equations in this
  chapter are translations of the Maude specification. For rewrite rules (that
  we will introduce shortly) we use Maude syntax in favor of mathematical
  notation.

** A Short Introduction to Maude

   The Maude System consists of a programming and modeling language, as well as
   tools for exploring the state space of the model. In essence, Maude is an
   implementation of /rewriting logic/ which has been proved useful for
   modeling distributed systems cite:peter.

   A Maude specification consists of /sorts/, /signatures/, /variables/,
   /equations/ and /rewrite rules/. The sorts are simply labels that are
   associated with some data type. A signature defines a function symbol, along
   with its domains, which constitutes the values of a data type (where a
   constant is represented as a function symbol with arty zero). The values of
   a specification, which are constructed by applying function symbols with
   respect to their domains, yields what is called a /ground term/. Variables
   must be of a given sort and is essentially a placeholder for a ground term;
   a term (i.e. "non-ground") can contain variables, which is what separates it
   from a /ground/ term.

   An equation is a relation that takes a left-hand and a right-hand term; it
   symbolizes that the terms are considered equivalent. Rewriting rules are
   similar to equations, but the terms does not need to be equivalent. Rather a
   rewriting rule symbolizes that the left-hand term /may evolve/ to the
   right-hand term, and is strictly read left to right. The equations of the
   system represents the /static/ part of the system, and the rewrite rules
   represent the /dynamic/ part of the system.

   The Maude System have two fundamental commands that sheds light on how
   equations and rewriting rules operate. The /reduce/ command takes a term and
   if the term (or a subterm) matches the left-hand term of an equation, it is
   rewritten to the right hand term, and the process continues until the
   reduced term does not match any equation in the specification. The /rewrite/
   command can be given an argument deciding how many rewrites it should
   perform. It takes a term which it applies to an arbitrary rewrite rule that
   matches the left-hand term of the rule, followed by reducing the resulting
   term. The process is repeated until it has reached the specified number of
   rewrites, or if no more rewrites can be applied. It can be useful to think
   of an equation as special case of a rewrite rule which is always applied
   immediately.

   # A reduction should be deterministic, meaning that, for a given input, it
   # always yields the same term. On the other hand, a rewrite may be
   # nondeterministic

   In our specification, we use rewrite rules to describe nondeterministic
   changes in the system, like a user inserting or deleting a character from
   its buffer. The equations are used to describe the system's reaction to the
   changes in the system, which should is deterministic.

   # The equational membership logic is very similar to a functional programming
   # language, in the sense that they are both declarative and have the same
   # expressive power. By stating a set of equations we can represent any
   # /static/ part of the system, that is, the parts that for a given input
   # always yields the same output.

   # The /dynamic/ behaviour of a system is described by a set of rewriting
   # rules,

** Client-side Specification

   In Chapter [[Formal Semantics of Editing Operations]] we defined operations and
   the how they are applied. This was stated as a set of equations which has
   been translated to Maude. The Maude representation is almost identical with
   the aforementioned definitions, but operation application is syntactically
   different and have not modeled the entire $Unicode$ set, but rather chosen a
   small set of characters.

   A client consists of a user label, buffer, sequence number, state token,
   along with an incoming and outgoing message queue. The following Maude term,
   where capital letters are variables of the appropriate sort, will match any
   user:

   #+BEGIN_EXAMPLE
   < U | buffer : B, seqno : N, token : T, out-queue : Q, in-queue: Q' >
   #+END_EXAMPLE

   An example of a ground term that will match the term above can look like so:

   #+BEGIN_EXAMPLE
   < user 0 | buffer : nil, seqno : 0, token : 0,
              in-queue : nil, out-queue : nil >
   #+END_EXAMPLE

   Note that =nil= is used to represent both an empty buffer and an empty
   queue. A user may nondeterministically insert a character to its buffer,
   which is represented using a rewrite rule, where ~=>~ symbolizes the rewrite
   relation [fn:3]:

   #+BEGIN_EXAMPLE
       rl [user-inserts] :
           < U | buffer : (B B'), seqno : S, token : T, out-queue : Q >
         =>
           < U | buffer : (B C B'), seqno : s S, token : T,
                 out-queue : (msg(ins(size(B), C), T, S) Q) > .
   #+END_EXAMPLE

   The buffer is represented as =(B B')=, where both =B= and =B'= are any two
   buffers that matches the client's buffer when concatenated (where
   concatenating buffers is analogous to concatenation of strings). Note that
   the buffers may be empty. Assuming we have a character =C= (where a
   character is treated as a string of length one), an insertion is simply
   placing a character in between the two buffers, which yields a new buffer
   =(B C B')=. This rule enables =C= to be inserted at any point in the buffer,
   because we have not put any restriction on =B= and =B'= besides that they
   together form the complete buffer.

   The client must communicate its change to the server, which is modeled as
   putting a message on in its outgoing queue. A message, denoted =msg=,
   consists of an operation, a state token and a sequence number. The size of
   =B= determines the position of the insertion, and so =ins(size(B), C)=
   represents that =C= was inserted at position =size(B)=. The current state
   token =T= and sequence number =S= is added to the message. Lastly, the
   client must increment its sequence number, using the successor function =s=.
   The rule for deletion is almost identical, with the distinction of removing
   a character from the buffer, rather than inserting one, and labeling the
   operation =del=.

   The server can put messages on a client's incoming queue, which the client
   in turn (eventually) reads from. In order to model the latency of messages
   traveling, it reads from the queue in an nondeterministic manner. The
   following rewrite rule may be applied if the sequence number of the client
   is equal to the sequence number of the message at the end of its incoming
   queue:

   #+BEGIN_EXAMPLE
   rl [user-receive] :
       < U | buffer : B, seqno : S, token : T,
             in-queue : (Q msg(O,T',S)) >
     =>
       < U | buffer : apply O on B, seqno : s S, token : T',
             in-queue : Q > .
   #+END_EXAMPLE

   Notice that the variable =S= is used both as the client sequence number and
   the sequence number of the message to ensure that the sequence numbers are
   equal. On reception of a message the operation is applied to the client's
   local buffer, the sequence number is incremented and the state token of the
   message replaces the current state token of the client. Note that =apply O
   on B= is a term that will match an equation which applies the operation =O=
   to =B=. It is syntactically different from $O(B)$, which we have seen in
   previous chapters, but semantically identical.

   Similarly, there is a rule for rejecting a message, which may be applied if
   an incoming message has a sequence number that is /not/ equal to the
   sequence number of the client. In that case the message is removed from the
   queue, and the sequence number is incremented; nothing else changes.

   At this point we can try to perform rewrites on a term containing multiple
   users, and they will insert and delete characters and add messages to their
   outgoing queue. Seeing that we have not specified a server yet, they will
   not receive any messages and their outgoing queue will grow monotonically.
   Their respective buffers are likely to diverge. Here is an example of two
   users starting with an empty buffer after three rewrites:

   #+BEGIN_EXAMPLE
   < user 0 | buffer : nil, seqno : 2, token : 0, in-queue : nil,
              out-queue : (msg(del(0, a), 0, 1) msg(ins(0, a), 0, 0)) >

   < user 1 | buffer : b, seqno : 1, token : 0, in-queue : nil,
              out-queue : msg(ins(0, b), 0, 0) >
   #+END_EXAMPLE

   From the resulting term we can read that $u_0$ (i.e. =user 0=) has inserted
   an =a=, and deleted it afterwards, whilst $u_1$ has inserted a =b=.

*** Measures to Reduce the State Space

    The /state explosion problem/ is considered the main obstacle for model
    checking cite:DBLP:conf/laser/ClarkeKNZ11. When performing model checking,
    an initial state must be given; in Maude this corresponds to a term. If the
    term matches a rewrite rule, it may be applied which in turn yields a new
    state. A term can match multiple rewrite rules, so the number of reachable
    state is given by the sum how many rewrite rules the initial term matches,
    and how many rewrite rules each of the resulting terms matches and so on.
    This number may be infinite; a minimal example is a system where each state
    consists only of a natural number, which can be rewritten to the successor
    of that number --- because there is no largest natural number, the rewrite
    rule can always be applied, and so the set of reachable states is infinite.
    # The number of /reachable/ states from that term is given by all the
    # possible ways that rewrite rules can be applied. The number of reachable
    # states is often exponential with regards to the

    # --- for a model to be useful for
    # verification, the state space generally needs to be kept at a manageable
    # size.

    Our focus has been on writing a specification which accurately
    describes the system, rather than optimizing the specification for
    verification; nevertheless, some measures has been taken to reduce the
    state space and are documented here.

    In reality, a user could decide to type any arbitrary character at any
    given time; in the model, all insertions are done alphabetically, meaning
    the first insertion is always an =a=, the second is a =b= and so on. This
    is necessary in order to keep the state space at a manageable size. What
    character the user types is of no importance to the algorithm, so there is
    no need to check what would happen if, say, =b= where typed before =a=.

    Another restriction is put on which user performs an operation at a given
    time. Users are labeled because the server needs information about each
    individual user; however, if we were to swap all $u_0$ labels with $u_1$,
    it would have no effect on the scenario, as long as /all/ labels are
    swapped. It can be helpful to look at a visualized scenario and permute the
    labels at the top to see that the scenarios are symmetric, and checking
    both is redundant.

    #+BEGIN_EXPORT latex
    \begin{figure}[h]
      \centering
      \begin{subfigure}{.5\textwidth}
        \centering
        \begin{tikzpicture}[>=stealth, shorten >= 5pt, node distance=1em, scale=1]
          \tikzstyle{vertex} = [circle, scale=0.5]
          \tikzstyle{O_0} = [vertex, fill=black!30!green]
          \tikzstyle{O_1} = [vertex, fill=black!30!blue]

          \tikzstyle{to} = [-{Stealth[scale=1.2]}]
          \tikzstyle{toO_0} = [to, color=black!30!green]
          \tikzstyle{toO_1} = [to, color=black!30!blue]

          \tikzstyle{op} = [midway, above=-3pt, sloped, text=black, font=\scriptsize]

          %% Server receives operations in this order
          \node (s) at (2.5, 4) {$S$};
          \coordinate (se) at (2.5, 0) {};
          \node[O_0, below = 3em of s] (s1) {};
          \node[O_1, below = 1em of s1] (s2) {};

          %% User 0 generates/receives in this order
          \node (u0) at (0, 4) {$u_0$};
          \node (u0e) at (0, 0) {};
          \node[O_0, below = of u0] (u00) {};
          \node[O_0, above = of u01] (u00a) {};
          \node[O_1, above = 2em of u0e] (u01) {};

          %% User 1 generates/receives in this order
          \node (u1) at (5, 4) {$u_1$};
          \node (u1e) at (5, 0) {};
          \node[O_1, below = 1.5em of u1] (u11) {} ;
          \node[O_0, below = 3em of u11] (u10a) {};
          \node[O_1, above = 2em of u1e] (u11a) {};

          \begin{pgfonlayer}{bg} % select the background layer
            \draw[to, color=black!30] (s) -- (s1)  -- (s2) -- (se);
            \draw[to, color=black!30] (u0) -- (u00) -- (u01) -- (u0e);
            \draw[to, color=black!30] (u1) -- (u11) -- (u10a) -- (u1e);

            % Life of O_0
            \draw[toO_0] (u00) -- (s1) node [op] {$\overbrace{\ins{0}{a}}^{O_0}$};
            \draw[toO_0] (s1) -- (u00a) node [op] {$nop$};
            \draw[toO_0] (s1) -- (u10a) node [op, near end] {$O_0$};

            % Life of O_1
            \draw[toO_1] (u11) -- (s2) node [op] {$\overbrace{\ins{0}{b}}^{O_1}$};
            \draw[toO_1] (s2) -- (u01) node [op] {$O_1$};
            \draw[toO_1] (s2) -- (u11a) node [op] {$O_1 \circ O_0 \circ O_1^{-1}$};
          \end{pgfonlayer}
        \end{tikzpicture}
      \end{subfigure}%
      \begin{subfigure}{.5\textwidth}
        \centering
        \begin{tikzpicture}[>=stealth, shorten >= 5pt, node distance=1em, scale=1]
          \tikzstyle{vertex} = [circle, scale=0.5]
          \tikzstyle{O_0} = [vertex, fill=black!30!green]
          \tikzstyle{O_1} = [vertex, fill=black!30!blue]

          \tikzstyle{to} = [-{Stealth[scale=1.2]}]
          \tikzstyle{toO_0} = [to, color=black!30!green]
          \tikzstyle{toO_1} = [to, color=black!30!blue]

          \tikzstyle{op} = [midway, above=-3pt, sloped, text=black, font=\scriptsize]

          %% Server receives operations in this order
          \node (s) at (2.5, 4) {$S$};
          \coordinate (se) at (2.5, 0) {};
          \node[O_0, below = 3em of s] (s1) {};
          \node[O_1, below = 1em of s1] (s2) {};

          %% User 0 generates/receives in this order
          \node (u0) at (5, 4) {$u_1$};
          \node (u0e) at (5, 0) {};
          \node[O_0, below = of u0] (u00) {};
          \node[O_0, above = 3.5em of u0e] (u00a) {};
          \node[O_1, above = 2em of u0e] (u01) {};

          %% User 1 generates/receives in this order
          \node (u1) at (0, 4) {$u_0$};
          \node (u1e) at (0, 0) {};
          \node[O_1, below = 1.5em of u1] (u11) {} ;
          \node[O_0, below = 3em of u11] (u10a) {};
          \node[O_1, above = 2em of u1e] (u11a) {};

          \begin{pgfonlayer}{bg} % select the background layer
            \draw[to, color=black!30] (s) -- (s1)  -- (s2) -- (se);
            \draw[to, color=black!30] (u0) -- (u00) -- (u01) -- (u0e);
            \draw[to, color=black!30] (u1) -- (u11) -- (u10a) -- (u1e);

            % Life of O_0
            \draw[toO_0] (u00) -- (s1) node [op] {$\overbrace{\ins{0}{a}}^{O_0}$};
            \draw[toO_0] (s1) -- (u00a) node [op] {$nop$};
            \draw[toO_0] (s1) -- (u10a) node [op, near end] {$O_0$};

            % Life of O_1
            \draw[toO_1] (u11) -- (s2) node [op] {$\overbrace{\ins{0}{b}}^{O_1}$};
            \draw[toO_1] (s2) -- (u01) node [op] {$O_1$};
            \draw[toO_1] (s2) -- (u11a) node [op] {$O_1 \circ O_0 \circ O_1^{-1}$};
          \end{pgfonlayer}
        \end{tikzpicture}
      \end{subfigure}
      \caption{Permuting labels.}
      \label{fig:permuting-labels}
    \end{figure}
    #+END_EXPORT
    A scheme is imposed where $u_0$ always performs the first operation, $u_0$
    or $u_1$ performs the second, $u_0$, $u_1$ or $u_2$ performs the third, and
    so on. This corresponds to allowing the scenario to the left from Figure
    [[ref:fig:permuting-labels]] to occur, but not the scenario on the right.

    In the example at the end of the last section, three rewrites were made.
    Without the restriction of $u_0$ performing the first operation, there
    would be 49 reachable states. When imposing the scheme, only 25 different
    states can be reached within three rewrites, reducing the state space by a
    factor of 2. As the number of users grow, the reduction of states
    increases.

    # redo, du har brukt end-states ikke reachable states.
    #+CAPTION: Reachable states after three rewrites with and without restriction.
    | Number of users          | 2 users | 3 users | 4 users | 5 users | 6 users |
    |--------------------------+---------+---------+---------+---------+---------|
    | Non-restricted           |      49 |     106 |     193 |     316 |     481 |
    | Restricted               |      25 |      29 |      29 |      29 |      29 |
    | Reduction by a factor of |    1.96 |    3.66 |    6.66 |    10.9 |   16.59 |

    Note that the server only reacts to incoming messages, and never acts on
    its own accord. This is why the only measures to reduce the state space is
    done by imposing restrictions on the clients.

* Server-side Specification

  At this point the behaviour of clients has been specified. The more
  interesting part of the system is the server, as it handles most of the
  complexity in the algorithm.

  The server maintains a /state token/, a /history/ and a mapping from users
  to /sites/. For every operation received, the server increments its state
  token, which is one initially. The history determines the order of which
  operations should be applied. A /site/ is an object which represents the
  server's information about a given client; when receiving a message from a
  client, we assume that there exists a way of uniquely identifying the
  client --- in the model this is a user identifier.

** Events

   An essential part of the server algorithm is maintaining a history, where
   the entries in a history are /events/. There is only one type of event at
   the system, namely the reception of a message, containing an operation, a
   token and a sequence number.
   #+BEGIN_EXPORT latex
   \\
   \begin{definition}[Events]
     The events on a server $S$ communicating with a set of clients, identified by
     users in $\mathcal U$, is formally defined as the smallest set of four-tuples
     $\mathbb E$, where every $\tuple{O,t,m, u} \in \mathbb E$ satisisfies the
     following:
     \begin{itemize}
     \item \(O \in \mathcal O\) and $O$ is not a composition of operations
     \item \(t \in \mathbb N \land t < m\)
     \item \(m \in \mathbb N\)
     \item \(u \in \mathcal U\)\hfill$\dashv$
     \end{itemize}
   \end{definition}
   #+END_EXPORT
   # The events are constructed based on a message $msg(O, t, s)$ from $u \in
   # \mathcal U$ and a logical clock $m$ maintained on the server.
   The events are constructed based on a message received from a user and the
   state token $m$, maintained on the server. Given a message $msg(O, t, s)$
   sent from $u \in \mathcal U$ the event $\tuple{O, t, m, u}$ is constructed.
   Remember that the token $t$ is only updated at the client when it
   successfully receives a message from the server (i.e. does not reject); it
   implies that the latest message the client has received was when the
   server's state token was $t$. Furthermore, we assume that the client have
   executed all operations with a time stamp smaller than $t$.

   The history of events dictates an order of which operations should be
   applied. In the case where there are no concurrent events, the arrival time
   is used to determine what event should precede the other. But in order to
   decide an order, we first need to be able to detect concurrent operations.
   Intuitively, are two operations concurrent if they where generated
   independently from each other.
   #+BEGIN_EXPORT latex
   \\
   \begin{definition}[Concurrent Events]
     Two events $E_i = \tuple{O_i, t_i, m_i, u_i}$ and $E_j = \tuple{O_j, t_j,
       m_j, u_j}$, where $E_i, E_j \in \mathbb E$, are said to be concurrent if and
     only if:
     \[ u_i \not= u_j \land ((t_i \leq t_j \land m_i \geq t_j) \lor (t_j \leq t_i \land m_j \geq t_i)) \]
     $E_i$ is concurrent with $E_j$ is denoted $E_i \parallel E_j$.
     \hfill$\dashv$
   \end{definition}
   #+END_EXPORT

   A user cannot produce concurrent events; The first criteria of the
   definition $u_i \not= u_j$ ensures that events performed by the same user
   cannot be considered concurrent. Note that an event is not concurrent with
   itself by this definition; the case is ignored because there is never a
   need to examine the relationship between an event and itself. There are no
   duplicate events in the system, seeing that the time stamp is guaranteed to
   be unique.

   Let us now consider $t_i \leq t_j \land m_i \geq t_j$. It is helpful to read
   it as: "$O_i$ was generated at same time or before $O_j$ was generated, but
   $O_i$ arrived at the server at the same time or after $O_j$ was generated".
   If $t_i \leq t_j$ then it cannot be the case that $O_i$ was generated after
   having applied $O_j$. Similarly, if $t_j \leq m_i$ then it cannot be the
   case that $O_j$ was generated after having applied $O_i$. When the
   operations were generated independently from each other, we say they are
   concurrent. By the same reasoning, $E_j$ is concurrent with $E_i$ if $t_j
   \leq t_i \land m_j \geq t_i$, assuring symmetry.

   Given two non-concurrent events, one must have /happened before/ the other.
   Note that this /happened before/-relation is defined in terms of a state
   token and a time stamp, and does not necessarily represent which event
   happened before the other in /real/ time.
   #+BEGIN_EXPORT latex
   \\
   \begin{definition}[Happened Before]
     An event $E_i = \tuple{O_i, t_i, m_i, U_i}$ \textit{happened before} $E_j =
     \tuple{O_j, t_j, m_j, U_j}$, where $E_i, E_j \in \mathbb E$, if and only if:
     \[ E_i \nparallel E_j \land m_i < m_j \]
     $E_i$ \textit{happened before} $E_j$ is denoted $E_i \longrightarrow E_j$. \hfill$\dashv$
   \end{definition}
   #+END_EXPORT

   If the events are not concurrent, then the arrival time is used to determine
   which event happened before the other.
   #+BEGIN_EXPORT latex
   \begin{figure}[h]
     \centering
     \begin{tikzpicture}[>=stealth, shorten >= 5pt, node distance=4em, scale=1]
       \tikzstyle{vertex} = [circle, scale=0.5]
       \tikzstyle{O_0} = [vertex, fill=black!30!green]
       \tikzstyle{O_1} = [vertex, fill=black!30!blue]
       \tikzstyle{O_2} = [vertex, fill=black!30!red]

       \tikzstyle{to} = [-{Stealth[scale=1.2]}]
       \tikzstyle{toO_0} = [to, color=black!30!green]
       \tikzstyle{toO_1} = [to, color=black!30!blue]
       \tikzstyle{toO_2} = [to, color=black!30!red]

       \tikzstyle{op} = [pos=0.62, above=-3pt, sloped, text=black, font=\small]

       %% Server receives operations in this order
       \node (s) at (0, 9) {$S$};
       \coordinate (se) at (0, 0) {};
       \node[O_0, below = 2em of s,   label=left:{$\small\overbrace{\tuple{O_0, 0, 1, u_0}}^{E_0}$}] (s1) {};
       \node[O_1, below = 6em of s1,  label=left:{$\small\overbrace{\tuple{O_1, 0, 2, u_1}}^{E_1}$}] (s2) {};
       \node[O_2, above = 8em of se, label=left:{$\small\overbrace{\tuple{O_2, 2, 3, u_2}}^{E_2}$}] (s3) {};

       %% User 0 generates/receives in this order
       \node (u2) at (10, 9) {$u_0$};
       \node (u2e) at (10, 0) {};
       \node[O_0, below = 1em of u2] (u20) {};
       \node[O_0, below = 2em of u20] (u20a) {};
       \node[O_1, below = 7em of u20a] (u21a) {};
       \node[O_2, above = 3em of u2e] (u22a) {};

       %% User 1 generates/receives in this order
       \node (u0) at (8.5, 9) {$u_1$};
       \node (u0e) at (8.5, 0) {};
       \node[O_1, below = 6em of u0] (u01) {};
       \node[O_0, below = 2em of u01] (u00r) {}; % cross out
       \node[O_1, below = 3em of u00r] (u02) {};
       \node[O_2, above = 6em of u0e] (u02a) {};

       %% User 1 generates/receives in this order
       \node (u1) at (6, 9) {$u_2$};
       \node (u1e) at (6, 0) {};
       \node[O_0, below = 4.5em of u1] (u10a) {};
       \node[O_2, below = 7em of u10a] (u12) {};
       \node[O_1, below = 2em of u12] (u11r) {}; % cross out
       \node[O_2, above = 2.5em of u1e] (u12a) {};

       \begin{pgfonlayer}{bg} % select the background layer
         %\draw[to, color=black!30, text=black] (t) -- (te) node [midway, fill=white] {time};
         \draw[to, color=black!30] (s) -- (s1)  -- (s2)  -- (s3) -- (se);
         \draw[to, color=black!30] (u0) -- (u01) -- (u00r) -- (u02) -- (u02a) -- (u0e);
         \draw[to, color=black!30] (u1) -- (u10a) -- (u12) -- (u11r) -- (u12a) -- (u1e);
         \draw[to, color=black!30] (u2) -- (u20) -- (u20a) -- (u21a) -- (u22a) -- (u2e);

         % Life of O_0
         \draw[toO_0] (u20) -- (s1) node [op] {$\overbrace{\ins{0}{a}}^{O_0}$};
         \draw[toO_0] (s1) -- (u00r) node [op] {};
         \draw[toO_0] (s1) -- (u10a) node [op] {};
         \draw[toO_0] (s1) -- (u20a) node [op] {};

         % Life of O_1
         \draw[toO_1] (u01) -- (s2) node [op] {$\overbrace{\ins{1}{b}}^{O_1}$};
         \draw[toO_1] (s2) -- (u02) node [op] {};;
         \draw[toO_1] (s2) -- (u11r) node [op] {};
         \draw[toO_1] (s2) -- (u21a) node [op] {};

         % Life of O_2
         \draw[toO_2] (u12) -- (s3) node [op] {$\overbrace{\ins{0}{c}}^{O_2}$};
         \draw[toO_2] (s3) -- (u02a) node [op] {};
         \draw[toO_2] (s3) -- (u12a) node [op] {};
         \draw[toO_2] (s3) -- (u22a) node [op] {};
       \end{pgfonlayer}
     \end{tikzpicture}
     \caption{A non-trivial example.}
     \label{fig:non-trivial-happened-before/concurrency-example}
   \end{figure}
   #+END_EXPORT

   Let us look at a non-trivial example of a scenario and examine the
   relationships between events. The scenario is visualized in Figure
   [[ref:fig:non-trivial-happened-before/concurrency-example]]. We have the
   following three events:
   #+BEGIN_EXPORT latex
   \begin{align*}
     E_0 &= \tuple{O_0, t_0, m_0, u_0} = \tuple{O_0, 0, 1, u_0} \\
     E_1 &= \tuple{O_1, t_1, m_1, u_1} = \tuple{O_1, 0, 2, u_1} \\
     E_2 &= \tuple{O_2, t_2, m_2, u_2} = \tuple{O_2, 2, 3, u_2}
   \end{align*}
   #+END_EXPORT
   Their relationships are as follows:
   - $E_0 \parallel E_1$. The events were generated with the same state token, and the
     state token of $E_0$ is smaller than the arrival time of $E_1$. More
     precisely, they are concurrent because the operations are performed by
     different users and $t_0 \leq t_1 \land m_0 \geq t_1$.
   - $E_0 \longrightarrow E_2$. This is because $u_2$ received $O_0$ before
     generating $O_2$. More precisely, they are not concurrent because $t_0
     \leq t_2 \land m_0 \not\geq t_2$ and $t_2 \not\leq t_0 \land m_2 \geq
     t_0$, and $E_0 \longrightarrow E_2$ because $m_0 < m_2$.
   - $E_1 \parallel E_2$. The state token of $E_1$ is smaller than that of
     $E_2$, but the arrival time of $E_1$ the equal to the state token of
     $E_2$, meaning $O_2$ was generated before $O_1$ was received. More
     precisely, the events are performed by different users and $t_1 \leq t_2
     \land m_1 \geq t_2$.
   It can be helpful to notice that there is a correspondence between
   overlapping lines in the diagram and events being concurrent.

** An Ordering of Events

   The history maintained on the server should respect an ordering $\prec$.
   This ordering must respect the /happened before/-relation, meaning that for
   any two events $E_i, E_j \in \mathbb E$ where if $E_i \longrightarrow E_j$
   then $E_i \prec E_j$. The question that remains is how to order concurrent
   events.

   Let us first take a step back to make a useful observation. Say a character
   is inserted at point $i$ in a given buffer. The characters that were
   located at positions $0$ to $i$ (exclusive) remain at the same position ---
   the characters that were located at $i$ or higher are shifted one step to
   the right. Similarly for deletions, characters that were located at
   position $0$ to $i$ (exclusive) stay where they were, but characters
   located at point $i+1$ or higher are shifted to the left (the character
   that were at point $i$ is deleted).

   Say we have two operations $\ins{2}{x}$ and $\ins{4}{y}$ and both are
   independently applied to the buffer ="abcdef"=.
   #+BEGIN_EXPORT latex
   \begin{align*}
     \ins{2}{x} (\texttt{"abcdef"}) &= \texttt{"ab\textcolor{black!30!blue}{x}cdef"}\\
     \ins{4}{y} (\texttt{"abcdef"}) &= \texttt{"abcd\textcolor{black!30!red}{y}ef"}
   \end{align*}
   #+END_EXPORT
   Two ways of combining the operations are $\ins{4}{y} \circ \ins{2}{x}$ and
   $\ins{2}{x} \circ \ins{4}{y}$. Applying them to the buffer ="abcdef"=
   yields different results.
   #+BEGIN_EXPORT latex
   \begin{alignat*}{2}
     \ins{4}{y} \circ \ins{2}{x} (\texttt{"abcdef"})&=
     \ins{4}{y}(\texttt{"ab\textcolor{black!30!blue}{x}cdef"})&&=
     \texttt{"ab\textcolor{black!30!blue}{x}c\textcolor{black!30!red}{y}def"}\\
     \ins{2}{x} \circ \ins{4}{y} (\texttt{"abcdef"}) &=
     \ins{2}{x}(\texttt{"abcd\textcolor{black!30!red}{y}ef"})&&=
     \texttt{"ab\textcolor{black!30!blue}{x}cd\textcolor{black!30!red}{y}ef"}
   \end{alignat*}
   %% \begin{alignat*}{2}
   %%   \ins{4}{y} \circ \ins{2}{x} (\texttt{"abcdef"})&=
   %%   \ins{4}{y}(\texttt{"\textcolor{gray}{ab}x\textcolor{gray}{cdef}"})&&=
   %%   \texttt{"\textcolor{gray}{ab}x\textcolor{gray}{c}y\textcolor{gray}{def}"}\\
   %%   \ins{2}{x} \circ \ins{4}{y} (\texttt{"abcdef"}) &=
   %%   \ins{2}{x}(\texttt{"\textcolor{gray}{abcd}y\textcolor{gray}{ef}"})&&=
   %%   \texttt{"\textcolor{gray}{ab}x\textcolor{gray}{cd}y\textcolor{gray}{ef}"}
   %% \end{alignat*}
   #+END_EXPORT
   Notice that in both cases =x= was placed between =b= and =c=. On the other
   hand =y= was placed between =c= and =d= in the first case, and between =d=
   and =e= in the second. Originally =y= was placed between =d= and =e=, so we
   can assume that was the /intention/ of the user. We make the general rule,
   that when the positions of two operations differ, the operation with the
   highest position should always be performed first.

   Given two operations that operates on the same position, then deletions
   should always be performed before insertions. If the insertion is done
   first, then the delete operation would simply remove the character which
   was just inserted, which does not seem to satisfy either user. If the
   deletion is done first, the correct character is deleted and the insertion
   is placed between the characters it wanted, with the exception of the
   character immediately in front of it. Finally, if the operations are of the
   same type and operate on the same position, then the arrival time is used
   as a tiebreaker.

   The following defines when an event is said to precede another. Two
   accessor functions for operations are used, where $pos$ returns the
   position argument of the operation, and $type$ returns $ins$ or $del$,
   depending on the operation being an insertion or deletion.
   #+BEGIN_EXPORT latex
   \\
   \begin{definition}[Precedence]\label{def:prec}
     Two events $E_i = \tuple{O_i, t_i, m_i, U_i}$ and $E_j = \tuple{O_j, t_j,
       m_j, U_j}$ where $E_i, E_j \in \mathbb E$ are given. Let $p_i = pos(O_i)$,
     $p_j = pos(O_j)$, $type_i = type(O_i)$ and $type_j = type(O_j)$.
     An event $E_i$ \textit{precedes} $E_j$ if and only if:
     \[
     E_i \prec E_j =
     \begin{cases}
       p_i > p_j\\
       \text{or } (p_i = p_j \land type_i \not= type_j \land type_i = del)\\
       \text{or } (p_i = p_j \land type_i = type_j \land m_i < m_j) & \text{if } E_i \parallel E_j\\[0.5em]
       m_i < m_j & \text{otherwise}
     \end{cases}
     \]
     $E_i$ \textit{precedes} $E_j$ is denoted $E_i \prec E_j$. \hfill$\dashv$
   \end{definition}
   #+END_EXPORT
   Let us look back at the scenario from Figure
   [[ref:fig:non-trivial-happened-before/concurrency-example]]. There were three
   events:
   #+BEGIN_EXPORT latex
   \begin{align*}
     E_0 &= \tuple{O_0, t_0, m_0, u_0} = \tuple{\ins{0}{a}, 0, 1, u_0} \\
     E_1 &= \tuple{O_1, t_1, m_1, u_1} = \tuple{\ins{1}{b}, 0, 2, u_1} \\
     E_2 &= \tuple{O_2, t_2, m_2, u_2} = \tuple{\ins{0}{c}, 2, 3, u_2}
   \end{align*}
   #+END_EXPORT
   where $E_0 \parallel E_1$, $E_0 \longrightarrow E_2$ and $E_1 \parallel
   E_2$. We have the following relations:
   - $E_1 \prec E_0$ because they are concurrent and $pos(O_1) > pos(O_0)$.
   - $E_0 \prec E_2$ because they are not concurrent and $m_0 < m_2$.
   - $E_1 \prec E_2$ because they are concurrent and $pos(O_1) > pos(O_2)$.
   The only possible ordering of these three events is:
   #+BEGIN_EXPORT latex
   \[ E_1 \prec E_0 \prec E_2 \]
   #+END_EXPORT
   This scenario can only occur if the initial buffer was non-empty, seeing
   that $\ins{1}{b}$ was applied to the initial buffer; let us assume the
   initial buffer was ="f"=. From the perspective of each user:
   #+BEGIN_EXPORT latex
   \begin{multicols}{3}
     Perspective of $u_0$:
     \[ \ins{0}{a}(\texttt{"f"}) = \texttt{"af"} \]

     \columnbreak
     Perspective of $u_1$:
     \[ \ins{1}{b}(\texttt{"f"}) = \texttt{"fb"} \]

     \columnbreak
     Perspective of $u_2$:
     \[ \ins{0}{c}(\texttt{"af"}) = \texttt{"caf"} \]
   \end{multicols}
   #+END_EXPORT
   Note that the buffer of $u_2$ is different from the other two users, seeing
   that $\ins{0}{a}$ had been applied before $\ins{0}{c}$ was generated. By
   composing the operations from the events, according to the ordering, we
   would get the operation $\ins{0}{c} \circ \ins{0}{a} \circ \ins{1}{b}$. The
   result of applying the composed operation to the initial buffer is:
   #+BEGIN_EXPORT latex
   \begin{align*}
     \ins{0}{c} \circ \ins{0}{a} \circ \ins{1}{b}(\texttt{"f"}) &=\\
     \ins{0}{c} \circ \ins{0}{a}(\texttt{"fb"}) &=\\
     \ins{0}{c} (\texttt{"afb"}) &= \texttt{"cafb"}
   \end{align*}
   #+END_EXPORT
   It seems to satisfy the intent of every user; $u_0$ placed an =a= in front
   of the =f=, $u_1$ placed a =b= ahead of the =f= and $u_2$ placed a =c= in
   front of the =a=.

*** Events Under Precedence is not a Total Order

    A total order under a relation requires the relation to be antisymmetric,
    total and transitive. Antisymmetric, meaning that if $E_i$ precedes $E_j$
    then $E_j$ cannot precede $E_i$ and total, meaning that any two events are
    comparable under the precedence relation; we have found no counter example
    to either of these properties. However, the precedence relation is not
    transitive, and so an ordering under $\prec$ is not a total order, nor is
    it a partial order.

    These following three events is enough to show that $\prec$ is not
    transitive:
    #+BEGIN_EXPORT latex
    \begin{align*}
      E_0 = \tuple{\ins{0}{a}, 0, 1, u_0}\\
      E_1 = \tuple{\ins{1}{b}, 0, 2, u_0}\\
      E_2 = \tuple{\del{0}{f}, 0, 3, u_1}
    \end{align*}
    #+END_EXPORT
    The session was initiated with a buffer ="f"=. The first user ($u_0$) typed
    an =a= followed by a =b=, resulting in the buffer ="abf"=. The other user
    ($u_1$) deleted the only character in the buffer, resulting in the empty
    buffer $\epsilon$.

    We have that $E_0 \longrightarrow E_1$, $E_0 \parallel E_2$ and $E_1
    \parallel E_2$. Because $u_0$ performed both the operations from $E_0$ and
    $E_1$ we have that $E_0 \prec E_1$. $u_1$ performed a deletion at the same
    point as $u_0$ performed an insertion, so $E_2 \prec E_0$. However, $E_1
    \prec E_2$ because the operation in $E_2$ has a higher position. This means
    we have two plausible orderings:
    #+BEGIN_EXPORT latex
    \begin{align*}
      E_0 \prec E_1 \prec E_2 \\
      E_2 \prec E_0 \prec E_1
    \end{align*}
    #+END_EXPORT
    Neither satisfies transitivity, as $E_0 \not\prec E_2$ and $E_2 \not\prec
    E_1$. The problem is related to how events by the same user are totally
    ordered (i.e. always compared by a unique time stamp), but this
    information is not embedded in the event itself.

    This has two implications that we want to note. One is that we cannot
    /sort/ events based on $\prec$, nor use a standard ordered data structure,
    due to its lack of transitivity. The other is that there exists multiple
    plausible orderings of a given set of events, meaning that there are
    multiple orders where precedence relation is satisfied between each
    consecutive pair of events.

    A possible resolution to this is discussed in Future Work, Section
    [[Constructing a Total Order]]. Instead we build a history that relies on the
    given precedence relation (Definition [[ref:def:prec]]), presenting a scheme
    that takes the lack of transitivity into consideration.

** Building a History of Events

   A history of events is maintained on the server, and it dictates the order
   of which operations should be applied by every participant. It is built in
   an iterative manner, meaning that for every incoming message the new event
   is placed at some point in the history.

   The /happened before/ relation yields a partial order of events, leaving
   some events unordered, due to them being concurrent; the precedence
   relation preservers the ordering provided by the happened before relation,
   whilst trying to order the concurrent events in a way that preserves the
   users intentions.

   #+BEGIN_EXPORT latex
   \begin{figure}[h]
     \centering
     \begin{tikzpicture}[>=stealth, node distance=4em, scale=1.5]
       \tikzstyle{vertex} = [circle, draw]
       \tikzstyle{to} = [-{Stealth}]

       \node[vertex] (e0) at (0, 0) {$E_0$};
       \node[vertex] (e2) at (1, 1) {$E_2$};
       \node[vertex] (e1) at (2, 0) {$E_1$};

       \draw[to, shorten >= 1pt] (e2) -- (e0);
       \draw[to, shorten >= 1pt] (e0) -- (e1);
       \draw[to, shorten >= 1pt] (e1) -- (e2);

       \begin{pgfonlayer}{bg} % select the background layer
         \draw[rotate around={-45:(0.5,0.5)}, fill=red!30, draw=red, fill opacity=0.5] (0.5,0.5) ellipse (2.1em and 3.5em);
         \draw[rotate around={45:(1.5,0.5)}, fill=green!30, draw=green, fill opacity=0.5] (1.5,0.5) ellipse (2.1em and 3.5em);
       \end{pgfonlayer}
     \end{tikzpicture}
     \caption{Precedence relation.}
     \label{fig:precedence}
   \end{figure}
   #+END_EXPORT

   Figure [[ref:fig:precedence]] illustrates the example from the last section.
   The precedence relation is visualized by edges between the nodes; events
   that are concurrent are grouped. Notice that the precedence relation shows
   a cycle. The problem that needs to be solved, is choosing a path that
   visits every node exactly once, such that the precedence relation is
   satisfied between each pair of consecutive nodes. As discussed in the
   previous section, there are two possibilities in this example.

   The history is a list of events, where the head of the list is the most
   recent event, according to the precedence relation $\prec$. In other words
   it is a list where the successor relation $\succ$ holds between each pair of
   consecutive events (where $\succ$ is defined as the inverse relation of
   $\prec$). The main reason for ordering the history by the successor (rather
   than the precedence) relation is performance. If there are no conflicts,
   every new event will be inserted at the head of the list. Assuming a fairly
   fast internet connection and the (comparably) slow pace of human typing,
   this is by far the most likely scenario. Adding events by the precedence
   relation would give linear time in the most likely scenario, but using the
   successor relation we can often avoid traversing the entire history.

   When adding an event $E$ to a history $H$, we could just add $E$ to the
   first position where $E$ succeeds the event to its right (if there is no
   conflict this would be the head of the list). However, in the example
   visualized in Figure [[ref:fig:precedence]], this approach would break user
   intent. We have not found a way to completely avoid breaking user intent,
   but we have found a way to make it less frequent (see Section SECTION). The
   idea is to find the first event (i.e. the most recent) that is not
   concurrent with the event that is being added, and let the event skip past
   events until it precedes the event to its left.

   A function $collect$ collects all events until it finds one that is not
   concurrent with $E$; its dual, $drop$, skips all events until it finds one
   that is not concurrent and returns the remaining history (including the
   event it found). A function $put$, and a helper function $put'$, are defined
   in order to place the event at a suitable position in the history. It is
   defined here; note that $nil$ represents an empty history and white space is
   used to represent concatenation of lists and events (where events are
   treated as singleton lists under concatenation).
   #+BEGIN_EXPORT latex
   \begin{alignat*}{2}
     &put(E, H) &&= put'(E, collect(E, H))\ drop(E, H) \\
     &put'(E, nil) &&= E\\
     &put'(E, H\ E') &&=
     \begin{cases}
       H\ E'\ E       & \text{if } E \prec E'\\
       put'(E, H)\ E' & \text{otherwise}
     \end{cases}
   \end{alignat*}
   #+END_EXPORT
   We can now look at an example where we build a history with the three
   events $E_0$, $E_1$ and $E_2$ from the last section.
   #+BEGIN_EXPORT latex
   \begin{alignat*}{3}
     &put(E_0, nil)      &&= put'(E_0, nil)      &&= E_0 \\
     &put(E_1, E_0)      &&= put'(E_1, nil)\ E_0  &&= E_1\ E_0\\
     &put(E_2, E_1\ E_0) &&= put'(E_2, E_1\ E_0) &&= E_1\ E_0\ E_2
   \end{alignat*}
   #+END_EXPORT
   In the first equation the history is empty, and so there is no choice where
   to put $E_0$. When adding $E_1$ there is only one element in the history,
   namely $E_0$, which is performed by the same user --- $collect$ returns
   $nil$ and $drop$ returns a singleton list containing $E_0$. In the last
   equation $collect$ collects the entire history, and $E_2$ is first compared
   with $E_0$ which it precedes, and is therefore added to the end of the
   history.

** Transform the History

   Thus far we have found a way to construct a history of events such that
   every operation is represented in the history and greatly reduces the number
   of inconsistencies that can arise. Our hope was that this approach would be
   sufficient to handle all conflicts, but it turns out that there can still
   arise inconsistencies between clients. Using Maude to analyze the system
   uncovered that $0.7\%$ of states in the system, given a buffer of size two
   and 3 operations are inconsistent. To deal with the remaining portion of
   inconsistent states we apply transformation functions (discussed in Chapter
   [[Related Work]]).

   The following example consists of a set of events where the history does
   not provide a correct result.
   #+BEGIN_EXPORT latex
   \begin{alignat*}{2}
     E_0 &= \tuple{O_0, t_0, m_0, u_0} &&=\tuple{\ins{0}{a}, 0, 1, u_0}\\
     E_1 &= \tuple{O_1, t_1, m_1, u_0} &&=\tuple{\ins{2}{b}, 0, 2, u_0}\\
     E_2 &= \tuple{O_2, t_2, m_2, u_1} &&=\tuple{\del{0}{f}, 0, 3, u_1}
   \end{alignat*}
   #+END_EXPORT
   The ordering decided by the algorithm from the last section is:
   #+BEGIN_EXPORT latex
   \[ E_2 \prec E_0 \prec E_1 \]
   #+END_EXPORT
   The problem is that executing the operation $O_2 \circ O_0 \circ O_1$,
   obtained from the ordering, is not possible to execute on the initial buffer
   ="f"=. The =f= is deleted, then an =a= at the beginning of the buffer, and
   finally a =b= is attempted to be inserted at position $2$, which is beyond
   the bounds of the buffer. The reason that this occurs is that the first
   deletion /shrinks/ the buffer, but no measure is taken to make sure that the
   position of $O_2$ is decremented accordingly. This problem can be resolved
   by transforming the operations.

   We use two types of transformation functions, namely inclusion and
   exclusion; an inclusion transformation function is the kind we discussed in
   Chapter [[Related Work]]. Given two operations $O_i, O_j \in \mathcal O$, then
   an inclusion transformation of $O_i$ with regards to $O_j$ can be
   understood as "$O_i$ as if $O_j$ had already been applied". Exclusion
   transformation is the reverse, and transforming $O_i$ with regards to $O_j$
   can be understood as "$O_i$ as if $O_j$ had not been applied".

   Due to our ordering, we only need to transform against deletions to
   guarantee eventual consistency. It is however possible that including the
   complete set of transformations would better preserve user intent --- due
   to time restrictions we have not been able to verify this.

   We define two functions $it$ and $et$, where $it$ is the inclusion
   transformation function and $et$ is the exclusion transformation function.
   $it$ is derived from the (corrected) transformation from Figure
   [[ref:fig:transformation-function]] (page [[pageref:fig:transformation-function]]),
   whereas $et$ is derived from cite:sun1998reversible. Furthermore we define
   both $it$ and $et$ for composed operations, which is derived from
   cite:formalOT.

   One alteration has been made. When applying an inclusion transformation on
   two deletions with the same position the result is $nop$. To reverse this
   effect, $et$ must be able to retrieve the deletion that was omitted (i.e.
   transformed to $nop$). Using an exclusion transformation on $nop$ cannot be
   done, because it contains no information about what character was deleted.
   In cite:sun1998reversible this is handled by keeping a lookup table. Instead
   we store the information in the $nop$ object itself, by letting $nop$
   (optionally) contain an operation; its semantics is not changed, meaning
   applying $nop$ has no effect regardless.

   Note that the following equations, defining $it$ and $et$, uses the word
   /otherwise/ as it is used in Maude. It means that if none of the above
   equations covers a particular case, then it is covered by the equation
   tagged with otherwise. This is important for the last case, which would
   match all operations if not for this use of otherwise. $it$ is defined as
   follows:
   #+BEGIN_EXPORT latex
   \begin{align*}
     it(\ins{p1}{c1}, \del{p2}{c2}) &=
     \begin{cases}
       \ins{p1}{c1}   & \text{if } p1 \leq p2 \\
       \ins{p1-1}{c1} & \text{otherwise}
     \end{cases}
     \\
     it(\overbrace{\del{p1}{c1}}^{O_i}, \overbrace{\del{p2}{c2}}^{O_j}) &=
     \begin{cases}
       \del{p1}{c1}                         & \text{if }      p1 < p2 \\
       \del{p1-1}{c1}                       & \text{else if } p1 > p2 \\
       nop(O_i \circ O_j) & \text{otherwise}\\
     \end{cases}
     \\
     it(O_i, O_j \circ O_k) &= it(it(O_i, O_k), O_j) \text{\quad\ \ if $O_j$ is not composed}
     \\
     it(O_i, O_j) &= O_i \text{\qquad\qquad\qquad\quad\ \ otherwise}
   \end{align*}
   #+END_EXPORT
   The exclusion transformation is defined in a similar manner, where a
   position is incremented to reverse the effect of an inclusion
   transformation. In the cases where an inclusion transformation would omit an
   operation, the exclusion transformation retrieves the operation.
   #+BEGIN_EXPORT latex
   \begin{align*}
     et(\ins{p1}{c1}, \del{p2}{c2}) &=
     \begin{cases}
       \ins{p1}{c1}   & \text{if } p1 \leq p2 \\
       \ins{p1+1}{c1} & \text{otherwise}
     \end{cases}
     \\
     et(\del{p1}{c1}, \del{p2}{c2}) &=
     \begin{cases}
       \del{p1}{c1}   & \text{if }      p1 < p2 \\
       \del{p1+1}{c1} & \text{otherwise} \\
     \end{cases}
     \\
     et(nop(O_i \circ O_j), O_j) &= O_i
     \\
     et(O_i, O_j \circ O_k) &= et(et(O_i, O_j), O_k) \text{\quad\ \ if $O_j$ is not composed}
     \\
     et(O_i, O_j) &= O_i \text{\qquad\qquad\qquad\quad\ \ \ otherwise}
   \end{align*}
   #+END_EXPORT
   These transformation functions are used to "fix up" the history after a new
   event has been added. The inclusion transformations assumes that two
   operations were generated from the same state (i.e. the same buffer)
   cite:sun1998reversible, but this is not always the case. To deal with these
   cases, exclusion transformations is used to "reset" the operation to a
   agreed upon state, then perform inclusion transformations on this operation,
   and finally, we perform the inclusion transformations for the effects that
   were excluded.

   Given an event $E = \tuple{O, t, m, u}$ the events that will have effected
   $O$ can be found. These are the events with a smaller time stamp than $m$,
   or have the same user $u$ that occur at an earlier point in the history. The
   event must be "reset" to an agreed upon state, which is decided by the event
   with the smallest token which is concurrent with $E$. In order to use
   transformations on multiple events, the operations of a history can be
   composed using the $compose$ function. It is defined as:
   #+BEGIN_EXPORT latex
   \begin{alignat*}{2}
     &compose(nil) &&= nop\\
     &compose(\tuple{O, t, m, u}\ H) &&= O \circ compose(H)
   \end{alignat*}
   #+END_EXPORT
   We define a function $fix$ which takes a history and returns a "fixed up"
   version of the history:

   #+BEGIN_EXPORT latex
   \begin{align*}
     &fix(nil) = nil \\
     &fix(\tuple{O, t, m, u}\ H) = \tuple{O_{fixed}, t, m, u}\ H'\\
     &\begin{aligned}
        \text{where }
        &H'      &&= fix(H) \\
        &E       &&= \tuple{O, t, m, u}\\
        &H_c     &&= \text{filter $H'$, only keep events that are concurrent with $E$}\\  % filter(\tuple{O, t, n, u}, H') \\
        %% &t_{min}  &&= \text{get the smallest token from events in $H_c$}\\
        %% &O_e     &&= \text{compose operations that have effected $O$ (with token $t_{min}$ or greater)}\\
        &O_e     &&= \text{compose operations that have effected $O$}\\
        &O_{fixed} &&= it(it(et(O, O_e), compose(H_c)), O_e) \\
      \end{aligned}&&
   \end{align*}
   #+END_EXPORT
   By making sure the $fix$ function is applied to the history after each
   insertion, we ensure that composing the entire history can always be safely
   applied to the initial buffer. What remains is to ensure that each client
   eventually will apply the operations of the history.

** Ensuring Consistency

   After having gone into great depths on how to construct a history, the
   question of getting all clients to conform to this history still remains.
   This section concludes the specification of the server-side algorithm, and
   shows how the history, and properties of editing operations, are leveraged
   to guarantee eventual consistency. The only nondeterministic behaviour at
   the server is the reception of a message; this section describes the
   server's /reaction/ to incoming messages.

   Messages from the server are on exactly the same form as messages from a
   client, namely a $msg(O, t, s)$ where $O$ is an operation, $t$ is a token
   and $s$ is a sequence number. When a client receives a message, the
   operation is only applied if the sequence number of the message $s$ is equal
   to the client's local sequence number. If the client applies the operation,
   then it is guaranteed to be consistent with the history at time $t$. Being
   consistent with the history at time $t$ is defined as: Compose the history
   as it was when the server's state token was $t$; if this operation is
   applied to the initial buffer and the resulting buffer is equal to the
   client's buffer, then the client is consistent with the history at time $t$.

   On each reception the server sends a response to every connected client. The
   server constructs two operations, one to the client who sent the message and
   another to every other client. The token is the same in every message. The
   sequence number may vary for each client.

*** Sequence Number Scheme

    Remember that a client always increments its sequence number after it
    performs an operation or receives a message from the server. Say we have a
    set of users $U$ who identify each connected client. The server keeps a
    sequence number $s_u \in \mathbb N$ for each participant $u \in U$,
    initialized at zero.

    When a message is received from a client identified by $u \in U$, the
    server sends messages to every connected client, each of which contains a
    sequence number. For each client identified by the users in $u' \in U
    \setminus \{u\}$, the stored sequence number $s_{u'}$ is used, and
    incremented after the message is sent. It is incremented because the client
    will increment its sequence number at reception of the message, and will
    therefore expect a higher sequence number the next time it receives a
    message.

    #+BEGIN_EXPORT latex
    \begin{wrapfigure}[21]{r}{0pt}
      \centering
      \begin{tikzpicture}[>=stealth, shorten >= 1pt, node distance=1em, scale=1]
        \tikzstyle{vertex} = [circle, scale=0.3]
        \tikzstyle{O_0} = [vertex, fill=black!30!green]
        \tikzstyle{O_1} = [vertex, fill=black!30!blue]
        \tikzstyle{O_2} = [vertex, fill=black!30!red]

        \tikzstyle{to} = [-{Stealth[scale=1]}]
        \tikzstyle{toO_0} = [to, color=black!30!green]
        \tikzstyle{toO_1} = [to, color=black!30!blue]
        \tikzstyle{toO_2} = [to, color=black!30!red]

        \tikzstyle{op} = [near start, above=-3pt, sloped, text=black, font=\scriptsize]

        %% Server receives operations in this order
        \node[font=\scriptsize] (s) at (4, 7.5) {$S$};
        \coordinate (se) at (4, 0) {};

        \node[O_0, below = 2em of s, label={[font=\scriptsize, align=center]right:$s_u = 0$\\\\$s_u = 2$}] (s1) {};

        \node[O_1, below = 4.5em of s1, label={[font=\scriptsize, align=center]right:\\\\$s_u = 4$}] (s2) {};
        \node[O_2, below = of s2, label={[font=\scriptsize, align=center]right:\\\\$s_u = 6$}] (s3) {};
        \node[O_0, below = of s3, label={[font=\scriptsize, align=center]right:\\\\$s_u = 8$}] (s4) {};

        \node[O_1, below = 6em of s4, label={[font=\scriptsize, align=center]right:\\\\$s_u = 10$}] (s5) {};

        %% User 0 generates/receives in this order
        \node[font=\scriptsize] (u0) at (0, 7.5) {$u_0$};
        \node (u0e) at (0, 0) {};

        %% \node[O_0, below = 1em of u0, label={[font=\scriptsize, align=center]left:0\\\\1}] (u00) {};
        %% \node[O_0, below = 2em of u00, label={[font=\scriptsize, align=center]left:\\\\2}] (u01) {};

        %% \node[O_1, below = 1em of u01, label={[font=\scriptsize, align=center]left:\\\\3}] (u02) {};
        %% \node[O_2, below = of u02, label={[font=\scriptsize, align=center]left:\\\\4}] (u03) {};
        %% \node[O_0, below = of u03, label={[font=\scriptsize, align=center]left:\\\\5}] (u04) {};

        %% \node[O_1, below = 3em of u04, label={[font=\scriptsize, align=center]left:\\\\6}] (u05) {};
        %% \node[O_2, below = of u05, label={[font=\scriptsize, align=center]left:\\\\7}] (u06) {};
        %% \node[O_0, below = of u06, label={[font=\scriptsize, align=center]left:\\\\8}] (u07) {};

        %% \node[O_1, below = 1em of u07, label={[font=\scriptsize, align=center]left:\\\\9}] (u08) {};
        %% \node[O_1, below = 2em of u08, label={[font=\scriptsize, align=center]left:\\\\10}] (u09) {};
        \node[O_0, below = 1em of u0, label={[fill=white, font=\tiny, align=center]above left:0}] (dummy) {};
        \node[O_0, below = 1em of u0, label={[fill=white, font=\tiny, align=center]below left:1}] (u00) {};
        \node[O_0, below = 2em of u00, label={[fill=white, font=\tiny, align=center]below left:2}] (u01) {};

        \node[O_1, below = 1em of u01, label={[fill=white, font=\tiny, align=center]below left:3}] (u02) {};
        \node[O_2, below = of u02, label={[fill=white, font=\tiny, align=center]below left:4}] (u03) {};
        \node[O_0, below = of u03, label={[fill=white, font=\tiny, align=center]below left:5}] (u04) {};

        \node[O_1, below = 3em of u04, label={[fill=white, font=\tiny, align=center]below left:6}] (u05) {};
        \node[O_2, below = of u05, label={[fill=white, font=\tiny, align=center]below left:7}] (u06) {};
        \node[O_0, below = of u06, label={[fill=white, font=\tiny, align=center]below left:8}] (u07) {};

        \node[O_1, below = 1em of u07, label={[fill=white, font=\tiny, align=center]below left:9}] (u08) {};
        \node[O_1, below = 2em of u08, label={[fill=white, font=\tiny, align=center]below left:10}] (u09) {};

        \begin{pgfonlayer}{bg} % select the background layer
          \draw[to, color=black!30] (s) -- (se);
          \draw[to, color=black!30] (u0) -- (u0e);

          %% From client
          \draw[toO_0] (u00) -- (s1) node [op] {$s = 0$};
          \draw[toO_1] (u02) -- (s2) node [op] {$s = 2$};
          \draw[toO_2] (u03) -- (s3) node [op] {$s = 3$};
          \draw[toO_0] (u04) -- (s4) node [op] {$s = 4$};
          \draw[toO_1] (u08) -- (s5) node [op] {$s = 8$};
          %% \draw[toO_0] (u00) -- (s1) node [op, pos=0.25] {$msg(O_0, 0, 0)$};
          %% \draw[toO_1] (u02) -- (s2) node [op, pos=0.25] {$msg(O_1, 2, 2)$};
          %% \draw[toO_2] (u03) -- (s3) node [op, pos=0.25] {$msg(O_2, 2, 3)$};
          %% \draw[toO_0] (u04) -- (s4) node [op, pos=0.25] {$msg(O_3, 2, 4)$};
          %% \draw[toO_1] (u08) -- (s5) node [op, pos=0.25] {$msg(O_4, 5, 8)$};

          %% From server
          \draw[toO_0] (s1) -- (u01) node [op, near end] {$s = 1$};
          \draw[toO_1] (s2) -- (u05) node [op, near end] {$s = 3$};
          \draw[toO_2] (s3) -- (u06) node [op, near end] {$s = 5$};
          \draw[toO_0] (s4) -- (u07) node [op, near end] {$s = 7$};
          \draw[toO_1] (s5) -- (u09) node [op, near end] {$s = 9$};

          %% \draw[toO_0] (s1) -- (u01) node [op, pos=0.75] {$msg(O_0', 2, 1)$};
          %% \draw[toO_1] (s2) -- (u05) node [op, pos=0.75] {$msg(O_1', 3, 3)$};
          %% \draw[toO_2] (s3) -- (u06) node [op, pos=0.75] {$msg(O_2', 4, 5)$};
          %% \draw[toO_0] (s4) -- (u07) node [op, pos=0.75] {$msg(O_3', 5, 7)$};
          %% \draw[toO_1] (s5) -- (u09) node [op, pos=0.75] {$msg(O_4', 6, 9)$};
        \end{pgfonlayer}
      \end{tikzpicture}
      \caption{Sequence number scheme.}
      \label{fig:seqno-scheme}
    \end{wrapfigure}
    #+END_EXPORT

    When a message $msg(O, t, s)$ is received from a client identified by $u$,
    then the response to this client will contain a sequence number determined
    by the function $nextSeq$:
    #+BEGIN_EXPORT latex
    \begin{align*}
      nextSeq(s_u, s) = s_u + 1 + (s_u - s)
    \end{align*}
    #+END_EXPORT
    If there is no conflict then $s = s_u$, and so the response will just be
    the sequence number of the message incremented by one. It is incremented by
    one because sending the messages will have caused the client to increment
    its sequence number. If there is a conflict, then $u$ must have performed
    one or more operations between the time the server sent the last message
    and the client received it. The difference $s_u - s$ is the precise number
    of operations that $u$ has performed in this time span. Because each of
    these operations has caused the client's sequence number to increase, the
    difference is added in order to match the sequence number of the client.

    After the server has sent a response to the client, $s_u$ is set to $s_u =
    nextSeq(s_u, s) + 1$. The extra one is added because the reception of the
    message will (again) cause the client's sequence number to be incremented.

    The main benefits of this scheme are that it remains very simple on the
    client side (seeing that it only increments after every send or receive)
    and that it guarantees that clients do not perform operations from the
    server which are based on outdated information. Instead the client rejects
    messages for the duration of a conflict with the server. The disadvantage
    is that the system is not responsive during long lasting conflicts, which
    may arise if a users, for instance, holds down a button on her keyboard for
    a long time. However, it seems reasonable to assume that such situations
    are unlikely to occur, and even less likely to cause problems in practical
    uses of the system.

*** Constructing Operations

    When the server receives a message $msg(O, t, s)$ two operations are
    constructed; one for the client who sent the message, and one for all the
    other clients. We will discuss the message that is sent to all other
    clients first.

    If the message was sent by a client identified by $u \in U$ and the message
    is received at time $m$, then it is assumed that all clients identified by
    some $u' \in U \setminus \{u\}$ is consistent with the history at time $m$.
    The event $\tuple{O, t, m, u}$ is added to the history $H$, constructing a
    new history $H'$. A new message is constructed on the basis of $H$ and
    $H'$.

    If the new event is added to the beginning of the history (i.e. the most
    recent), then the constructed operation will always be $O$ itself. Let us
    say $O$ is in conflict with another operation $O_i$, with a lower position,
    then $O$ must applied before the operation with the lower position is
    applied. Since it is assumed that the clients have already applied $O_i$,
    this must be undone before. When this is done, $O$ may be applied followed
    by $O_i$.

    A function $until$ takes a history and a token, finds the earliest event
    that arrived at time greater or equal to the given token. It is defined as
    follows:
    #+BEGIN_EXPORT latex
    \begin{align*}
      &until(nil, t) = nil\\
      &until(H\ \tuple{O, t', m, u}, t) =
      \begin{cases}
        H\ \tuple{O, t', m, u} & \text{if } m \geq t\\
        until(H, t) & \text{otherwise}
      \end{cases}
    \end{align*}
    #+END_EXPORT
    Now we can define a function $makeOp$, which takes two histories and a
    token. It is presumably called with the history $H$ (as it was at time $m$,
    before the new event was added), and the history with the new event added
    $H'$, along with the token $t$. It is defined as follows:
    #+BEGIN_EXPORT latex
    \[ makeOp(H', H, t) = compose(until(H', t)) \circ compose(until(H, t))^{-1} \]
    #+END_EXPORT
    This operation will first undo operations that occurred at time $t$ or
    later, followed by the operations from the updated history (at time $t$ or
    later). As we discussed in [[Invertibility]], redundant operations on the form
    $O_i^{-1} \circ O_i$ can be omitted, which should be done (but is not
    strictly necessary) before the operation is sent.

    The message $msg(makeOp(H', H, t), m+1, s_{u'})$ is sent to all clients
    identified by some $u' \in U \setminus \{u\}$, where $s_{u'}$ may vary
    depending on the recipient. For each of these clients, the server keeps a
    mapping from $u'$ to a list of pairs, containing an operation and a
    token [fn:4]. The operation and token is added to the head of this list
    after sending the message.

    The second case to consider is what to send to the client, identified by
    $u$, that originally sent the message $msg(O, t, s)$. If there is no
    conflict, then the constructed operation is always $nop$. It is important
    to note that if a conflict has arisen, it can only be because the client
    has performed operations in the time between the server last sent it a
    message, and the time the client received it. The token $t$ indicates that
    the client was consistent with the history at time $t$.
    # The token $t$ shows at what point the client last accepted a message from
    # the server (i.e. received and did not reject).

    Because every operation (along with a token indicating what time it was
    sent) that is sent to the client is stored, the operations the client have
    rejected is retrievable. It has rejected all operations with a
    corresponding token that is strictly greater than $t$. These operations
    have to be represented in the response.

    The idea is to always make the client undo the operation $O$, then perform
    all the operations that it has rejected, and finally perform the operation
    that is sent to every other client (the operation constructed by $makeOp$).
    If there is no conflict, then the operation constructed by $makeOp$ is
    simply $O$ and there are no operations stored operations to compose; the
    resulting operation is $O \circ O^{-1}$ which is equal to $nop$.

    A simple helper function $rejected$ is used. It takes a list of pairs
    (where each pair contains an operation and a token) $R$ and a token $t$.
    The function returns the pairs with token strictly greater than $t$.
    Composing the resulting list is analogous to composing a history. The
    operation sent to the client who sent the message $msg(O, t, s)$ is given
    by a function $makeResponse$ that takes four arguments: The received
    operation $O$, the operation $makeOp(H', H, t)$, the list that contains
    rejected operations (along with the corresponding tokens) and the token $t$
    as argument.
    #+BEGIN_EXPORT latex
    \[ makeResponse(O, O', R, t) = O' \circ compose(rejected(R, t)) \circ O^{-1} \]
    #+END_EXPORT
    This operation can safely be applied by the client who sent the message
    $msg(O, t, s)$, and will make the client consistent with the history at
    time $m+1$.

    The last remaining detail is regarding the list of rejected operations
    (along with the corresponding token). The operation from $makeResponse$
    ensures that previously rejected operations are performed; it is very
    important not to perform these rejected operations again if a new conflict
    arises. The solution is to replace the list with a singleton list, only
    containing the operation constructed by $makeResponse$ and the token $m+1$.

**** A Summarizing Example

     Let us revisit the example from Figure [[ref:fig:non-trivial-complete]], where
     we include the operations that are sent to each client. The events
     received on the server is:
     #+BEGIN_EXPORT latex
     \begin{align*}
       E_0 &= \tuple{O_0, t_0, m_0, u_0} = \tuple{\ins{0}{a}, 0, 1, u_0} \\
       E_1 &= \tuple{O_1, t_1, m_1, u_1} = \tuple{\ins{1}{b}, 0, 2, u_1} \\
       E_2 &= \tuple{O_2, t_2, m_2, u_2} = \tuple{\ins{0}{c}, 2, 3, u_2}
     \end{align*}
     #+END_EXPORT
     The server decides on an ordering $E_1 \prec E_0 \prec E_2$, which means
     that all clients must perform the operation $O_2 \circ O_0 \circ O_1$. By
     composing all operations sent to a given client, we can calculate what
     operation they perform.
    #+BEGIN_EXPORT latex
    \begin{figure}[h]
      \centering
      \begin{tikzpicture}[>=stealth, shorten >= 5pt, node distance=4em, scale=1]
        \tikzstyle{vertex} = [circle, scale=0.5]
        \tikzstyle{O_0} = [vertex, fill=black!30!green]
        \tikzstyle{O_1} = [vertex, fill=black!30!blue]
        \tikzstyle{O_2} = [vertex, fill=black!30!red]

        \tikzstyle{to} = [-{Stealth[scale=1.2]}]
        \tikzstyle{toO_0} = [to, color=black!30!green]
        \tikzstyle{toO_1} = [to, color=black!30!blue]
        \tikzstyle{toO_2} = [to, color=black!30!red]

        \tikzstyle{op} = [near end, above=-3pt, sloped, text=black, font=\small]

        %% Server receives operations in this order
        \node (s) at (0, 11) {$S$};
        \coordinate (se) at (0, -1) {};
        \node[O_0, below = 2em of s,   label=left:{$\small\overbrace{\langle O_0, 0, 1, u_2 \rangle}^{E_0}$}] (s1) {};
        \node[O_1, below = 6em of s1,  label=left:{$\small\overbrace{\langle O_1, 0, 2, u_0 \rangle}^{E_1}$}] (s2) {};
        \node[O_2, above = 12em of se, label=left:{$\small\overbrace{\langle O_2, 2, 3, u_1 \rangle}^{E_2}$}] (s3) {};

        %% %% Time
        %% \node (t) at (-2, 9.5){};
        %% \coordinate (te) at (-2, 0.2) {};

        %% User 0 generates/receives in this order
        \node (u0) at (6, 11) {$u_0$};
        \node (u0e) at (6, -1) {%% $\texttt{cbfa}$
        };
        \node[O_1, below = 6em of u0] (u01) {};
        \node[O_0, below = 2em of u01] (u00r) {}; % cross out
        \node[O_1, below = 3em of u00r] (u01a) {};
        \node[O_2, above = 10em of u0e] (u02a) {};

        %% User 1 generates/receives in this order
        \node (u1) at (8.5, 11) {$u_1$};
        \node (u1e) at (8.5, -1) {%% $\texttt{cbfa}$
        };
        \node[O_0, below = 4.5em of u1] (u10a) {};
        \node[O_2, below = 8em of u10a] (u12) {};
        \node[O_1, below = of u12] (u11r) {}; % cross out
        \node[O_2, above = 2em of u1e] (u12a) {};

        %% User 2 generates/receives in this order
        \node (u2) at (10, 11) {$u_2$};
        \node (u2e) at (10, -1) {%% $\texttt{cbfa}$
        };
        \node[O_0, below = 1em of u2] (u20) {};
        \node[O_0, below = 6em of u20] (u20a) {};
        \node[O_1, below = 2.5em of u20a] (u21a) {};
        \node[O_2, above = 6em of u2e] (u22a) {};

        \begin{pgfonlayer}{bg} % select the background layer
          %\draw[to, color=black!30, text=black] (t) -- (te) node [midway, fill=white] {time};
          \draw[to, color=black!30] (s) -- (s1)  -- (s2)  -- (s3) -- (se);
          \draw[to, color=black!30] (u0) -- (u01) -- (u00r) -- (u01a) -- (u02a) -- (u0e);
          \draw[to, color=black!30] (u1) -- (u10a) -- (u12) -- (u11r) -- (u12a) -- (u1e);
          \draw[to, color=black!30] (u2) -- (u20) -- (u20a) -- (u21a) -- (u22a) -- (u2e);

          % Life of O_0
          \draw[toO_0] (u20) -- (s1) node [op] {$\overbrace{\ins{0}{b}}^{O_0}$};
          \draw[toO_0] (s1) -- (u00r) node [op, midway] {$O_0$};
          \draw[toO_0] (s1) -- (u10a) node [op] {$O_0$};
          \draw[toO_0] (s1) -- (u20a) node [op] {$nop$};

          % Life of O_1
          \draw[toO_1] (u01) -- (s2) node [op] {$\overbrace{\ins{1}{a}}^{O_1}$};
          \draw[toO_1] (s2) -- (u01a) node [op] {$O_0$};
          \draw[toO_1] (s2) -- (u11r) node [op, midway] {$O_0 \circ O_1 \circ O_0^{-1}$};
          \draw[toO_1] (s2) -- (u21a) node [op] {$O_0 \circ O_1 \circ O_0^{-1}$};

          % Life of O_2
          \draw[toO_2] (u12) -- (s3) node [op] {$\overbrace{\ins{0}{c}}^{O_2}$};
          \draw[toO_2] (s3) -- (u02a) node [op] {$O_2$};
          \draw[toO_2] (s3) -- (u12a) node [op] {$O_2 \circ \overbrace{O_0 \circ O_1 \circ O_0^{-1}}^{\text{rejected}} \circ O_2^{-1}$};
          \draw[toO_2] (s3) -- (u22a) node [op] {$O_2$};
        \end{pgfonlayer}
      \end{tikzpicture}
      \caption{The events are ordered $E_1 \prec E_0 \prec E_2$.}
      \label{fig:non-trivial-complete}
    \end{figure}
    #+END_EXPORT

     From the perspective of $u_0$:
     - $O_1$ is generated,
     - $O_0$ is received,
     - $O_2$ is received.
     The composition of these operations yields the operation $O_2 \circ O_0
     \circ O_1$.

     From the perspective of $u_1$:
     - $O_0$ is received,
     - $O_2$ is generated,
     - $O_0 \circ O_1 \circ O_0^{-1}$ is received, but rejected,
     - $O_2 \circ O_0 \circ O_1 \circ O_0^{-1} \circ O_2^{-1}$ is received.
     The composition of the operations (excluding the rejected operation)
     yields:
     #+BEGIN_EXPORT latex
     \begin{align*}
       O_2 \circ O_0 \circ O_1 \circ O_0^{-1} \circ \overbrace{O_2^{-1} \circ O_2}^{nop} \circ O_0 &= \\
       O_2 \circ O_0 \circ O_1 \circ \overbrace{O_0^{-1} \circ O_0}^{nop} &= O_2 \circ O_0 \circ O_1
     \end{align*}
     #+END_EXPORT

     Lastly, from the perspective of $u_2$:
     - $O_0$ is generated,
     - $O_0 \circ O_1 \circ O_0^{-1}$ is received,
     - $O_2$ is received.
     The composition of the operations yields:
     #+BEGIN_EXPORT latex
     \begin{align*}
       O_2 \circ O_0 \circ O_1 \circ \overbrace{O_0^{-1} \circ O_0}^{nop} &= O_2 \circ O_0 \circ O_1
     \end{align*}
     #+END_EXPORT

** Summary

   This chapter is in essence a comprehensive walk through of the equations of
   the Maude specification that are related to the server-side of the
   specification. The reception of a message is the only nondeterministic
   behaviour at the server; this is expressed as a single rewriting rule in
   Maude. This rule calls the functions we have described in the preceding
   sections.

   #+BEGIN_EXPORT latex
   \begin{figure}[h]
   \centering
   \begin{verbatim}
   crl [server-receive] :
       < U | out-queue : (Q msg(O, T, N)),
             in-queue  : Q' >
       < server | history : H, state : M, sites : (U |-> Q'', US) >
     =>
       < U | out-queue : Q,
             in-queue  : (msg(O'', s M, S) Q') >
       < server | history : H', state : s M, sites : US' >
       (send O' to US)
     if  H'  := fix(put(O T M U, H)) /\
         O'  := makeOp(H', H, T) /\
         S   := nextSeq(Q'', N) /\
         O'' := makeResponse(O, O', Q'', T) /\
         US' := (U |-> msg(O'', s M, s S), US) .
   \end{verbatim}
   \caption{The rule expresses the reaction to the reception of a message.}
   \label{fig:maude-rule}
   \end{figure}
   #+END_EXPORT

   The rewriting rule in Figure [[ref:fig:maude-rule]] concisely summarizes
   this chapter, as it describes the /reaction/ to the reception of a message.
   The reception of a message is modeled as the server nondeterministically
   picking a message off of the end of the message outgoing queue of a client.
   It adds a response message to the incoming queue to the client. The
   expression =(send O' to US)= similarly adds a message containing the
   operation =O'= on all the other clients incoming queues with the correct
   sequence number.

   The =sites= field is a mapping from users to the information the server
   stores about each client. Each site consists of a list of messages, which
   contains messages that might be rejected by the client; note that the
   sequence number is incremented by one in order to comply with the sequence
   number scheme (Section [[Sequence Number Scheme]]). Also note that the rule
   is expressed as a /conditional/ rule =crl= in order to achieve the effects
   of a /let/-expression, commonly found in functional programming languages.

[fn:3] The rules stated here are slightly simplified from those in the actual
Maude specification.
[fn:4] In the Maude specification, each user maps to a list of messages. It
contains the message that was sent, but where the sequence number $s_{u'}$ is
incremented by one. This is because the sequence number $s_{u'} + 1$ has to be
stored somewhere, as discussed in [[Sequence Number Scheme]], and a list of
messages was already present in the specification, in order to model message
queues.


* Shared Buffer for Emacs --- Source Code

  #+INCLUDE: ../shared-buffer-clients/shared-buffer-emacs/shared-buffer.el src emacs-lisp

* LISP In Summer Projects contribution

  The following is the project description submitted for the LISP In Summer
  Projects contest.

** Purpose

   # What is your project? In about 50 words, describe your project.

   Shared buffer is a project that enables real-time collaborative editing in
   Emacs. It is split up in two parts, client and server. The client is an
   Emacs extension entirely written in Emacs Lisp. The server is a small
   Common Lisp program; there is currently a server running on 'virvel.de'.

** Function

   # What does your project do? In about 50 words, describe what your project
   # does.

   In Emacs one is simply able to share a buffer and connect to a buffer that
   is already shared. This is done by requesting a connection to a shared
   buffer server. Once a connection is established all changes in your buffer
   is sent to the server. The server simply redirects these messages to all
   Emacs clients connected to that shared buffer.

** Motivation

   # Why did you choose this project?  In about 50 words, describe what was
   # your motivation was for doing this particular project?

   Working on a small scale project with friends, fellow students and
   coworkers was not simple enough to do with Emacs. Having recently started
   learning Lisp, it seemed like a fun and ambitious project.

** Audience

   # Who did you write this for? In about 50 words, describe the intended
   # target audience and anticipated users.

   Initially me, and whomever I wanted to work with. After realizing I’d
   might actually make it work, I think it can be useful for anyone using
   Emacs in collaboration with others. It is written with small scale
   software projects in mind, but can be used for all kinds of text editing.

** Methodology

   # How does it work?  In about 300-400 words, describe the technical details
   # of how your software works.  This might include high-level algorithms, the
   # technical stack and technical or social challenges you faced.

   The project is divided into two parts, a client and a server. The server
   is written in Common Lisp, and it's main job is to allow the clients to
   communicate. The client is an Emacs extension written in Emacs Lisp which
   mainly send changes to the server, or receives changes from the server.

   The client may ask to establish a new session or connect to an existing
   one. If a new session is required, the client provides a key. This key is
   used by the server as key in a hash table, containing lists of clients. A
   client asking to connect to a shared buffer is simply added to the list of
   clients that corresponds to the given key.

   When a new client connects to an already established session, a single
   client is asked by the server to send it's entire buffer content. This
   package is marked as being for new clients only. From that point on they
   should keep synced. The session is kept alive as long as there are clients
   connected to it.

   The main challenge in this project was to figure out how to keep several
   separate Emacs buffers mirrored. This is resolved by sending a message for
   every command a user invokes (this is done by adding functions to
   after-change-hook and post-command-hook, both built-in variables in
   Emacs). These messages will dictate a change that happened in a
   buffer. Assuming the shared buffers are identical to the one sending the
   message prior of that change, we can safely apply that change to any
   client that receives this message.

   A problem arises if our assumption is wrong. The most common situation is
   that a client has made changes in a buffer between the time the message
   was sent and received. The point where the change should be applied is
   then calculated by using the difference in the size of the buffer the
   message was sent from, and the size of the buffer receiving the
   message. This works in most cases.

** Conclusion

   # In 100-200 words, clearly summarize both the accomplishments and
   # limitations of your software.  Describe future directions for your
   # projects. This can include enhancements as well as extensions.

   After a summers worth of coding I am glad to say that the core
   functionality is up and running. It is fast and lightweight. A lot of time
   has gone into finding the /right/ solution to the big problems, and
   finding good workarounds for Emacs's many idiosyncrasies. I believe the
   project has great potential.

   The main issue that needs fixing is how to detect and resolve problems
   with synchronization. As of now, once buffers go out of sync, there is
   really no other solution than to disconnect and reconnect. There are also
   quite a few bugs triggered by Emacs's many features and extensions, and
   I'm hoping to resolve these after the competition is over.

   I plan to make Shared buffer more user friendly, by supplying a Emacs
   minor mode accompanied by a chat feature. When these things are in order
   it will be released in [[http://melpa.milkbox.net/][melpa]], and will hopefully be found useful.

   #+LaTeX:\backmatter{}
   #+LaTeX:\printbibliography

    After a summers worth of coding I am glad to say that the core
    functionality is up and running. It is fast and lightweight. A lot of time
    has gone into finding the /right/ solution to the big problems, and
    finding good workarounds for Emacs's many idiosyncrasies. I believe the
    project has great potential.

    The main issue that needs fixing is how to detect and resolve problems
    with synchronization. As of now, once buffers go out of sync, there is
    really no other solution than to disconnect and reconnect. There are also
    quite a few bugs triggered by Emacs's many features and extensions, and
    I'm hoping to resolve these after the competition is over.

    I plan to make Shared buffer more user friendly, by supplying a Emacs
    minor mode accompanied by a chat feature. When these things are in order
    it will be released in [[http://melpa.milkbox.net/][melpa]], and will hopefully be found useful.

* COMMENT Local variables
  # Local Variables:
  # company-mode : nil
  # eval: (require 'org-ref)
  # org-ref-pdf-directory: "~/Dropbox/ifi/master/articles/"
  # dabbrev-check-all-buffers: nil
  # eval: (server-start)
  # eval: (add-hook 'after-save-hook 'org-latex-export-to-latex nil t)
  # eval: (compile "latexmk -pdf -pvc -pdflatex='pdflatex -shell-escape -interaction nonstopmode'")
  # End:
