#+TITLE: Achieving Portable, Responsive and Robust Real-Time Collaborative Editing
#+AUTHOR: Lars Tveito
#+EMAIL: larstvei@ifi.uio.no
#+DATE: August 2016
#+OPTIONS: num:3 H:5 todo:nil title:nil toc:nil ':t
#+LaTeX_CLASS_OPTIONS: [USenglish, hidelinks]
#+LaTeX_CLASS: ifimaster
#+LATEX_HEADER: \usepackage{tikz}
#+LATEX_HEADER: \usetikzlibrary{shapes, arrows, arrows.meta, positioning, decorations.pathreplacing, automata}
#+LATEX_HEADER: \usepackage[scale=0.85]{sourcecodepro}
#+LATEX_HEADER: \usepackage[backend=biber,bibencoding=utf8]{biblatex}
#+LATEX_HEADER: \usepackage{amsthm, centernot, parskip, multicol, siunitx, subcaption, url}
#+LATEX_HEADER: \usepackage[hang]{footmisc}
#+LATEX_HEADER: \usepackage{hyperref}
#+LATEX_HEADER: \bibliography{ref}
#+LaTeX_HEADER: \urlstyle{sf}

#+LaTeX_HEADER: \newcommand{\ins}[2]{ins(#1,\ \texttt{#2})}
#+LaTeX_HEADER: \newcommand{\del}[2]{del(#1,\ \texttt{#2})}
#+LATEX_HEADER: \newcommand{\tuple}[1]{\ensuremath{\langle #1\rangle}}
#+LATEX_HEADER: \let\oldcirc\circ
#+LATEX_HEADER: \renewcommand{\circ}{\oldcirc\,}
#+LaTeX_HEADER: \newenvironment{ritemize}{\begin{itemize}\raggedright}{\end{itemize}}
#+LaTeX_HEADER: \theoremstyle{definition}
#+LaTeX_HEADER: \newtheorem{definition}{Definition}[section]

#+LaTeX_HEADER: \setlength\footnotemargin{5pt}

#+LaTeX: \pgfdeclarelayer{bg}    % declare background layer
#+LaTeX: \pgfsetlayers{bg,main}  % set the order of the layers (main is the standard layer)

#+LaTeX: \ififorside{}
#+LaTeX: \frontmatter{}
#+LaTeX: \maketitle{}

#+LaTeX: \newpage
#+LaTeX: \thispagestyle{empty}
#+LaTeX: \mbox{}

#+BEGIN_abstract
Placeholder for abstract.
#+END_abstract

#+LaTeX: \newpage
#+LaTeX: \thispagestyle{empty}
#+LaTeX: \mbox{}
#+LaTeX: \renewcommand{\abstractname}{Acknowledgements}

#+BEGIN_abstract
  When I was looking for a thesis project, I got to talk with Rudi. It did not
  take more than five minutes to realize that he would be a great supervisor.
  Throughout the process he has shown genuine interest in the project and given
  me both the freedom I wanted and the guidance I needed. Martin has been a
  tremendous help. He has given me the theoretical foundations that I sorely
  needed, both as my supervisor and as a lecturer. He is a bottomless source of
  knowledge, and I am convinced he has read every paper on theoretical computer
  science since the early 70's. I would like to convey my deepest gratitude to
  Rudi and Martin.

  Throughout my years at the Department of Informatics I have worked as a
  teaching assistant and been actively involved in the department's student
  council. Both of these arenas are simply packed with fantastic people that I
  have been lucky enough to get to know. A thanks goes out to Joshi, who have
  played a big part in encouraging me to pursue these roles. I want to thank
  the students who attended my lessons for letting me have their attention; it
  has been a wonderful experience for me, and hopefully for the students too.
  Furthermore, I would like to thank the many faculty members who actively work
  to make the Department of Informatics a fantastic place to study, and not
  shying from discussions with the students where improvement is due. I would
  like to thank my wonderful friends from the student council (FUI), who made
  my life at university a joy. There are simply too many to thank. This has
  made the university a great place to be.

  Thanks to the nano-gang, who I started my time at the university with and
  still visit regularly on the fourth floor. I especially want to thank Jarle
  and Kai for having long discussions about the thesis.

  For the last couple of years, I have spent a fair share of my time with Tore,
  Carl Martin and Sigurd, constantly having excited discussions of both a
  fruitful and completely useless nature. I've thoroughly enjoyed it, and would
  like to them to know that I kind-of love them.

  Finally, I want to thank my wonderful family. My sisters, Lisa and Julie, for
  being the coolest kids I know, my father for being the one I can always turn
  to for sound advice, my mother for being the most loving and caring person in
  the world and finally, my brother, Vegard, for being my favorite person.

  \hfill Thank you \\
  \null\hfill Lars Tveito
#+END_abstract
  #+LaTeX: \tableofcontents{}
  #+LaTeX: \listoffigures{}
  #+LaTeX: \listoftables{}
* Preface
  :PROPERTIES:
  :UNNUMBERED: t
  :END:
  In 2013 [[http://lispnyc.org][LispNYC]], [[http://www.meetup.com/Clojure-NYC/][ClojureNYC]] and [[http://alu.org][Association of Lisp Users]] hosted a
  programming competition called [[http://lispinsummerprojects.org/][LISP In Summer Projects]], awarding cash prizes
  for Lisp-related projects. They gathered some great finalist judges: Matthias
  Felleisen, Richard Gabriel, Rich Hickey, Peter Norvig, Christian Queinnec and
  Taiichi Yuasa.

  Around the time the competition was announced, I attended a course on
  functional programming, in which we were to collaborate on programming
  assignments in small teams. Mostly, we programmed together while in the same
  room, and at any given moment the one with the most promising idea used the
  keyboard. Sometimes we all wanted to explore some idea, and we would have to
  type it out on separate computers, and synchronize our changes afterwards.

  Seeing the aforementioned competition announcement, I immediately decided
  that implementing real-time collaboration in Emacs would make the perfect
  project. A program was developed using a trial and error approach, and by the
  end of the summer I had a rough prototype, consisting of an Emacs client and
  a server written in Common Lisp. It did not handle concurrent edits, which
  poses the greatest algorithmic challenge for a real-time collaborative
  editing system.

  Still, the judges of the competition deemed the program worthy of second
  prize, awarding me $500 for my efforts. The project description submitted to
  the competition can be found in at the [[http://lispinsummerprojects.org/static/summer/231030-sharedbuffer.pdf][Lisp in Summer Projects website]], and
  the source code for the project is hosted on [[https://github.com/larstvei/shared-buffer-lisp-in-summer-projects][Github]].

  This thesis is a continuation of the work I did on that project, but with a
  different focus. The aim is to find a way to gracefully handle concurrent
  edits, without adding complexity to the client side algorithm. Having
  experienced that detecting bugs in such a system was a challenging endeavor,
  lead to the decision of leveraging formal methods to ensure correctness for
  the algorithm.
 #+LaTeX: \mainmatter{}
* Introduction

  A real-time collaborative editor enables multiple users, at (potentially)
  different locations, to work on the same document /simultaneously/. The idea
  has been around for a long time, and was demoed by Douglas Engelbart in the
  Mother of All Demos cite:engelbart1968mother already in 1968. In this thesis
  we leverage formal methods to aid the development of a real-time
  collaboration system.

  First, let us make it clear what we will characterize as a real-time
  collaborative editor. An /editor/ is a program that allows a user to
  manipulate a plain text document. The editor is considered /collaborative/ if
  it has features that makes it easier for multiple users to form a document
  together. Furthermore, it is considered /real-time/ if multiple users can
  edit the document simultaneously cite:ellis1989concurrency, and that changes
  are propagated to the other users within a reasonably short amount of time.

  The first actual implementation of such an editor that was documented in the
  literature, came with GROVE (GROUP Outline Viewing Editor)
  cite:ellis1989concurrency, which introduced the concept of /Operational
  Transformation/ (OT) which we will cover in Chapter [[Related Work]]. Previous
  systems
  cite:Greif:1986:ADA:512644.512659,Fish:1988:QCT:45410.45414,Lewis:1988:SBC:45410.45431
  that provided collaborative capabilities were not considered /real-time/
  systems by cite:ellis1989concurrency, because users could not edit the same
  /section/ of the document simultaneously.

  The reader might be familiar with [[https://www.google.com/docs/about/][Google Docs]], which is an example of a
  modern real-time collaborative document WYSIWYG (What You See Is What You
  Get) editor with over 240 million monthly active users cite:NextWeb2014. It
  is largely based on OT cite:WaveOT, but has also initiated research in a
  technique called Differential Synchronization cite:Fraser:09. Through its
  integration with [[https://www.google.com/drive/][Google Drive]], it offers a collaborative platform, where
  users can both store and manipulate their documents, as long as they have an
  internet connection and a (fairly modern) browser.

  We present a tool for real-time collaborative editing called Shared Buffer,
  which is designed with developers in mind. What most developers have in
  common is that they spend a lot of time manipulating /plain text/, yet they
  use a lot of different tools to do so cite:stackoverflowdevelopersurvey. We
  therefore aim at enabling real-time collaboration in /existing/ text editors,
  as opposed to developing an editor with real-time collaborative features. As
  a means to this end, we develop a protocol which, ideally, should be portable
  to any text editor, or any program that embeds a text editor.

  A client-server model is chosen, as opposed to a fully decentralized
  solution. We have tried to move complexity to the server whenever possible,
  if this simplifies the client-side algorithm. Furthermore, proving
  correctness for a fully decentralized solution has proven to be very
  difficult cite:formalOT,DBLP:journals/corr/abs-1302-3292,Imine2003.

  Our prototype client is for the text editor Emacs. The name Shared Buffer
  reflects a choice in design; in Emacs, text is stored in a /buffer/; when a
  file is opened, its contents is put inside a buffer which the user can
  manipulate. You may also have buffers that are not associated with any file.
  In Shared Buffer, there is no notion of a file, meaning there is no centrally
  stored copy of the document.

  The server is written in a dialect of Lisp called [[https://clojure.org/][Clojure]], a modern
  functional programming language with strong concurrency semantics
  cite:Emerick2012. Being hosted on the JVM, Clojure offers full Java
  interoperability, meaning that we can leverage the vast collection of Java
  libraries.

** The Naïve Algorithm

   Let us now consider two cases that illustrates how a naïve implementation
   (like the one briefly described in the [[Preface]]) might work, and where it
   fails to produce a desirable result.

   Say we have two users, our European friend $u_0$ and $u_1$, the American,
   who are both communicating with a server $S$. They each have a copy of a
   shared buffer. Both may either insert a character, or delete one from the
   buffer, and they may do so at any time. When a user performs an operation
   (meaning insertion or deletion) on its local buffer, then this should be
   communicated to $S$. When $S$ receives an operation, it should communicate
   this to the other user.

   We represent scenarios that can occur in the system graphically by using a
   variation of message sequence charts. The diagrams are read from top to
   bottom with regards to time, where directed edges represents the transfer of
   a message.

   #+BEGIN_EXPORT latex
   \begin{figure}[h]
     \centering
     \begin{tikzpicture}[>=stealth, shorten >= 5pt, node distance=1em, scale=1]
       \tikzstyle{vertex} = [circle, scale=0.5]
       \tikzstyle{O_0} = [vertex, fill=black!30!green]
       \tikzstyle{O_1} = [vertex, fill=black!30!blue]

       \tikzstyle{to} = [-{Stealth[scale=1.2]}]
       \tikzstyle{toO_0} = [to, color=black!30!green]
       \tikzstyle{toO_1} = [to, color=black!30!blue]

       \tikzstyle{op} = [midway, above=-3pt, sloped, text=black, font=\small]

       %% Server receives operations in this order
       \node (s) at (3, 4) {$S$};
       \coordinate (se) at (3, 0) {};
       \node[O_0, below = 2em of s] (s1) {};
       \node[O_1, below = 3.2em of s1] (s2) {};

       %% User 0 generates/receives in this order
       \node (u0) at (0, 4) {$u_0$};
       \node (u0e) at (0, 0) {};
       \node[O_0, below = of u0, label=left:{\texttt{a}}] (u00) {};
       \node[O_1, above = 2em of u0e, label=left:{\texttt{ba}}] (u01a) {};

       %% User 1 generates/receives in this order
       \node (u1) at (6, 4) {$u_1$};
       \node (u1e) at (6, 0) {};
       \node[O_0, below = 3em of u1, label=right:{\texttt{a}}] (u10a) {};
       \node[O_1, below = 1em of u10a, label=right:{\texttt{ba}}] (u11) {};

       \begin{pgfonlayer}{bg} % select the background layer
         \draw[to, color=black!30] (s) -- (s1)  -- (s2) -- (se);
         \draw[to, color=black!30] (u0) -- (u00) -- (u01a) -- (u0e);
         \draw[to, color=black!30] (u1) -- (u11) -- (u10a) -- (u1e);

         % Life of O_0
         \draw[toO_0] (u00) -- (s1) node [op] {$\overbrace{\ins{0}{a}}^{O_0}$};
         \draw[toO_0] (s1) -- (u10a) node [op, near end] {$O_0$};

         % Life of O_1
         \draw[toO_1] (u11) -- (s2) node [op] {$\overbrace{\ins{0}{b}}^{O_1}$};
         \draw[toO_1] (s2) -- (u01a) node [op, near end] {$O_1$};
       \end{pgfonlayer}
     \end{tikzpicture}
     \caption{A conflict-free scenario with two clients.}
     \label{fig:noconflict0}
   \end{figure}
   #+END_EXPORT

   Figure [[ref:fig:noconflict0]] describes a very simple scenario. Imagine that
   $u_0$ has an empty buffer which she precedes to insert an ="a"= into. Then
   $u_1$ inserts a ="b"= in front of the ="a"= that just showed up in her
   buffer. The ="b"= eventually reaches $u_0$, and the end result of the
   interaction is that they both will be looking at a buffer containing ="ba"=.
   In this scenario the buffers ended up identical, so we say that we have
   reached a /consistent state/.

   Simple scenarios like the one we saw, where only one message is "in flight"
   at any one time, would be gracefully handled even by the naïve approach. We
   can see that ="a"= was inserted prior to the ="b"= at both $u_0$ and $u_1$,
   hence they cannot have been applied concurrently. We will now demonstrate
   that the approach does not work when we introduce concurrent edits.

   Let us return to the example from Figure [[ref:fig:noconflict0]], with a slight
   modification, visualized in Figure [[ref:fig:conflict0]]. The scenario is
   unchanged at $u_0$, where she first inserts an ="a"=, and later receives the
   ="b"= which leaves her with a buffer containing ="ba"=. Now say that $u_1$
   inserts her ="b"= /before/ having received the ="a"=. When she has already
   typed a ="b"=, she receives a message saying that she should place an ="a"=
   at the first point in her buffer. The resulting buffer is ="ab"=. Now they
   are looking at different buffers, so we say we have reached an /inconsistent
   state/.

   #+BEGIN_EXPORT latex
   \begin{figure}[h]
     \centering
     \begin{tikzpicture}[>=stealth, shorten >= 5pt, node distance=1em, scale=1]
       \tikzstyle{vertex} = [circle, scale=0.5]
       \tikzstyle{O_0} = [vertex, fill=black!30!green]
       \tikzstyle{O_1} = [vertex, fill=black!30!blue]

       \tikzstyle{to} = [-{Stealth[scale=1.2]}]
       \tikzstyle{toO_0} = [to, color=black!30!green]
       \tikzstyle{toO_1} = [to, color=black!30!blue]

       \tikzstyle{op} = [midway, above=-3pt, sloped, text=black, font=\small]

       %% Server receives operations in this order
       \node (s) at (3, 4) {$S$};
       \coordinate (se) at (3, 0) {};
       \node[O_0, below = 3em of s] (s1) {};
       \node[O_1, below = 1em of s1] (s2) {};

       %% User 0 generates/receives in this order
       \node (u0) at (0, 4) {$u_0$};
       \node (u0e) at (0, 0) {};
       \node[O_0, below = of u0, label=left:{\texttt{a}}] (u00) {};
       \node[O_1, above = 2em of u0e, label=left:{\texttt{ba}}] (u01a) {};

       %% User 1 generates/receives in this order
       \node (u1) at (6, 4) {$u_1$};
       \node (u1e) at (6, 0) {};
       \node[O_1, below = 1.5em of u1, label=right:{\texttt{b}}] (u11) {} ;
       \node[O_0, below = 3em of u11, label=right:{\texttt{ab}}] (u10a) {};

       \begin{pgfonlayer}{bg} % select the background layer
         \draw[to, color=black!30] (s) -- (s1)  -- (s2) -- (se);
         \draw[to, color=black!30] (u0) -- (u00) -- (u01a) -- (u0e);
         \draw[to, color=black!30] (u1) -- (u11) -- (u10a) -- (u1e);

         % Life of O_0
         \draw[toO_0] (u00) -- (s1) node [op] {$\overbrace{\ins{0}{a}}^{O_0}$};
         \draw[toO_0] (s1) -- (u10a) node [op, near end] {$O_0$};

         % Life of O_1
         \draw[toO_1] (u11) -- (s2) node [op] {$\overbrace{\ins{0}{b}}^{O_1}$};
         \draw[toO_1] (s2) -- (u01a) node [op, near end] {$O_1$};
       \end{pgfonlayer}
     \end{tikzpicture}
     \caption{A minimal conflict with two clients.}
     \label{fig:conflict0}
   \end{figure}
   #+END_EXPORT

   In this thesis we introduce and discuss a new protocol which guarantees
   /eventual consistency/ cite:Vogels:2009:EC:1435417.1435432 between
   participating clients. Intuitively, this means that if all users stop typing
   at some point, then given enough time for traveling messages to reach their
   destination, they will all be looking at the same buffer. In later chapters
   we will come to realize that is not at all trivial, considering the highly
   concurrent and distributed nature of the problem. In order to handle this
   level of complexity we will rely heavily on the use of formal methods.

** Method

   In this thesis we use a formal verification technique called /model
   checking/ cite:Clarke:2000:MC:332656. This technique requires us to obtain a
   formal model of the system we wish to validate. A model is represented as a
   set of states, and transitions between these states. We can think of model
   checking as a graph search, where the states acts as nodes, and edges
   represent the possibility of going from one state to another. If the graph
   is finite, we can prove that the model has a certain property by checking
   whether the property holds true in every state. Furthermore, we want to use
   Linear Temporal Logic (LTL) to express properties over paths, which are
   sequences of states.

   The model is an abstraction of a given system, where one carefully chooses
   what parts of the system is necessary to represent, in order to prove the
   properties that are of interest.

   Moreover, we use the model as a way of driving the development process, or
   rather, solving the problem. When model checking a property, a counter
   example is given if the property does not hold. By studying the example, we
   can change the model in hope of resolving the issue, and see the effects of
   the change. This resembles Test Driven Development (TDD), but instead of
   testing our actual system we perform tests on a model, and rather than
   testing a few selected scenarios, we check all possible scenarios.

   [[http://maude.cs.illinois.edu/][The Maude System]] is our chosen modeling language and verification tool. It
   provides an expressive language, that is well suited for modeling concurrent
   and distributed systems [[cite:DBLP:conf/maude/2007]]. In addition, it
   provides an LTL Model Checker cite:Eker2004162, which allows us to specify
   and verify LTL properties.

** Contributions

   The main result of this thesis is a protocol that enables real-time
   collaborative editing. Both a client- and server-side algorithm have been
   modeled and implemented. The model has been formally verified to guarantee
   eventual consistency for a limited number of clients and operations.

   In the process we have:
   - provided a formal description of our system based on OT,
   - demonstrated how modeling has been used to drive the development,
   - presented a representation of the system in Maude,
   - performed LTL model checking on our model in Maude,
   - provided a client as an extension for Emacs,
   - provided an implementation of the server-side algorithm in Clojure.

* Formal Semantics of Editing Operations

  #+BEGIN_EXPORT latex
  \begin{wrapfigure}[14]{r}{0pt}
    \begin{tikzpicture}[>=stealth, shorten >= 5pt, node distance=1em, scale=1]
        \tikzstyle{vertex} = [circle, scale=0.5]
        \tikzstyle{O_0} = [vertex, fill=black!30!green]
        \tikzstyle{O_1} = [vertex, fill=black!30!blue]

        \tikzstyle{to} = [-{Stealth[scale=1.2]}]
        \tikzstyle{toO_0} = [to, color=black!30!green]
        \tikzstyle{toO_1} = [to, color=black!30!blue]

        \tikzstyle{op} = [midway, above=-3pt, sloped, text=black, font=\small]

        %% Server receives operations in this order
        \node[color=black!20] (s) at (3, 3.5) {$S$};
        \coordinate (se) at (3, 0) {};
        \node[O_0, color=black!20, below = 2em of s] (s1) {};
        \node[O_1, color=black!20, below = 1.5em of s1] (s2) {};

        %% User 0 generates/receives in this order
        \node (u0) at (0, 3.5) {$u_0$};
        \node (u0e) at (0, 0) {};
        \node[O_0, below = of u0, label=left:{\texttt{a}}] (u00) {};
        \node[O_1, above = 2em of u0e, label=left:{\texttt{ba}}] (u01a) {};

        \begin{pgfonlayer}{bg} % select the background layer
          \draw[to, color=black!20] (s) -- (s1)  -- (s2) -- (se);
          \draw[to, color=black!30] (u0) -- (u00) -- (u01a) -- (u0e);

          % Life of O_0
          \draw[toO_0] (u00) -- (s1) node [op] {$\overbrace{\ins{0}{a}}^{O_0}$};

          % Life of O_1
          \draw[toO_1] (s2) -- (u01a) node [op] {$\overbrace{\ins{0}{b}}^{O_1}$};
        \end{pgfonlayer}
    \end{tikzpicture}
    \caption{Our focus is on the operations of a single user.}
    \label{fig:focusclient}
  \end{wrapfigure}
  #+END_EXPORT

  A model of a given system is an abstraction of that system cite:Lamport:2002,
  which means only some aspects of the system are described. In our case, the
  fundamental capabilities of a text editor, namely the insertion and deletion
  of characters in a buffer, should be captured, along with the order in which
  they are performed. The time between operations is an example of something
  /not/ represented in the model; as a result the model cannot be used to
  analyze the real time performance of the system. Other features of a text
  editor, like "search and replace", are also omitted, because such features
  can be represented as a series of deletions and insertions.

  In this chapter we introduce a formal definition of editing operations and
  their semantics. Operations are fundamental for all /Operational
  Transformation/ (OT) algorithms, as well as the Shared Buffer algorithm. To
  get a deeper understanding of the operations we study their algebraic
  properties, which simplifies the process of both specifying and implementing
  them. Furthermore, the Shared Buffer heavily relies on the ability to take
  the inverse of an operation, which motivates Section [[Invertibility]].

  The definitions are based on
  cite:ellis1989concurrency,DBLP:journals/corr/abs-1302-3292; we specify them
  formally and define the semantics of editing operations as a set of
  equations. This chapter is only concerned with events at a single client. We
  assume that every event is simply an operation being applied, and do not
  differentiate between an operation originating locally or remotely.

** Operations and Buffers

   The operations we are concerned with is the /insertion/ and /deletion/ of a
   character in a buffer.
   #+BEGIN_EXPORT latex
   \\
   \begin{definition}[Operations]
     The set $\mathcal O$ is inductively defined as the smallest set such that
     the following holds:
     \begin{itemize}
     \item \(nop \in \mathcal O\),
     \item \(ins(i,\ c) \in \mathcal O\) for any \(i \in \mathbb{N}\) and \(c \in Unicode\),
     \item \(del(i) \in \mathcal O\) for any \(i \in \mathbb{N}\),
     \item for any two \(O_i, O_j \in \mathcal O\) then \(O_j \circ O_i \in \mathcal O\).\hfill$\dashv$
     \end{itemize}
   \end{definition}
   #+END_EXPORT

   The semantics of an operation is defined in terms of how it is applied to a
   buffer, where a buffer is simply defined as a 0-indexed string of UTF-8
   encoded characters. The set $Unicode$ is our alphabet, which contains every
   character defined by the Unicode standard cite:unicode-standard. We let
   $\mathcal B$ constitute the set of all possible buffers --- this set could
   also be expressed as $Unicode^{*}$.

   An operation can be applied to a buffer, which in turn yields a new buffer.
   Consequently all $O \in \mathcal O$ are partial unary operations $O :
   \mathcal B \rightarrow \mathcal B$. The operations are partial because a
   given operation cannot necessarily be applied to all buffers; as an example,
   no delete operation can be applied to the empty buffer $\epsilon$. We assume
   that no text-editor are able to produce an operation which is ill-defined on
   its current buffer.
   #+BEGIN_EXPORT latex
   \\
   \begin{definition}{(Semantics of Operations).}
     Let $B \in \mathcal{B}$. The $nop$ operation is the operation that does
     nothing, and applying it is defined as:
     \begin{align*}
       nop(B) &= B
     \end{align*}
     Let $i \in \mathbb{N}$, and both $c, c' \in Unicode$. We let a single space
     represent concatenation, where characters are treated like strings of length
     one. Applying an insertion is then defined as follows:
     \begin{align*}
       ins(0, c)(B) &= c\ B \\
       ins(i + 1, c)(c'\ B) &= c'\ ins(i, c)(B)
     \end{align*}
     Similarly, applying a deletion is defined as:
     \begin{align*}
       del(0)(c\ B) &= B \\
       del(i + 1)(c\ B) &= c\ del(i)(B)
     \end{align*}
     Let $O_i, O_j \in \mathcal O$, and let $O_j \circ O_i$ represent the
     \textit{composition} of $O_i$ and $O_j$. Applying a composed operation to a buffer
     is defined as:
     \begin{align*}
       O_j \circ O_i(B) &= O_j(O_i(B))
     \end{align*}\hfill$\dashv$
   \end{definition}
   #+END_EXPORT
   Note that composition of operations is no different from regular function
   composition.

** Scenarios Described in Terms of Operations and Their Application

   In the previous section we formalized
   - what operations are,
   - how operations are applied to buffers, and
   - how operations are combined.

   Let us try to bridge the gap between the formal notion of an editing
   operation, and scenarios that involves a user typing on a keyboard. Imagine
   that a user types the word ~"hello"~ --- this is modeled as a single
   operation:
   \[ \ins{4}{o} \circ \ins{3}{l} \circ \ins{2}{l} \circ \ins{1}{e} \circ \ins{0}{h} \]
   The result of applying the operation to the empty buffer $\epsilon$
   evaluates to the buffer that only contains the word ~"hello"~, and can be
   calculated as so:
   #+BEGIN_EXPORT latex
   \begin{align*}
     \ins{4}{o} \circ \ins{3}{l} \circ \ins{2}{l} \circ \ins{1}{e} \circ \ins{0}{h} (\epsilon) &= \\
     \ins{4}{o} \circ \ins{3}{l} \circ \ins{2}{l} \circ \ins{1}{e} (\texttt{"h"}) &= \\
     \ins{4}{o} \circ \ins{3}{l} \circ \ins{2}{l} (\texttt{"he"}) &= \\
     \ins{4}{o} \circ \ins{3}{l} (\texttt{"hel"}) &= \\
     \ins{4}{o} (\texttt{"hell"}) &= \texttt{"hello"}
   \end{align*}
   #+END_EXPORT
   Now we will expand from the case where a single user types on a keyboard,
   and include operations that can be received from a server. In the scenario
   best described by Figure [[ref:fig:noconflict0]] (page pageref:fig:noconflict0),
   we saw two operations $\ins{0}{a}$ and $\ins{0}{b}$, named $O_0$ and $O_1$
   respectively, being applied in the same order at two different locations.
   #+BEGIN_EXPORT latex
   \begin{multicols}{2}
     From the perspective of $u_0$:
     \begin{itemize}
     \item $O_0$ is generated locally,
     \item $O_1$ is received from the server.
     \end{itemize}
     \columnbreak
     From the perspective of $u_1$:
     \begin{itemize}
     \item $O_0$ is received from the server,
     \item $O_1$ is generated locally.
     \end{itemize}
   \end{multicols}
   #+END_EXPORT
   Common to both $u_0$ and $u_1$ is their initial buffer (the empty buffer
   $\epsilon$) and the operation they apply is $O_1 \circ O_0$. Because they
   perform the same operation to the same initial buffer, they must necessarily
   end up in a consistent state (i.e. end up with the same buffer).

   The scenario from Figure [[ref:fig:conflict0]] (page pageref:fig:conflict0) is
   almost identical to the scenario above, but the operations are applied in
   different orders.
   #+BEGIN_EXPORT latex
   \begin{multicols}{2}
     From the perspective of $u_0$:
     \begin{itemize}
     \item $O_0$ is generated locally,
     \item $O_1$ is received from the server.
     \end{itemize}
     \columnbreak
     From the perspective of $u_1$:
     \begin{itemize}
     \item $O_1$ is generated locally,
     \item $O_0$ is received from the server.
     \end{itemize}
   \end{multicols}
   #+END_EXPORT
   $u_0$ and $u_1$ have the same initial buffer, but the composed operation of
   $u_0$ is $O_1 \circ O_0$ and the composed operation of $u_1$ is $O_0 \circ
   O_1$. By applying these operations to the empty buffer $\epsilon$ we show
   that $u_0$ and $u_1$ end up in an inconsistent state (i.e. end up with
   different buffers).
   #+BEGIN_EXPORT latex
   \begin{multicols}{2}
     Operation applied by $u_0$:
     \begin{align*}
       \overbrace{\ins{0}{b}}^{O_1} \circ \overbrace{\ins{0}{a}}^{O_0}(\epsilon) &= \\
       \ins{0}{b}(\texttt{"a"}) &= \texttt{"ba"}
     \end{align*}

     \columnbreak
     Operation applied by $u_1$:
     \begin{align*}
       \overbrace{\ins{0}{a}}^{O_0} \circ \overbrace{\ins{0}{b}}^{O_1}(\epsilon) &= \\
       \ins{0}{a}(\texttt{"b"}) &= \texttt{"ab"}
     \end{align*}
   \end{multicols}
   #+END_EXPORT

** Algebraic Properties

   An algebraic structure is a set along with one or more operations
   cite:antonsen2014logiske. The set of operations $\mathcal O$ under
   composition $\circ : \mathcal O \times \mathcal O \rightarrow \mathcal O$
   forms an algebraic structure, denoted $\langle \mathcal O, \circ \rangle$.

   The previous section contains a proof that $\circ$ is /not/ commutative,
   meaning that $O_j \circ O_i = O_i \circ O_j$ is not the case for all $O_i,
   O_j \in \mathcal O$.
   \begin{proof}
   As examplified in the previous section:
   \[
   ins(0, b) \circ ins(0, a) \neq ins(0, a) \circ ins(0, b)
   \]
   \end{proof}

   The fact that $\circ$ is not commutative is precisely the problem with the
   naïve algorithm (Section [[The Naïve Algorithm]]); in other words, the naïve
   algorithm would guarantee eventual consistency if the order of which
   operations are applied does not affect the end result. In the next chapter
   we will introduce /Operational Transformation/ which, at its core, is a
   technique for restoring commutativity for operations.

   Furthermore, the structure $\langle \mathcal O, \circ \rangle$ is a /monoid/
   because it satisfies the following properties:

   - $nop$ is the identity element of $\circ$.
     \begin{proof}
     Let $O \in \mathcal O$, then
     \begin{itemize}
       \item $nop \circ O(B) = nop(O(B)) = O(B)$
       \item $O \circ nop(B) = O(nop(B)) = O(B)$
     \end{itemize}
     for any $B \in \mathcal B$. It follows that $nop \circ O = O \circ nop = O$.
     \end{proof}
   - $\circ$ is associative.
     \begin{proof}
     Let $O_i, O_j, O_k \in \mathcal O$, then
     \begin{itemize}
       \item $((O_k \circ O_j) \circ O_i)(B) = (O_k \circ O_j)(O_i(B)) = O_k(O_j(O_i(B)))$
       \item $(O_k \circ (O_j \circ O_i))(B) = O_k((O_j \circ O_i)(B)) = O_k(O_j(O_i(B)))$
     \end{itemize}
     for any $B \in \mathcal B$. It follows that $O_k \circ (O_j \circ O_i) =
     (O_k \circ O_j) \circ O_i$.
     \end{proof}
   - $\circ$ is closed under $\mathcal O$.
     \begin{proof}
     By definition.
     \end{proof}

   There are two main reasons for noting these algebraic properties; one is
   that it is helpful when writing a formal specification in Maude, because
   Maude is an /algebraic/ specification language; the other is that it helps
   when translating the structure to a given programming language, by making
   sure the selected representation preserves the properties of a monoid.

*** Invertibility

    A /group/ can be described as a monoid with /invertibility/, meaning every
    element in $\mathcal O$ has an inverse. More formally, for $\langle
    \mathcal O, \circ \rangle$ to be a group, it must satisfy that for any $O_i
    \in \mathcal O$ there exists a $O_j \in \mathcal O$ such that:
    #+BEGIN_EXPORT latex
    \[ O_j \circ O_i = O_i \circ O_j = nop \]
    #+END_EXPORT
    The inverse of an operation $O \in \mathcal O$ is denoted $O^{-1}$, and so
    the equation can be restated as:
    #+BEGIN_EXPORT latex
    \[ O \circ O^{-1} = O^{-1} \circ O = nop \]
    #+END_EXPORT
    /Undo/ is a common feature in text editors, and should guide us in
    constructing an inverse function for $\mathcal O$. Intuitively it seems to
    satisfy the equation, in the sense that adding a character to a buffer,
    followed by an undo, is the same as having done nothing at all.

    Guided by this intuition, the inverse of $\ins{0}{a}$ should be $del(0)$,
    because applying $del(0) \circ \ins{0}{a}$ to a buffer will always yield
    the same buffer. We can make the exact same argument for $\ins{0}{b}$; its
    inverse should be $del(0)$. What should then be the inverse of $del(0)$? It
    cannot be both $\ins{0}{a}$ and $\ins{0}{b}$. If we were to choose one
    arbitrarily, then a user could suddenly experience that the character the
    inserted morphed in to another.

    The problem is solved by extending the delete operations with what
    character is deleted, and so we redefine delete operations as so:
    - $del(i,\ c) \in \mathcal O$ for any $i \in \mathbb{N}$ and $c \in Unicode$.

    With the information of what character was deleted in the operation, we
    disambiguate what the inverse of a deletion should be. The inverse of
    $\ins{0}{a}$ should be $\del{0}{a}$, and the inverse of $\ins{0}{b}$ should
    be $\del{0}{b}$, where the inverse of each deletion should be $\ins{0}{a}$
    and $\ins{0}{b}$ respectively.

    Inverting composed operations is analogous with undoing multiple steps. Say
    a user types an =a= followed by a =b=, then undoing it would be to first
    delete the =b=, then delete the =a=. So for instance, the inverse of
    $\ins{1}{b} \circ \ins{0}{a}$ should be $\del{0}{a} \circ \del{1}{b}$.
    #+BEGIN_EXPORT latex
    \\
    \begin{definition}[Inverse of an Operation]\label{def:inverse}
      The inverse of the $nop$ element is the $nop$ element itself:
      \[ nop^{-1} = nop \]
      The inverse of an insertion of a character $c \in Unicode$ at position $i
      \in \mathbb{N}$, is the deletion of that character at that position:
      \[ ins(i,\ c)^{-1} = del(i,\ c) \]
      Similarly for deletions:
      \[ del(i,\ c)^{-1} = ins(i,\ c) \]
      For a composed operation $O_j \circ O_i \in \mathcal{O}$, the order of the
      operations is reversed, and the operations are inverted:
      \[ (O_j \circ O_i)^{-1} = O_i^{-1} \circ O_j^{-1} \]\hfill$\dashv$
    \end{definition}
    #+END_EXPORT
    Now that we have defined an inverse for all operations, we can check if
    invertibillity holds. Say we have the operation $\ins{0}{a}$, then its
    inverse is $\del{0}{a}$. We apply $\del{0}{a} \circ \ins{0}{a}$ to the
    empty buffer $\epsilon$:
    #+BEGIN_EXPORT latex
    \begin{align*}
      \del{0}{a} \circ \ins{0}{a} (\epsilon) &= \\
      \del{0}{a} (\texttt{"a"}) &= \epsilon
    \end{align*}
    #+END_EXPORT
    In order to satisfy the invertibility axiom, the reverse should be true as
    well. It is not because applying $\ins{0}{a} \circ \del{0}{a}$ on the empty
    buffer $\epsilon$, because it is not well defined. Consequently, the
    invertibility axiom does not hold, and so $\langle \mathcal O, \circ
    \rangle$ is not a group.

    Inverting operations is an essential part of the Shared Buffer algorithm,
    and we rely on the definition above even though the invertibillity axiom
    does not hold. Notice that the counter example $\ins{0}{a} \circ \del{0}{a}
    (\epsilon)$ expresses that a deletion is applied to the empty buffer and
    then undone. It seems fair to question if that situation could really
    occur, because there is no reasonably defined way for an editor to perform
    the deletion in the first place.

    We have to ensure that the algorithm never construct an operation that
    cannot be applied to a given client's buffer. We rely on the model checker
    to provide a counter example, if we were to construct such an operation.
* Related Work

  In this chapter we present some of the work of Ellis and Gibbs
  cite:ellis1989concurrency, the pioneers of /Operational Transformation/ (OT)
  and the very interesting work of Imine et al. on proving correctness for
  transformation functions using formal verification techniques
  cite:DBLP:conf/ecscw/ImineMOR03,DBLP:journals/corr/abs-1302-3292,formalOT.
  The chapter should sufficiently convey the basic idea of OT and how it
  works, without going into the finer details. We use notation established in
  Chapter [[Formal Semantics of Editing Operations]] to describe the workings of
  OT.

** Basics of Operational Transformation

   Ellis and Gibbs introduced the dOPT (Distributed Operational Transformation)
   algorithm cite:ellis1989concurrency, and with it, /Operational
   Transformation/ (OT), which tries to solve the problem of diverging copies
   of a buffer, in a fully distributed setting. The main idea is to construct a
   /transformation function/ where remote operations are transformed with
   regards to conflicting local operations in a way that guarantees
   consistency.

   In order to achieve this, an additional parameter, /priority/, is added to
   insertions and deletions; the priority is a unique identifier for a given
   client, represented as a number, and is used in order to break ties. The
   transformation function $T: \mathcal O \times \mathcal O \rightarrow
   \mathcal O$, proposed by Ellis and Gibbs, is restated in Figure
   [[ref:fig:transformation-function]].

   #+BEGIN_EXPORT latex
   \begin{figure}[h]
     \begin{align*}
       T(ins(p1,c1,pr1), ins(p2,c2,pr2)) &=
       \begin{cases}
         ins(p1,c1,pr1)      & \text{if }      p1 < p2 \\
         ins(p1+1,c1,pr1)    & \text{else if } p1 > p2 \\
         nop                 & \text{else if } c1 = c2 \\
         ins(p1+1,c1,pr1)    & \text{else if } pr1 > pr2 \\
         ins(p1,c1,pr1)      & \text{otherwise}
       \end{cases}
       \\\\
       T(ins(p1,c1,pr1), del(p2,pr2)) &=
       \begin{cases}
         ins(p1,c1,pr1)      & \text{if } p1 < p2 \\
         ins(p1-1,c1,pr1)    & \text{otherwise}
       \end{cases}
       \\\\
       T(del(p1,pr1), ins(p2,c2,pr2)) &=
       \begin{cases}
         del(p1,pr1)         & \text{if } p1 < p2 \\
         del(p1+1,pr1)       & \text{otherwise}
       \end{cases}
       \\\\
       T(del(p1,pr1), del(p2,pr2)) &=
       \begin{cases}
         del(p1,pr1)         & \text{if }      p1 < p2 \\
         del(p1-1,pr1)       & \text{else if } p1 > p2 \\
         nop                 & \text{otherwise}
       \end{cases}
     \end{align*}
     \caption{The transformation function from \cite{ellis1989concurrency}.}
     \label{fig:transformation-function}
   \end{figure}
   #+END_EXPORT
   Let us again consider the example described in Figure [[ref:fig:conflict0]]
   (page pageref:fig:conflict0), where two operations $O_0 = ins(0,\
   \texttt{a},\ 0)$ and $O_1 = ins(0,\ \texttt{b},\ 1)$ are performed
   concurrently, leading to an inconsistent state. Rather than applying
   operations directly, remote operations are transformed with regards to
   (potential) concurrent local operations, before they are applied.
   Communication is done directly between clients (as opposed to going via a
   server).
   #+BEGIN_EXPORT latex
   \begin{multicols}{2}
     From the perspective of $u_0$:
     \begin{ritemize}
     \item $O_0$ is generated locally,
     \item $O_1$ is received from $u_1$, $T(O_1, O_0)$ is applied.
     \end{ritemize}
     \columnbreak
     From the perspective of $u_1$:
     \begin{ritemize}
     \item $O_1$ is generated locally,
     \item $O_0$ is received from $u_0$, $T(O_0, O_1)$ is applied.
     \end{ritemize}
   \end{multicols}
   #+END_EXPORT
   The scenario is illustrated in Figure
   [[ref:fig:conflict-resolved-transformation]]. By composing the operations at
   each user and applying that operation to the empty buffer $\epsilon$, the
   resulting buffer is found.
   #+BEGIN_EXPORT latex
   \begin{multicols}{2}
     Operation applied by $u_0$:
     \begin{align*}
       T(O_1, O_0) \circ ins(0,\ \texttt{a},\ 0) (\epsilon) &= \\
       T(ins(0,\ \texttt{b},\ 1), ins(0,\ \texttt{a},\ 0)) (\epsilon) &= \\
       ins(1,\ \texttt{b},\ 1)(\texttt{"a"}) &= \texttt{"ab"}
     \end{align*}

     \columnbreak
     Operation applied by $u_1$:
     \begin{align*}
       T(O_0, O_1) \circ ins(0,\ \texttt{b},\ 1) (\epsilon) &= \\
       T(ins(0,\ \texttt{a},\ 0), ins(0,\ \texttt{b},\ 1)) (\epsilon) &= \\
       ins(0,\ \texttt{a},\ 0)(\texttt{"b"}) &= \texttt{"ab"}
     \end{align*}
   \end{multicols}
   #+END_EXPORT
   #+BEGIN_EXPORT latex
   \begin{figure}[h]
     \centering
     \begin{tikzpicture}[>=stealth, shorten >= 5pt, node distance=1em, scale=1]
       \tikzstyle{vertex} = [circle, scale=0.5]
       \tikzstyle{O_0} = [vertex, fill=black!30!green]
       \tikzstyle{O_1} = [vertex, fill=black!30!blue]

       \tikzstyle{to} = [-{Stealth[scale=1.2]}]
       \tikzstyle{toO_0} = [to, color=black!30!green]
       \tikzstyle{toO_1} = [to, color=black!30!blue]

       \tikzstyle{op} = [above=-3pt, sloped, text=black]

       %% User 0 generates/receives in this order
       \node (u0) at (0, 5) {$u_0$};
       \node (u0e) at (0, 0) {};
       \node[O_0, below = of u0, label=left:{\texttt{a}}] (u00) {};
       \node[O_1, above = 2em of u0e, label=left:{\texttt{ab}}] (u01a) {};

       %% User 1 generates/receives in this order
       \node (u1) at (7, 5) {$u_1$};
       \node (u1e) at (7, 0) {};
       \node[O_1, below = 4em of u1, label=right:{\texttt{b}}] (u11) {} ;
       \node[O_0, below = 1em of u11, label=right:{\texttt{ab}}] (u10a) {};

       \draw[to, color=black!30] (u0) -- (u00) -- (u01a) -- (u0e);
       \draw[to, color=black!30] (u1) -- (u11) -- (u10a) -- (u1e);

       % Life of O_0
       \draw[toO_0] (u00) -- (u10a) node [op, pos=0.4] {$\overbrace{T(ins(0,\ \texttt{a},\ 0), ins(0,\ \texttt{b},\ 1))}^{ins(0,\ \texttt{a},\ 0)}$};

       % Life of O_1
       \draw[toO_1] (u11) -- (u01a) node [op, pos=0.6] {$\overbrace{T(ins(0,\ \texttt{b},\ 1), ins(0,\ \texttt{a},\ 0))}^{ins(1,\ \texttt{b},\ 1)}$};

     \end{tikzpicture}
     \caption{Conflict resolved using $T$.}
     \label{fig:conflict-resolved-transformation}
   \end{figure}
   #+END_EXPORT
   Note that $T(O_1, O_0) \circ O_0 \neq T(O_0, O_1) \circ O_1$ (i.e. the
   operations are not /equal/), but they are /equivalent/ in the sense that
   applying them to the same buffer yields the same result, denoted:
   #+BEGIN_EXPORT latex
   \[ T(O_1, O_0) \circ O_0 \equiv T(O_0, O_1) \circ O_1 \]
   #+END_EXPORT
   As shown, the transformation function $T$ can be used to resolve a conflict.
   However, the algorithm should be able to handle any number of concurrent
   operations, from an arbitrary number of clients, which may lead to conflicts
   of great complexity --- it is not given that the transformation function can
   resolve every conflict that can arise.

** Discussing Consistency in Operational Transformation

   This section introduces some consistency models that have been used to
   describe correctness of OT algorithms, and achievements in trying to verify
   these algorithms. In OT it is common to refer to a /site/ as a uniquely
   identified object with a data segment (for example a document) which a user
   can manipulate. When no messages are "in flight", the system is said to be
   /quiescence/.

   The consistency model of cite:ellis1989concurrency, is defined by the
   following two properties:

   - *Causality*[fn:1]: If $O_i$ was executed before $O_j$ at one site, then
     $O_i$ must be executed before $O_j$ on all sites.
   - *Convergence*: At quiescence, all copies are identical.

   Sun et al. cite:DBLP:journals/tochi/SunJZYC98 expanded the consistency model
   of cite:ellis1989concurrency with:

   - *Intention preservation*: If an operation $O_i$ has been transformed to
     $O_i'$, then the effects of applying $O_i'$ must be equivalent of that of
     applying $O_i$.

   dOPT is a fully distributed algorithm, where determining temporal
   relationships between events (i.e. generation and reception of operations)
   is a more challenging task than when leveraging a centralized server. It
   uses a /state vector/ (also referred to as a /vector clock/) which is
   essentially an extension of Lamport clocks cite:lamport1978time, yielding a
   partial order of events. An ordering being partial means that there exists
   events where neither event precedes the other, which means the events are
   /concurrent/.

   The dOPT algorithm ensures that operations are applied according to the
   partial order of events, where an event is either the generation of an
   operation or the reception of one. This ensures causality, but not
   convergence. Because the order is partial there are events that are
   concurrent; instead of trying to order these events /totally/ (i.e. ensure
   that for any two events, one will precede the other) a transformation
   function is used. Given two concurrent operations $O_i, O_j$, where $O_i$
   has already been applied, $O_j$ must be transformed with regards to $O_i$
   before it is applied.

   A transformation function $T$ must satisfy:
   #+BEGIN_EXPORT latex
   \begin{equation*}
     \tag{$C_1$}
     T(O_j, O_i) \circ O_i \equiv T(O_i, O_j) \circ O_j
     \label{eqn:C1}
   \end{equation*}
   #+END_EXPORT
   for all $O_i, O_j \in \mathcal O$ in order to guarantee convergence; this is
   a necessary, but not a sufficient condition cite:ellis1989concurrency. The
   transformation function $T$ from Figure [[ref:fig:transformation-function]] does
   not satisfy the condition, which has been shown by
   cite:DBLP:conf/ecscw/ImineMOR03.

   We have been able to reproduce the result by model checking our Maude
   specification. A minimal counter example, as shown in Figure
   [[ref:fig:disprove-c1]], involves two operations, $O_0 = \ins{0}{b}$ and $O_1 =
   del(0)$, applied to an initially non-empty buffer. The priority parameter is
   omitted in this example, because it has no effect on the outcome. Assume
   that both $u_0$ and $u_1$ initially has a buffer containing ~"a"~.
   #+BEGIN_EXPORT latex
   \begin{multicols}{2}
     From the perspective of $u_0$:
     \begin{ritemize}
     \item $\ins{0}{b}$ is generated locally,
     \item $O_1$ is received from $u_1$, $T(O_1, O_0)$ is applied.
     \end{ritemize}
     \columnbreak
     From the perspective of $u_1$:
     \begin{ritemize}
     \item $del(0)$ is generated locally,
     \item $O_0$ is received from $u_0$, $T(O_0, O_1)$ is applied.
     \end{ritemize}
   \end{multicols}
   #+END_EXPORT
   Again, the resulting buffer can be calculated by applying the respective
   operations to the buffer ~"a"~.
   #+BEGIN_EXPORT latex
   \begin{multicols}{2}
     Operation applied by $u_0$:
     \begin{align*}
       T(O_1, O_0) \circ \ins{0}{b} (\texttt{"a"}) &= \\
       T(del(0), \ins{0}{b}) (\texttt{"ba"}) &= \\
       del(1) (\texttt{"ba"}) &= \texttt{"b"}
     \end{align*}

     \columnbreak
     Operation applied by $u_1$:
     \begin{align*}
       T(O_0, O_1) \circ del(0) (\texttt{"a"}) &= \\
       T(\ins{0}{b}, del(0)) (\epsilon) &= \\
       \ins{-1}{b} (\epsilon) &= \textcolor{black!15!red}{error}
     \end{align*}
   \end{multicols}
   #+END_EXPORT
   #+BEGIN_EXPORT latex
   \begin{figure}[h]
     \centering
     \begin{tikzpicture}[>=stealth, shorten >= 5pt, node distance=1em, scale=1]
       \tikzstyle{vertex} = [circle, scale=0.5]
       \tikzstyle{O_0} = [vertex, fill=black!30!green]
       \tikzstyle{O_1} = [vertex, fill=black!30!blue]

       \tikzstyle{to} = [-{Stealth[scale=1.2]}]
       \tikzstyle{toO_0} = [to, color=black!30!green]
       \tikzstyle{toO_1} = [to, color=black!30!blue]

       \tikzstyle{op} = [above=-3pt, sloped, text=black]

       %% User 0 generates/receives in this order
       \node (u0) at (0, 5) {$u_0$};
       \node (u0e) at (0, 0) {};
       \node[draw=none, below = of u0, label=left:{\texttt{a}}] (u0l) {};
       \node[O_0, below = of u0l, label=left:{\texttt{ba}}] (u00) {};
       \node[O_1, above = 2em of u0e, label=left:{\texttt{b}}] (u01a) {};

       %% User 1 generates/receives in this order
       \node (u1) at (6, 5) {$u_1$};
       \node (u1e) at (6, 0) {};
       \node[draw=none, below = of u1, label=right:{\texttt{a}}] (u1l) {};
       \node[O_1, below = 5em of u1, label=right:{$\epsilon$}] (u11) {} ;
       \node[O_0, below = 1em of u11, label=right:{$\textcolor{black!15!red}{error}$}] (u10a) {};

       \draw[to, color=black!30] (u0) -- (u00) -- (u01a) -- (u0e);
       \draw[to, color=black!30] (u1) -- (u11) -- (u10a) -- (u1e);

       % Life of O_0
       \draw[toO_0] (u00) -- (u10a) node [op, pos=0.4] {$\overbrace{T(\ins{0}{b}, del(0))}^{\ins{-1}{b}}$};

       % Life of O_1
       \draw[toO_1] (u11) -- (u01a) node [op, pos=0.6] {$\overbrace{T(del(0), \ins{0}{b})}^{del(1)}$};

     \end{tikzpicture}
     \caption{Disproving \ref{eqn:C1}.}
     \label{fig:disprove-c1}
   \end{figure}
   #+END_EXPORT
   Here we demonstrate two problems with the transformation function. One is
   that the buffers diverged, seeing that $u_0$ and $u_1$ does not end up in
   the same final state. Secondly, the transformation function returns
   $\ins{-1}{b}$ which is not well defined, and is not in the set of operations
   $\mathcal O$. The problem is manifested in the second equation from Figure
   [[ref:fig:transformation-function]], where $<$ must be replaced with $\le$. The
   equation is restated correctly for completeness:
   #+BEGIN_EXPORT latex
     \[
     T(ins(p1,c1,pr1), del(p2,pr2)) =
     \begin{cases}
       ins(p1,c1,pr1)   & \text{if } p1 \le p2 \\
       ins(p1-1,c1,pr1) & \text{otherwise}
     \end{cases}
     \]
   #+END_EXPORT
   From what we can tell, the bug went unnoticed for many years[fn:2], which
   shows the subtleness of the bug --- uncovering bugs like this is hard, and
   is part of our motivation for using formal methods.

   The corrected version of $T$ satisfies ref:eqn:C1, but this is not
   sufficient for guaranteeing convergence in a fully distributed setting. It
   handles all conflicts where only two operations are involved; in order to
   handle any number of concurrent operations, being executed in an arbitrary
   order, $T$ must also satisfy:
   #+BEGIN_EXPORT latex
   \begin{equation*}
     \tag{$C_2$}
     T(T(O_k, O_i), O_j') = T(T(O_k, O_j), O_i')\\
     \label{eqn:C2}
   \end{equation*}
   #+END_EXPORT
   where $O_j' = T(O_j, O_i)$ and $O_i' = T(O_i, O_j)$ for all $O_i, O_j, O_k
   \in \mathcal O$. It has been proved that a transformation function $T$ that
   satisfies [[ref:eqn:C1]] and ref:eqn:C2 is sufficient in order to guarantee
   convergence cite:DBLP:conf/icde/SuleimanCF98,Lushman2003303.

   In cite:DBLP:conf/ecscw/ImineMOR03, Imine et al. show, using a theorem
   prover, that neither the corrected version of $T$ from
   cite:ellis1989concurrency, or any of transformation functions from
   cite:DBLP:conf/cscw/ResselNG96,DBLP:journals/tochi/SunJZYC98,DBLP:conf/group/SuleimanCF97
   satisfies [[ref:eqn:C1]] and ref:eqn:C2. Furthermore, they propose a
   transformation function of their own, which was proved correct by their
   theorem prover. Yet, in cite:DBLP:journals/corr/abs-1302-3292, they prove
   this transformation function wrong. This paper also shows that there does
   not exist a transformation function that satisfies [[ref:eqn:C1]] and ref:eqn:C2
   without adding additional parameters to the operations.

   To the best of our knowledge, there has not been found a transformation
   function that satisfies the consistency model of Sun et al.
   cite:DBLP:journals/tochi/SunJZYC98.

[fn:1] Referred to as the /Precedence Property/ in cite:ellis1989concurrency.
[fn:2] In cite:DBLP:conf/ecscw/ImineMOR03 Imine et al. credits the finding to
cite:DBLP:journals/tochi/SunJZYC98,DBLP:conf/icde/SuleimanCF98,DBLP:conf/cscw/ResselNG96,
but we have not been able to confirm that any of them uncovered that $T$ does
not satisfy ref:eqn:C1.

** Operational Transformation with a Client-Server Architecture

   In cite:nichols95, Nichols et al. introduces a simplified algorithm for OT
   in the Jupiter Collaboration System, based on GROVE
   cite:ellis1989concurrency, leveraging a centralized server. It is a
   symmetric algorithm, in the sense that the core algorithm is the same at the
   client and the server. As in GROVE, the document is replicated at every
   client, but the server keeps an additional copy of the document. Each client
   synchronizes its changes with the server, yielding a two-way synchronization
   protocol, as opposed to the fully distributed $N\text{-way}$ synchronization
   of GROVE.

   When a client generates an operation, it is communicated to the server. On
   reception of an operation, the server applies it to its document,
   transforming it if necessary, and sends the transformed operation to the
   other clients. When a client receives an operation from the server, the
   operation is transformed if necessary, and then applied to the client's
   local copy.

   Having a server guarantees that causality violation never occurs
   cite:ellis-ot, without the need for maintaining a state vector. This is
   because all communication is done via the server, so a client will receive
   all remotely generated operations (i.e. operations it did not generate
   itself) in the order the server received them.

   In the Jupiter Collaboration System each client-server pair must store the
   operations sent until they are acknowledged by their counterpart. This is
   because new operations might need to be transformed with regards to
   non-acknowledged operations.

   The Google Wave protocol is largely based on the Jupiter Collaboration
   System cite:WaveOT. In contrast to the Jupiter Collaboration System, the
   Google Wave protocol requires that clients wait for acknowledgement before
   sending new operations. Clients may still apply changes to their local copy,
   but need to queue the operations, and send them on reception of an
   acknowledgement. This reduces the memory consumption at the server, because
   the server will only need to keep one history of operations.

** Existing Implementations

   There are a wide range of existing implementations that supports
   collaborative editing. Providing a comprehensive survey on all existing
   solutions is not a goal of this thesis, so we will only briefly discuss a
   select few.

   One particularly interesting implementation is [[https://gobby.github.io/][Gobby]], which runs on the Obby
   protocol and is open. Through browsing the source code, we believe it is
   based on the Jupiter Collaborative System algorithm to ensure consistency
   between clients[fn:8]. It is a feature-full protocol, supporting things like
   group undo (only undo locally generated operations), group chat and more.

   There exists an Emacs extension called [[https://sourceforge.net/projects/rudel/][Rudel]], which supports the Obby
   protocol. It does however seem abandoned, and we have not been able to make
   it run on a modern Emacs distribution. In addition, the protocol seems
   non-trivial to implement, seeing that the extension is over 5000 lines of
   code.

   Another interesting implementation is [[https://floobits.com/][Floobits]], as it supports a wide range
   of editors, leveraging a centralized server. It is, however, not open and it
   can be used with a limited amount of "workspaces" in exchange for a monthly
   fee. Because the protocol is closed, we do not know how it resolves
   conflicts between participating clients.

** Shared Buffer in Comparison

   The Shared Buffer algorithm leverages a centralized server, similarly to the
   Jupiter Collaborative System. The main problem that Shared Buffer solves
   which, to the best of our knowledge is not covered in the literature, is to
   maintain consistency between clients without requiring complicated control
   mechanisms on the client side. It does this in an optimistic way, meaning
   that there are put no restrictions to when, or in what section of the
   buffer the clients may perform editing operations.

   When leveraging a centralized server, the transformation function used only
   needs to satisfy ref:eqn:C1 in order to guarantee convergence cite:ellis-ot.
   ref:eqn:C2 essentially states that the transformation function is not
   dependent on the order of which a sequence of operations are transformed
   cite:DBLP:conf/ecscw/ImineMOR03. As the server is the only entity that will
   perform transformations, there is only one order of which the operations
   will be transformed.

   There are complicating factors introduced by relieving the clients of having
   to applying control mechanisms themselves. One is that the client is the
   only entity that has a fully updated view of what operations it has
   performed. To deal with this, the algorithm must ensure that clients never
   perform operations received from the server, if the client is in conflict
   with the server. This is ensured by using a sequence number scheme (Section
   [[Sequence Number Scheme]]), which is very simple on the client side.

   Further complications arise when a client simply rejects outdated messages;
   in the Jupiter Collaboration System, the client would accept the operation,
   and transform it if necessary, which would leave it consistent with the
   server. Transformation functions only work for operations that are generated
   from the same state cite:sun1998reversible; when giving the client the
   opportunity to generate operations from an inconsistent state, then
   transformation functions alone cannot be used to ensure consistency. To
   resolve this, the new operations from the client must be reset to a
   consistent state; to achieve this we leverage /exclusion/ transformations
   cite:DBLP:journals/tochi/SunJZYC98, which can be seen as the dual of the
   transformation functions we have seen so far.

   Shared Buffer does not rely heavily on transformation functions, and instead
   try to order operations in a way that preserves the users intentions. This
   has proved successful for the majority of cases, but transformation
   functions are needed to deal with some edge cases; these are typically the
   cases where multiple operations are performed at the same position in the
   buffer.

   The Shared Buffer algorithm borrows ideas from both fully distributed
   algorithms and the Jupiter Collaborative System. It has similarities to the
   GOT algorithm cite:DBLP:journals/tochi/SunJZYC98, in that it uses both
   inclusion and exclusion transformation functions. The GOT algorithm also
   uses a undo/do/redo-scheme which is similar to Shared Buffer. A main
   distinction is that Shared Buffer constructs operations that will undo
   operations on the clients behalf.

   The consistency model used for Shared Buffer is a weak consistency model,
   namely /eventual consistency/ cite:Vogels:2009:EC:1435417.1435432. This was
   chosen because it can naturally be seen as a minimum requirement for a
   real-time collaborative system. In addition, it is a property which is easy
   to express in LTL (Linear Temporal Logic), which allows us to use the Maude
   LTL model checker for verification. Requirements with regards to preserving
   user intent is not formally specified, but measures are taken to preserve
   user intent in the majority of cases.

   The system has been formally specified and model checked, and has been
   verified correct for a small number of clients and operations (see Section
   [[Experiments]]). This means that it handles /all possible conflicts/ that can
   occur within the set bounds. Our specification is /broader/ than that of
   Imine et al. in the sense that we model the clients, the server and the flow
   of messages, where as the work of Imine et al. focuses on properties of the
   transformation functions. This gives us confidence that the algorithm is
   correct in its entirety.

[fn:8] We have skimmed the source code and found files with "jupiter" in the
name, which indicates that the Jupiter algorithm is used. However, we have not
found this explicitly stated in the documentation or done a comprehensive study
of the source code.

* Client-side Specification

  The Shared Buffer System is formally modeled using The Maude System. Modeling
  a system is in essence capturing what can occur in the system in a precise
  manner, at a suitable level of abstraction. For instance, it is important to
  model that clients can send messages concurrently, and that there is no way
  to a priori determine the order of which they are received by the server. On
  the other hand, we merely assume that messages between a given client and the
  server are delivered in order, undamaged and without duplication, and make no
  attempt to model how this is achieved.

  Earlier work on formal verification of /Operational Transformation/ (OT)
  algorithms has been focused on verifying properties of the /transformation
  functions/ (as discussed in Section [[Discussing Consistency in Operational
  Transformation]]), which is an essential part of all OT algorithms. However,
  there are other aspects of the algorithms, that are left unverified, leaning
  on analytical proofs by the original authors. Instead of writing analytical
  proofs we leverage formal methods to ensure robustness of the system.

  We aim at modeling the clients, the server and the communication between
  these, but restrict ourselves to editing sessions where all the clients have
  the same initial buffer and a constant number of connected clients. The
  algorithm is a part of the specification, and therefore also subject for
  verification. To the best of our knowledge, formal verification techniques
  has not been applied on a /complete/ real-time collaboration algorithm in the
  literature before.

  The verification technique we have chosen to apply is model checking. Proving
  properties of a finite-state system using model checking is /decidable/, but
  if the system has an infinite number of reachable states, there is no
  guarantee that the model checker will terminate. Our system is infinite as
  there can be an arbitrary number of operations, an arbitrary number of
  clients, with an infinite number of different initial buffers. If we were to
  model the system without limitations, the model checker would not necessarily
  terminate. In order to deal with this the system is modeled as a finite
  system, where the number of operations, the number of clients and an initial
  buffer are given as parameters when model checking.

  # We need to emphasize that model checking prove properties for finite-state
  # models. A buffer can be in an infinite number of states, seeing that
  # nothing prevents the user from adding another character to its buffer. If
  # our model has no bounds on the number of operations then there would be an
  # infinite number unique reachable states. This means we cannot possibly
  # prove properties of the system by model checking. However, by adding
  # boundaries to the number of operations and to the number of clients, we can
  # prove properties of the system under that that restriction. Thus, we will
  # not provide a proof that the Shared Buffer Algorithm is correct.

  # Dette avsnittet suger:
  This chapter starts of by giving a short introduction to the Maude language
  and how we specify the system. We will then go on to specify the behavior of
  the clients. The equations in this chapter are translations of the Maude
  specification. For rewrite rules (that we will introduce shortly) we use
  Maude syntax in favor of mathematical notation.

** A Short Introduction to Maude

   The Maude System consists of a programming and modeling language, as well as
   tools for exploring the state space of the model. In essence, Maude is an
   implementation of /rewriting logic/ which has proved useful for modeling
   distributed systems cite:peter.

   A Maude specification consists of /sorts/, /signatures/, /variables/,
   /equations/ and /rewrite rules/. A sort is simply a label that is associated
   with some value. A signature defines a function symbol, along with its
   domain and codomain, which constitutes the values of a sort (where a
   constant is represented as a function symbol with arity zero). The values of
   a specification are constructed by applying function symbols with respect to
   their domains, and yields what is called a /ground term/. Variables must be
   of a given sort and is essentially a placeholder for a ground term; a term
   (i.e. "non-ground") can contain variables, which is what separates it from a
   /ground/ term.

   An equation is a relation that takes a left-hand and a right-hand term; it
   symbolizes that the terms are considered equivalent. Rewriting rules are
   similar to equations, but the terms does not need to be equivalent. Rather,
   a rewriting rule symbolizes that the left-hand term /may evolve/ to the
   right-hand term, and is strictly read left to right. The equations of the
   system represents the /static/ part of the system, and the rewrite rules
   represent the /dynamic/ part of the system.

   Two fundamental commands in The Maude System helps to shed light on how
   equations and rewriting rules operate. The /reduce/ command takes a term and
   if the term (or a subterm) matches the left-hand term of an equation, it is
   rewritten to the right hand term, and the process continues until the
   reduced term does not match any equation in the specification. The /rewrite/
   command can be given an argument deciding how many rewrites it performs. It
   takes a term which it applies to an arbitrary rewrite rule that matches the
   left-hand term of the rule, followed by reducing the resulting term. The
   process is repeated until it has reached the specified number of rewrites,
   or if no more rewrites can be applied. It can be useful to think of an
   equation as special case of a rewrite rule which is always applied
   immediately.

   # A reduction should be deterministic, meaning that, for a given input, it
   # always yields the same term. On the other hand, a rewrite may be
   # nondeterministic

   In our specification, we use rewrite rules to describe nondeterministic
   changes in the system, like a user inserting or deleting a character from
   its buffer. The equations are used to describe the system's reaction to the
   changes in the system, which is deterministic.

   # The equational membership logic is very similar to a functional programming
   # language, in the sense that they are both declarative and have the same
   # expressive power. By stating a set of equations we can represent any
   # /static/ part of the system, that is, the parts that for a given input
   # always yields the same output.

   # The /dynamic/ behaviour of a system is described by a set of rewriting
   # rules,

** Client-side Specification

   In Chapter [[Formal Semantics of Editing Operations]] we defined operations and
   how they are applied. This was stated as a set of equations which has been
   translated to Maude. The Maude representation is almost identical with the
   aforementioned definitions, but operation application is syntactically
   different and have not modeled the entire $Unicode$ set, but rather chosen a
   small set of characters.

   A client consists of a user label, buffer, sequence number, state token,
   along with an incoming and outgoing message queue. The following Maude term,
   where capital letters are variables of the appropriate sort, will match any
   user:

   #+BEGIN_EXAMPLE
   < U | buffer : B, seqno : N, token : T, out-queue : Q, in-queue: Q' >
   #+END_EXAMPLE

   An example of a ground term that will match the term above can look like so:

   #+BEGIN_EXAMPLE
   < user 0 | buffer : nil, seqno : 0, token : 0,
              in-queue : nil, out-queue : nil >
   #+END_EXAMPLE

   Note that =nil= is used to represent both an empty buffer and an empty
   queue. A user may nondeterministically insert a character to its buffer,
   which is represented using a rewrite rule, where ~=>~ symbolizes the rewrite
   relation [fn:3]:

   #+BEGIN_EXAMPLE
       rl [user-inserts] :
           < U | buffer : (B B'), seqno : S, token : T, out-queue : Q >
         =>
           < U | buffer : (B C B'), seqno : s S, token : T,
                 out-queue : (msg(ins(size(B), C), T, S) Q) > .
   #+END_EXAMPLE

   The buffer is represented as =(B B')=, where both =B= and =B'= are any two
   buffers that matches the client's buffer when concatenated (where
   concatenating buffers is analogous to concatenation of strings). Note that
   the buffers may be empty. Assuming we have a character =C= (where a
   character is treated as a string of length one), an insertion is simply
   placing a character in between the two buffers, which yields a new buffer
   =(B C B')=. This rule enables =C= to be inserted at any point in the buffer,
   because we have not put any restriction on =B= and =B'= besides that they
   together form the complete buffer.

   The client must communicate its change to the server, which is modeled as
   putting a message on in its outgoing queue. A message, denoted =msg=,
   consists of an operation, a state token and a sequence number. The size of
   =B= determines the position of the insertion, and so =ins(size(B), C)=
   represents that =C= was inserted at position =size(B)=. The current state
   token =T= and sequence number =S= is added to the message. Lastly, the
   client must increment its sequence number, using the successor function =s=.
   The rule for deletion is almost identical, with the difference of removing a
   character from the buffer, rather than inserting one, and labeling the
   operation =del=.

   The server can put messages on a client's incoming queue, which the client
   in turn (eventually) reads from. In order to model the latency of messages
   traveling, it reads from the queue in an nondeterministic manner. The
   following rewrite rule may be applied if the sequence number of the client
   is equal to the sequence number of the message at the end of its incoming
   queue:

   #+BEGIN_EXAMPLE
   rl [user-receive] :
       < U | buffer : B, seqno : S, token : T,
             in-queue : (Q msg(O,T',S)) >
     =>
       < U | buffer : apply O on B, seqno : s S, token : T',
             in-queue : Q > .
   #+END_EXAMPLE

   Notice that the variable =S= is used both as the client sequence number and
   the sequence number of the message to ensure that the sequence numbers are
   equal. On reception of a message the operation is applied to the client's
   local buffer, the sequence number is incremented and the state token of the
   message replaces the current state token of the client. Note that =apply O
   on B= is a term that will match an equation which applies the operation =O=
   to =B=. It is syntactically different from $O(B)$, which we have seen in
   previous chapters, but semantically identical.

   Similarly, there is a rule for rejecting a message, which may be applied if
   an incoming message has a sequence number that is /not/ equal to the
   sequence number of the client. In that case the message is removed from the
   queue, and the sequence number is incremented; nothing else changes.

   At this point we can try to perform rewrites on a term containing multiple
   users, and they will insert and delete characters and add messages to their
   outgoing queue. Seeing that we have not specified a server yet, they will
   not receive any messages and their outgoing queue will grow monotonically.
   Their respective buffers are likely to diverge. Here is an example of two
   users starting with an empty buffer after three rewrites:

   #+BEGIN_EXAMPLE
   < user 0 | buffer : nil, seqno : 2, token : 0, in-queue : nil,
              out-queue : (msg(del(0, a), 0, 1) msg(ins(0, a), 0, 0)) >

   < user 1 | buffer : b, seqno : 1, token : 0, in-queue : nil,
              out-queue : msg(ins(0, b), 0, 0) >
   #+END_EXAMPLE

   From the resulting term we can read that $u_0$ (i.e. =user 0=) has inserted
   an =a=, and deleted it afterwards, while $u_1$ has inserted a =b=.

*** Measures to Reduce the State Space

    The /state explosion problem/ is considered the main obstacle for model
    checking cite:DBLP:conf/laser/ClarkeKNZ11. When performing model checking,
    an initial state must be given; in Maude this corresponds to a term. If the
    term matches a rewrite rule, it may be applied which in turn yields a new
    state. A term can match multiple rewrite rules, so the number of reachable
    states is given by the sum of how many rewrite rules the initial term
    matches, and how many rewrite rules each of the resulting terms matches and
    so on. There may be an infinite number of reachable states.
    # The number of /reachable/ states from that term is given by all the
    # possible ways that rewrite rules can be applied. The number of reachable
    # states is often exponential with regards to the

    # --- for a model to be useful for
    # verification, the state space generally needs to be kept at a manageable
    # size.

    Our focus has been on writing a specification which accurately
    describes the system, rather than optimizing the specification for
    verification; nevertheless, some measures has been taken to reduce the
    state space and are documented here.

    In reality, a user could decide to type any arbitrary character at any
    given time; in the model, all insertions are done alphabetically, meaning
    the first insertion is always an =a=, the second is a =b= and so on. This
    is necessary in order to keep the state space at a manageable size. What
    character the user types is of no importance to the algorithm, so there is
    no need to check what would happen if, say, =b= where typed before =a=.

    Another restriction is put on which user performs an operation at a given
    time. Users are labeled because the server needs information about each
    individual user; however, if we were to swap all $u_0$ labels with $u_1$,
    it would have no effect on the scenario, as long as /all/ labels are
    swapped. It can be helpful to look at a visualized scenario and permute the
    labels at the top to see that the scenarios are symmetric, and checking
    both is redundant.

    #+BEGIN_EXPORT latex
    \begin{figure}[h]
      \centering
      \begin{subfigure}{.5\textwidth}
        \centering
        \begin{tikzpicture}[>=stealth, shorten >= 5pt, node distance=1em, scale=1]
          \tikzstyle{vertex} = [circle, scale=0.5]
          \tikzstyle{O_0} = [vertex, fill=black!30!green]
          \tikzstyle{O_1} = [vertex, fill=black!30!blue]

          \tikzstyle{to} = [-{Stealth[scale=1.2]}]
          \tikzstyle{toO_0} = [to, color=black!30!green]
          \tikzstyle{toO_1} = [to, color=black!30!blue]

          \tikzstyle{op} = [midway, above=-3pt, sloped, text=black, font=\scriptsize]

          %% Server receives operations in this order
          \node (s) at (2.5, 4) {$S$};
          \coordinate (se) at (2.5, 0) {};
          \node[O_0, below = 3em of s] (s1) {};
          \node[O_1, below = 1em of s1] (s2) {};

          %% User 0 generates/receives in this order
          \node (u0) at (0, 4) {$u_0$};
          \node (u0e) at (0, 0) {};
          \node[O_0, below = of u0] (u00) {};
          \node[O_1, above = 2em of u0e] (u01) {};
          \node[O_0, above = of u01] (u00a) {};

          %% User 1 generates/receives in this order
          \node (u1) at (5, 4) {$u_1$};
          \node (u1e) at (5, 0) {};
          \node[O_1, below = 1.5em of u1] (u11) {} ;
          \node[O_0, below = 3em of u11] (u10a) {};
          \node[O_1, above = 2em of u1e] (u11a) {};

          \begin{pgfonlayer}{bg} % select the background layer
            \draw[to, color=black!30] (s) -- (s1)  -- (s2) -- (se);
            \draw[to, color=black!30] (u0) -- (u00) -- (u01) -- (u0e);
            \draw[to, color=black!30] (u1) -- (u11) -- (u10a) -- (u1e);

            % Life of O_0
            \draw[toO_0] (u00) -- (s1) node [op] {$\overbrace{\ins{0}{a}}^{O_0}$};
            \draw[toO_0] (s1) -- (u00a) node [op] {$nop$};
            \draw[toO_0] (s1) -- (u10a) node [op, near end] {$O_0$};

            % Life of O_1
            \draw[toO_1] (u11) -- (s2) node [op] {$\overbrace{\ins{0}{b}}^{O_1}$};
            \draw[toO_1] (s2) -- (u01) node [op] {$O_1$};
            \draw[toO_1] (s2) -- (u11a) node [op] {$O_1 \circ O_0 \circ O_1^{-1}$};
          \end{pgfonlayer}
        \end{tikzpicture}
      \end{subfigure}%
      \begin{subfigure}{.5\textwidth}
        \centering
        \begin{tikzpicture}[>=stealth, shorten >= 5pt, node distance=1em, scale=1]
          \tikzstyle{vertex} = [circle, scale=0.5]
          \tikzstyle{O_0} = [vertex, fill=black!30!green]
          \tikzstyle{O_1} = [vertex, fill=black!30!blue]

          \tikzstyle{to} = [-{Stealth[scale=1.2]}]
          \tikzstyle{toO_0} = [to, color=black!30!green]
          \tikzstyle{toO_1} = [to, color=black!30!blue]

          \tikzstyle{op} = [midway, above=-3pt, sloped, text=black, font=\scriptsize]

          %% Server receives operations in this order
          \node (s) at (2.5, 4) {$S$};
          \coordinate (se) at (2.5, 0) {};
          \node[O_0, below = 3em of s] (s1) {};
          \node[O_1, below = 1em of s1] (s2) {};

          %% User 0 generates/receives in this order
          \node (u0) at (5, 4) {$u_1$};
          \node (u0e) at (5, 0) {};
          \node[O_0, below = of u0] (u00) {};
          \node[O_0, above = 3.5em of u0e] (u00a) {};
          \node[O_1, above = 2em of u0e] (u01) {};

          %% User 1 generates/receives in this order
          \node (u1) at (0, 4) {$u_0$};
          \node (u1e) at (0, 0) {};
          \node[O_1, below = 1.5em of u1] (u11) {} ;
          \node[O_0, below = 3em of u11] (u10a) {};
          \node[O_1, above = 2em of u1e] (u11a) {};

          \begin{pgfonlayer}{bg} % select the background layer
            \draw[to, color=black!30] (s) -- (s1)  -- (s2) -- (se);
            \draw[to, color=black!30] (u0) -- (u00) -- (u01) -- (u0e);
            \draw[to, color=black!30] (u1) -- (u11) -- (u10a) -- (u1e);

            % Life of O_0
            \draw[toO_0] (u00) -- (s1) node [op] {$\overbrace{\ins{0}{a}}^{O_0}$};
            \draw[toO_0] (s1) -- (u00a) node [op] {$nop$};
            \draw[toO_0] (s1) -- (u10a) node [op, near end] {$O_0$};

            % Life of O_1
            \draw[toO_1] (u11) -- (s2) node [op] {$\overbrace{\ins{0}{b}}^{O_1}$};
            \draw[toO_1] (s2) -- (u01) node [op] {$O_1$};
            \draw[toO_1] (s2) -- (u11a) node [op] {$O_1 \circ O_0 \circ O_1^{-1}$};
          \end{pgfonlayer}
        \end{tikzpicture}
      \end{subfigure}
      \caption{Permuting labels.}
      \label{fig:permuting-labels}
    \end{figure}
    #+END_EXPORT
    A scheme is imposed where $u_0$ always performs the first operation, $u_0$
    or $u_1$ performs the second, $u_0$, $u_1$ or $u_2$ performs the third, and
    so on. This corresponds to allowing the scenario to the left from Figure
    [[ref:fig:permuting-labels]] to occur, but not the scenario on the right.

    In the example at the end of the last section, three rewrites were made.
    Without the restriction of $u_0$ performing the first operation, there
    would be 49 reachable states. When imposing the scheme, only 25 different
    states can be reached within three rewrites, reducing the state space by a
    factor of 2. As the number of users grow, the reduction of states
    increases.

    # redo, du har brukt end-states ikke reachable states.
    #+CAPTION: Reachable states after three rewrites with and without restriction.
    | Number of users          | 2 users | 3 users | 4 users | 5 users | 6 users |
    |--------------------------+---------+---------+---------+---------+---------|
    | Non-restricted           |      49 |     106 |     193 |     316 |     481 |
    | Restricted               |      25 |      29 |      29 |      29 |      29 |
    | Reduction by a factor of |    1.96 |    3.66 |    6.66 |    10.9 |   16.59 |

    Note that the server only reacts to incoming messages, and never acts on
    its own accord. This is why the only measures to reduce the state space is
    done by imposing restrictions on the clients.

* Server-side Specification

  At this point the behavior of clients has been specified. The more
  interesting part of the system is the server, as it handles most of the
  complexity in the algorithm. This chapter fully describes the server-side
  algorithm.

  The server maintains a /state token/, a /history/ and a mapping from users to
  a list of possibly rejected operations associated with a token. For every
  operation received, the server increments its state token, which is one
  initially. The history determines the order of which operations should be
  applied. The list of possibly rejected operations (associated with a token)
  is used to construct an operation which will make the client consistent with
  the current history. When receiving a message from a client, we assume that
  there exists a way of uniquely identifying the client --- in the model this
  is a user identifier.

** Events

   An essential part of the server algorithm is maintaining a history, where
   the entries in a history are /events/. There is only one type of event at
   the system, namely the reception of a message, containing an operation, a
   token and a sequence number.
   #+BEGIN_EXPORT latex
   \\
   \begin{definition}[Events]
     The events on a server $S$ communicating with a set of clients, identified by
     users in $\mathcal U$, is formally defined as the smallest set of four-tuples
     $\mathbb E$, where every $\tuple{O,t,m, u} \in \mathbb E$ satisfies the
     following:
     \begin{itemize}
     \item \(O \in \mathcal O\) and $O$ is not a composition of operations
     \item \(t \in \mathbb N\)
     \item \(m \in \mathbb N\)
     \item \(u \in \mathcal U\)\hfill$\dashv$
     \end{itemize}
   \end{definition}
   #+END_EXPORT
   # The events are constructed based on a message $msg(O, t, s)$ from $u \in
   # \mathcal U$ and a logical clock $m$ maintained on the server.
   Given a message $msg(O, t, s)$ sent from $u \in \mathcal U$ and received by
   the server at time $m$, the event $\tuple{O, t, m, u}$ is constructed.
   Remember that the token $t$ is only updated at the client when it
   successfully receives a message from the server (i.e. does not reject); it
   implies that the latest message the client has received was when the
   server's state token was $t$. Furthermore, we rely on the client to have
   executed all operations with a time stamp smaller than $t$.

   The history of events dictates an order of which operations should be
   applied. In the case where there are no concurrent events, the arrival time
   $m$ is used to determine what event should precede the other. But to decide
   an order, we first need to be able to detect concurrent operations.
   Intuitively, two operations are concurrent if they were generated
   independently from each other.
   #+BEGIN_EXPORT latex
   \\
   \begin{definition}[Concurrent Events]\label{def:concurrent}
     Two events $E_i = \tuple{O_i, t_i, m_i, u_i}$ and $E_j = \tuple{O_j, t_j,
       m_j, u_j}$, where $E_i, E_j \in \mathbb E$, are said to be concurrent if:
     \[ u_i \not= u_j \land ((t_i \leq t_j \land m_i \geq t_j) \lor (t_j \leq t_i \land m_j \geq t_i)) \]
     $E_i$ is concurrent with $E_j$ is denoted $E_i \parallel E_j$.
     \hfill$\dashv$
   \end{definition}
   #+END_EXPORT

   A user cannot produce concurrent events; The first criteria of the
   definition $u_i \not= u_j$ ensures that events performed by the same user
   cannot be considered concurrent. Note that an event is not concurrent with
   itself by this definition; the case is ignored because there is never a
   need to examine the relationship between an event and itself. There are no
   duplicate events in the system, seeing that the time stamp is guaranteed to
   be unique.

   Let us now consider $t_i \leq t_j \land m_i \geq t_j$. It is helpful to read
   it as: "$O_i$ was generated at same time or before $O_j$ was generated, but
   $O_i$ arrived at the server at the same time or after $O_j$ was generated".
   If $t_i \leq t_j$ then it cannot be the case that $O_i$ was generated after
   having applied $O_j$. Similarly, if $t_j \leq m_i$ then it cannot be the
   case that $O_j$ was generated after having applied $O_i$. When the
   operations were generated independently from each other, we say they are
   concurrent. By the same reasoning, $E_j$ is concurrent with $E_i$ if $t_j
   \leq t_i \land m_j \geq t_i$, assuring symmetry.

   Given two non-concurrent events, one must have /happened before/ the other.
   Note that this /happened before/-relation is defined in terms of a state
   token and a time stamp, and does not necessarily represent which event
   happened before the other in /real/ time.
   #+BEGIN_EXPORT latex
   \\
   \begin{definition}[Happened Before]\label{def:happened-before}
     An event $E_i = \tuple{O_i, t_i, m_i, U_i}$ \textit{happened before} $E_j =
     \tuple{O_j, t_j, m_j, U_j}$, where $E_i, E_j \in \mathbb E$, if:
     \[ E_i \nparallel E_j \land m_i < m_j \]
     $E_i$ \textit{happened before} $E_j$ is denoted $E_i \longrightarrow E_j$. \hfill$\dashv$
   \end{definition}
   #+END_EXPORT

   If the events are not concurrent, then the arrival time is used to determine
   which event happened before the other.
   #+BEGIN_EXPORT latex
   \begin{figure}[h]
     \centering
     \begin{tikzpicture}[>=stealth, shorten >= 5pt, node distance=4em, scale=1]
       \tikzstyle{vertex} = [circle, scale=0.5]
       \tikzstyle{O_0} = [vertex, fill=black!30!green]
       \tikzstyle{O_1} = [vertex, fill=black!30!blue]
       \tikzstyle{O_2} = [vertex, fill=black!30!red]

       \tikzstyle{to} = [-{Stealth[scale=1.2]}]
       \tikzstyle{toO_0} = [to, color=black!30!green]
       \tikzstyle{toO_1} = [to, color=black!30!blue]
       \tikzstyle{toO_2} = [to, color=black!30!red]

       \tikzstyle{op} = [pos=0.62, above=-3pt, sloped, text=black, font=\small]

       %% Server receives operations in this order
       \node (s) at (0, 9) {$S$};
       \coordinate (se) at (0, 0) {};
       \node[O_0, below = 2em of s,   label=left:{$\small\overbrace{\tuple{O_0, 0, 1, u_0}}^{E_0}$}] (s1) {};
       \node[O_1, below = 6em of s1,  label=left:{$\small\overbrace{\tuple{O_1, 0, 2, u_1}}^{E_1}$}] (s2) {};
       \node[O_2, above = 8em of se, label=left:{$\small\overbrace{\tuple{O_2, 2, 3, u_2}}^{E_2}$}] (s3) {};

       %% User 0 generates/receives in this order
       \node (u2) at (10, 9) {$u_0$};
       \node (u2e) at (10, 0) {};
       \node[O_0, below = 1em of u2] (u20) {};
       \node[O_0, below = 2em of u20] (u20a) {};
       \node[O_1, below = 7em of u20a] (u21a) {};
       \node[O_2, above = 3em of u2e] (u22a) {};

       %% User 1 generates/receives in this order
       \node (u0) at (8.5, 9) {$u_1$};
       \node (u0e) at (8.5, 0) {};
       \node[O_1, below = 6em of u0] (u01) {};
       \node[O_0, below = 2em of u01] (u00r) {}; % cross out
       \node[O_1, below = 3em of u00r] (u02) {};
       \node[O_2, above = 6em of u0e] (u02a) {};

       %% User 1 generates/receives in this order
       \node (u1) at (6, 9) {$u_2$};
       \node (u1e) at (6, 0) {};
       \node[O_0, below = 4.5em of u1] (u10a) {};
       \node[O_2, below = 7em of u10a] (u12) {};
       \node[O_1, below = 2em of u12] (u11r) {}; % cross out
       \node[O_2, above = 2.5em of u1e] (u12a) {};

       \begin{pgfonlayer}{bg} % select the background layer
         %\draw[to, color=black!30, text=black] (t) -- (te) node [midway, fill=white] {time};
         \draw[to, color=black!30] (s) -- (s1)  -- (s2)  -- (s3) -- (se);
         \draw[to, color=black!30] (u0) -- (u01) -- (u00r) -- (u02) -- (u02a) -- (u0e);
         \draw[to, color=black!30] (u1) -- (u10a) -- (u12) -- (u11r) -- (u12a) -- (u1e);
         \draw[to, color=black!30] (u2) -- (u20) -- (u20a) -- (u21a) -- (u22a) -- (u2e);

         % Life of O_0
         \draw[toO_0] (u20) -- (s1) node [op] {$\overbrace{\ins{0}{a}}^{O_0}$};
         \draw[toO_0] (s1) -- (u00r) node [op] {};
         \draw[toO_0] (s1) -- (u10a) node [op] {};
         \draw[toO_0] (s1) -- (u20a) node [op] {};

         % Life of O_1
         \draw[toO_1] (u01) -- (s2) node [op] {$\overbrace{\ins{1}{b}}^{O_1}$};
         \draw[toO_1] (s2) -- (u02) node [op] {};;
         \draw[toO_1] (s2) -- (u11r) node [op] {};
         \draw[toO_1] (s2) -- (u21a) node [op] {};

         % Life of O_2
         \draw[toO_2] (u12) -- (s3) node [op] {$\overbrace{\ins{0}{c}}^{O_2}$};
         \draw[toO_2] (s3) -- (u02a) node [op] {};
         \draw[toO_2] (s3) -- (u12a) node [op] {};
         \draw[toO_2] (s3) -- (u22a) node [op] {};
       \end{pgfonlayer}
     \end{tikzpicture}
     \caption{A non-trivial example.}
     \label{fig:non-trivial-happened-before/concurrency-example}
   \end{figure}
   #+END_EXPORT

   Let us look at a non-trivial example of a scenario and examine the
   relationships between events. The scenario is visualized in Figure
   [[ref:fig:non-trivial-happened-before/concurrency-example]]. We have the
   following three events:
   #+BEGIN_EXPORT latex
   \begin{align*}
     E_0 &= \tuple{O_0, t_0, m_0, u_0} = \tuple{O_0, 0, 1, u_0} \\
     E_1 &= \tuple{O_1, t_1, m_1, u_1} = \tuple{O_1, 0, 2, u_1} \\
     E_2 &= \tuple{O_2, t_2, m_2, u_2} = \tuple{O_2, 2, 3, u_2}
   \end{align*}
   #+END_EXPORT
   Their relationships are as follows:
   - $E_0 \parallel E_1$. The events were generated with the same state token, and the
     state token of $E_0$ is smaller than the arrival time of $E_1$. More
     precisely, they are concurrent because the operations are performed by
     different users and $t_0 \leq t_1 \land m_0 \geq t_1$.
   - $E_0 \longrightarrow E_2$. This is because $u_2$ received $O_0$ before
     generating $O_2$. More precisely, they are not concurrent because $t_0
     \leq t_2 \land m_0 \not\geq t_2$ and $t_2 \not\leq t_0 \land m_2 \geq
     t_0$, and $E_0 \longrightarrow E_2$ because $m_0 < m_2$.
   - $E_1 \parallel E_2$. The state token of $E_1$ is smaller than that of
     $E_2$, but the arrival time of $E_1$ the equal to the state token of
     $E_2$, meaning $O_2$ was generated before $O_1$ was received. More
     precisely, the events are performed by different users and $t_1 \leq t_2
     \land m_1 \geq t_2$.
   It can be helpful to notice that there is a correspondence between
   overlapping lines in the diagram and events being concurrent.

** An Ordering of Events

   The history maintained on the server should respect an ordering $\prec$.
   This ordering must respect the /happened before/-relation, meaning that for
   any two events $E_i, E_j \in \mathbb E$ where if $E_i \longrightarrow E_j$
   then $E_i \prec E_j$. The question that remains is how to order concurrent
   events.

   Let us first take a step back to make a useful observation. Say a character
   is inserted at point $i$ in a given buffer. The characters that were
   located at positions $0$ to $i$ (exclusive) remain at the same position ---
   the characters that were located at $i$ or higher are shifted one step to
   the right. Similarly for deletions, characters that were located at
   position $0$ to $i$ (exclusive) stay where they were, but characters
   located at point $i+1$ or higher are shifted to the left (the character
   that were at point $i$ is deleted).

   Say we have two operations $\ins{2}{x}$ and $\ins{4}{y}$ and both are
   independently applied to the buffer ="abcdef"=.
   #+BEGIN_EXPORT latex
   \begin{align*}
     \ins{2}{x} (\texttt{"abcdef"}) &= \texttt{"ab\textcolor{black!30!blue}{x}cdef"}\\
     \ins{4}{y} (\texttt{"abcdef"}) &= \texttt{"abcd\textcolor{black!30!red}{y}ef"}
   \end{align*}
   #+END_EXPORT
   Two ways of combining the operations are $\ins{4}{y} \circ \ins{2}{x}$ and
   $\ins{2}{x} \circ \ins{4}{y}$. Applying them to the buffer ="abcdef"=
   yields different results.
   #+BEGIN_EXPORT latex
   \begin{alignat*}{2}
     \ins{4}{y} \circ \ins{2}{x} (\texttt{"abcdef"})&=
     \ins{4}{y}(\texttt{"ab\textcolor{black!30!blue}{x}cdef"})&&=
     \texttt{"ab\textcolor{black!30!blue}{x}c\textcolor{black!30!red}{y}def"}\\
     \ins{2}{x} \circ \ins{4}{y} (\texttt{"abcdef"}) &=
     \ins{2}{x}(\texttt{"abcd\textcolor{black!30!red}{y}ef"})&&=
     \texttt{"ab\textcolor{black!30!blue}{x}cd\textcolor{black!30!red}{y}ef"}
   \end{alignat*}
   %% \begin{alignat*}{2}
   %%   \ins{4}{y} \circ \ins{2}{x} (\texttt{"abcdef"})&=
   %%   \ins{4}{y}(\texttt{"\textcolor{gray}{ab}x\textcolor{gray}{cdef}"})&&=
   %%   \texttt{"\textcolor{gray}{ab}x\textcolor{gray}{c}y\textcolor{gray}{def}"}\\
   %%   \ins{2}{x} \circ \ins{4}{y} (\texttt{"abcdef"}) &=
   %%   \ins{2}{x}(\texttt{"\textcolor{gray}{abcd}y\textcolor{gray}{ef}"})&&=
   %%   \texttt{"\textcolor{gray}{ab}x\textcolor{gray}{cd}y\textcolor{gray}{ef}"}
   %% \end{alignat*}
   #+END_EXPORT
   Notice that in both cases =x= was placed between =b= and =c=. On the other
   hand =y= was placed between =c= and =d= in the first case, and between =d=
   and =e= in the second. Originally =y= was placed between =d= and =e=, so we
   can assume that was the /intention/ of the user. We make the general rule,
   that when the positions of two operations differ, the operation with the
   highest position should always be performed first.

   Given two operations that operates on the same position, then deletions
   should always be performed before insertions. If the insertion is done
   first, then the delete operation would simply remove the character which
   was just inserted, which does not seem to satisfy either user. If the
   deletion is done first, the correct character is deleted and the insertion
   is placed between the characters it wanted, with the exception of the
   character immediately in front of it. Finally, if the operations are of the
   same type and operate on the same position, then the arrival time is used
   as a tiebreaker.

   The following defines when an event is said to precede another. Two
   accessor functions for operations are used, where $pos$ returns the
   position argument of the operation, and $type$ returns $ins$ or $del$,
   depending on the operation being an insertion or deletion.
   #+BEGIN_EXPORT latex
   \\
   \begin{definition}[Precedence]\label{def:prec}
     Two events $E_i = \tuple{O_i, t_i, m_i, U_i}$ and $E_j = \tuple{O_j, t_j,
       m_j, U_j}$ where $E_i, E_j \in \mathbb E$ are given. Let $p_i = pos(O_i)$,
     $p_j = pos(O_j)$, $type_i = type(O_i)$ and $type_j = type(O_j)$.
     An event $E_i$ \textit{precedes} $E_j$ if:
     \[
     E_i \prec E_j =
     \begin{cases}
       p_i > p_j\\
       \text{or } (p_i = p_j \land type_i \not= type_j \land type_i = del)\\
       \text{or } (p_i = p_j \land type_i = type_j \land m_i < m_j) & \text{if } E_i \parallel E_j\\[0.5em]
       m_i < m_j & \text{otherwise}
     \end{cases}
     \]
     $E_i$ \textit{precedes} $E_j$ is denoted $E_i \prec E_j$. \hfill$\dashv$
   \end{definition}
   #+END_EXPORT
   Let us look back at the scenario from Figure
   [[ref:fig:non-trivial-happened-before/concurrency-example]]. There were three
   events:
   #+BEGIN_EXPORT latex
   \begin{align*}
     E_0 &= \tuple{O_0, t_0, m_0, u_0} = \tuple{\ins{0}{a}, 0, 1, u_0} \\
     E_1 &= \tuple{O_1, t_1, m_1, u_1} = \tuple{\ins{1}{b}, 0, 2, u_1} \\
     E_2 &= \tuple{O_2, t_2, m_2, u_2} = \tuple{\ins{0}{c}, 2, 3, u_2}
   \end{align*}
   #+END_EXPORT
   where $E_0 \parallel E_1$, $E_0 \longrightarrow E_2$ and $E_1 \parallel
   E_2$. We have the following relations:
   - $E_1 \prec E_0$ because they are concurrent and $pos(O_1) > pos(O_0)$.
   - $E_0 \prec E_2$ because they are not concurrent and $m_0 < m_2$.
   - $E_1 \prec E_2$ because they are concurrent and $pos(O_1) > pos(O_2)$.
   The only possible ordering of these three events is:
   #+BEGIN_EXPORT latex
   \[ E_1 \prec E_0 \prec E_2 \]
   #+END_EXPORT
   This scenario can only occur if the initial buffer was non-empty, seeing
   that $\ins{1}{b}$ was applied to the initial buffer; let us assume the
   initial buffer was ="f"=. From the perspective of each user:
   #+BEGIN_EXPORT latex
   \begin{multicols}{3}
     Perspective of $u_0$:
     \[ \ins{0}{a}(\texttt{"f"}) = \texttt{"af"} \]

     \columnbreak
     Perspective of $u_1$:
     \[ \ins{1}{b}(\texttt{"f"}) = \texttt{"fb"} \]

     \columnbreak
     Perspective of $u_2$:
     \[ \ins{0}{c}(\texttt{"af"}) = \texttt{"caf"} \]
   \end{multicols}
   #+END_EXPORT
   Note that the buffer of $u_2$ is different from the other two users, seeing
   that $\ins{0}{a}$ had been applied before $\ins{0}{c}$ was generated. By
   composing the operations from the events, according to the ordering, we
   would get the operation $\ins{0}{c} \circ \ins{0}{a} \circ \ins{1}{b}$. The
   result of applying the composed operation to the initial buffer is:
   #+BEGIN_EXPORT latex
   \begin{align*}
     \ins{0}{c} \circ \ins{0}{a} \circ \ins{1}{b}(\texttt{"f"}) &=\\
     \ins{0}{c} \circ \ins{0}{a}(\texttt{"fb"}) &=\\
     \ins{0}{c} (\texttt{"afb"}) &= \texttt{"cafb"}
   \end{align*}
   #+END_EXPORT
   It seems to satisfy the intent of every user; $u_0$ placed an =a= in front
   of the =f=, $u_1$ placed a =b= ahead of the =f= and $u_2$ placed a =c= in
   front of the =a=.

*** Events Under Precedence is not a Total Order

    A total order under a relation requires the relation to be antisymmetric,
    total and transitive. Antisymmetric, meaning that if $E_i$ precedes $E_j$
    then $E_j$ cannot precede $E_i$ and total, meaning that any two events are
    comparable under the precedence relation; we have found no counter example
    to either of these properties. However, the precedence relation is not
    transitive, and so an ordering under $\prec$ is not a total order, nor is
    it a partial order.

    These following three events is enough to show that $\prec$ is not
    transitive:
    #+BEGIN_EXPORT latex
    \begin{align*}
      E_0 = \tuple{\ins{0}{a}, 0, 1, u_0}\\
      E_1 = \tuple{\ins{1}{b}, 0, 2, u_0}\\
      E_2 = \tuple{\del{0}{f}, 0, 3, u_1}
    \end{align*}
    #+END_EXPORT
    The session was initiated with a buffer ="f"=. The first user ($u_0$) typed
    an =a= followed by a =b=, resulting in the buffer ="abf"=. The other user
    ($u_1$) deleted the only character in the buffer, resulting in the empty
    buffer $\epsilon$.

    We have that $E_0 \longrightarrow E_1$, $E_0 \parallel E_2$ and $E_1
    \parallel E_2$. Because $u_0$ performed both the operations from $E_0$ and
    $E_1$ we have that $E_0 \prec E_1$. $u_1$ performed a deletion at the same
    point as $u_0$ performed an insertion, so $E_2 \prec E_0$. However, $E_1
    \prec E_2$ because the operation in $E_2$ has a higher position. This means
    we have two plausible orderings:
    #+BEGIN_EXPORT latex
    \begin{align*}
      E_0 \prec E_1 \prec E_2 \\
      E_2 \prec E_0 \prec E_1
    \end{align*}
    #+END_EXPORT
    Neither satisfies transitivity, as $E_0 \not\prec E_2$ and $E_2 \not\prec
    E_1$. The problem is related to how events by the same user are totally
    ordered (i.e. always compared by a unique time stamp), but this
    information is not embedded in the event itself.

    This has two implications that we want to note. One is that we cannot
    /sort/ events based on $\prec$, nor use a standard ordered data structure,
    due to its lack of transitivity. The other is that there exists multiple
    plausible orderings of a given set of events, meaning that there are
    multiple orders where the precedence relation is satisfied between each
    consecutive pair of events.

    A possible resolution to this is discussed in Future Work, Section
    [[Constructing a Total Order]]. Instead we build a history that relies on the
    given precedence relation (Definition [[ref:def:prec]]), presenting a scheme
    that takes the lack of transitivity into consideration.

** Building a History of Events

   A history of events is maintained on the server, and it dictates the order
   of which operations should be applied by every participant. It is built in
   an iterative manner, meaning that for every incoming message the new event
   is placed at some point in the history.

   The /happened before/ (Definition ref:def:happened-before) relation yields a
   partial order of events, leaving some events unordered, due to them being
   concurrent; the precedence relation (Definition ref:def:prec) preservers the
   ordering provided by the happened before relation, while trying to order the
   concurrent events in a way that preserves the users intentions.

   #+BEGIN_EXPORT latex
   \begin{figure}[h]
     \centering
     \begin{tikzpicture}[>=stealth, node distance=4em, scale=1.5]
       \tikzstyle{vertex} = [circle, draw]
       \tikzstyle{to} = [-{Stealth}]

       \node[vertex] (e0) at (0, 0) {$E_0$};
       \node[vertex] (e2) at (1, 1) {$E_2$};
       \node[vertex] (e1) at (2, 0) {$E_1$};

       \draw[to, shorten >= 1pt] (e2) -- (e0);
       \draw[to, shorten >= 1pt] (e0) -- (e1);
       \draw[to, shorten >= 1pt] (e1) -- (e2);

       \begin{pgfonlayer}{bg} % select the background layer
         \draw[rotate around={-45:(0.5,0.5)}, fill=red!30, draw=red, fill opacity=0.5] (0.5,0.5) ellipse (2.1em and 3.5em);
         \draw[rotate around={45:(1.5,0.5)}, fill=green!30, draw=green, fill opacity=0.5] (1.5,0.5) ellipse (2.1em and 3.5em);
       \end{pgfonlayer}
     \end{tikzpicture}
     \caption{Precedence relation.}
     \label{fig:precedence}
   \end{figure}
   #+END_EXPORT

   Figure [[ref:fig:precedence]] illustrates the example from the last section.
   The precedence relation is visualized by edges between the nodes; events
   that are concurrent are grouped. Notice that the precedence relation shows
   a cycle. The problem that needs to be solved, is choosing a path that
   visits every node exactly once, such that the precedence relation is
   satisfied between each pair of consecutive nodes. As discussed in the
   previous section, there are two possibilities in this example.

   The history is a list of events, where the head of the list is the most
   recent event, according to the precedence relation $\prec$. In other words
   it is a list where the successor relation $\succ$ holds between each pair of
   consecutive events (where $\succ$ is defined as the inverse relation of
   $\prec$). The main reason for ordering the history by the successor (rather
   than the precedence) relation is performance. If there are no conflicts,
   every new event will be inserted at the head of the list. Assuming a fairly
   fast internet connection and the (comparably) slow pace of human typing,
   this is by far the most likely scenario. Adding events by the precedence
   relation would give linear time in the most likely scenario, but using the
   successor relation we can often avoid traversing the entire history.

   When adding an event $E$ to a history $H$, we could just add $E$ to the
   first position where $E$ succeeds the event to its right (if there is no
   conflict this would be the head of the list). However, in the example
   visualized in Figure [[ref:fig:precedence]], this approach would break user
   intent. We have not found a way to completely avoid breaking user intent,
   but we have found a way to make it less frequent. The idea is to find the
   first event (i.e. the most recent) that is not concurrent with the event
   that is being added, and let the event skip past events until it precedes
   the event to its left.

   A function $collect$ collects all events until it finds one that is not
   concurrent with $E$; its dual, $drop$, skips all events until it finds one
   that is not concurrent and returns the remaining history (including the
   event it found). A function $put$, and a helper function $put'$, are defined
   in order to place the event at a suitable position in the history. It is
   defined here; note that $nil$ represents an empty history and white space is
   used to represent concatenation of lists and events (where events are
   treated as singleton lists under concatenation).
   #+BEGIN_EXPORT latex
   \begin{alignat*}{2}
     &put(E, H) &&= put'(E, collect(E, H))\ drop(E, H) \\
     &put'(E, nil) &&= E\\
     &put'(E, H\ E') &&=
     \begin{cases}
       H\ E'\ E       & \text{if } E \prec E'\\
       put'(E, H)\ E' & \text{otherwise}
     \end{cases}
   \end{alignat*}
   #+END_EXPORT
   We can now look at an example where we build a history with the three
   events $E_0$, $E_1$ and $E_2$ from the last section.
   #+BEGIN_EXPORT latex
   \begin{alignat*}{3}
     &put(E_0, nil)      &&= put'(E_0, nil)      &&= E_0 \\
     &put(E_1, E_0)      &&= put'(E_1, nil)\ E_0  &&= E_1\ E_0\\
     &put(E_2, E_1\ E_0) &&= put'(E_2, E_1\ E_0) &&= E_1\ E_0\ E_2
   \end{alignat*}
   #+END_EXPORT
   In the first equation the history is empty, and so there is no choice where
   to put $E_0$. When adding $E_1$ there is only one element in the history,
   namely $E_0$, which is performed by the same user --- $collect$ returns
   $nil$ and $drop$ returns a singleton list containing $E_0$. In the last
   equation $collect$ collects the entire history, and $E_2$ is first compared
   with $E_0$ which it precedes, and is therefore added to the end of the
   history.

** Transform the History

   Thus far we have found a way to construct a history of events such that
   every operation is represented in the history and greatly reduces the number
   of inconsistencies that can arise. Our hope was that this approach would be
   sufficient to handle all conflicts, but it turns out that there can still
   arise inconsistencies between clients. Using Maude to analyze the system
   uncovered that $2.2\%$ of states in the system, given a buffer of size two
   and 3 operations are inconsistent. To deal with the remaining portion of
   inconsistent states we apply transformation functions (discussed in Chapter
   [[Related Work]]).

   The following example consists of a set of events where the history does
   not provide a correct result.
   #+BEGIN_EXPORT latex
   \begin{alignat*}{2}
     E_0 &= \tuple{O_0, t_0, m_0, u_0} &&=\tuple{\ins{0}{a}, 0, 1, u_0}\\
     E_1 &= \tuple{O_1, t_1, m_1, u_0} &&=\tuple{\ins{2}{b}, 0, 2, u_0}\\
     E_2 &= \tuple{O_2, t_2, m_2, u_1} &&=\tuple{\del{0}{f}, 0, 3, u_1}
   \end{alignat*}
   #+END_EXPORT
   The ordering decided by the algorithm from the last section is:
   #+BEGIN_EXPORT latex
   \[ E_2 \prec E_0 \prec E_1 \]
   #+END_EXPORT
   The problem is that executing the operation $O_2 \circ O_0 \circ O_1$,
   obtained from the ordering, is not possible to execute on the initial buffer
   ="f"=. The =f= is deleted, then an =a= at the beginning of the buffer, and
   finally a =b= is attempted to be inserted at position $2$, which is beyond
   the bounds of the buffer. The reason that this occurs is that the first
   deletion /shrinks/ the buffer, but no measure is taken to make sure that the
   position of $O_2$ is decremented accordingly. This problem can be resolved
   by transforming the operations.

   We use two types of transformation functions, namely inclusion and
   exclusion; an inclusion transformation function is the kind we discussed in
   Chapter [[Related Work]]. Given two operations $O_i, O_j \in \mathcal O$, then
   an inclusion transformation of $O_i$ with regards to $O_j$ can be
   understood as "$O_i$ as if $O_j$ had already been applied". Exclusion
   transformation is the reverse, and transforming $O_i$ with regards to $O_j$
   can be understood as "$O_i$ as if $O_j$ had not been applied".

   Due to our ordering, we only need to transform against deletions to
   guarantee eventual consistency. It is however possible that including the
   complete set of transformations would better preserve user intent --- due
   to time restrictions we have not been able to verify this.

   We define two functions $it$ and $et$, where $it$ is the inclusion
   transformation function and $et$ is the exclusion transformation function.
   $it$ is derived from the (corrected) transformation from Figure
   [[ref:fig:transformation-function]] (page [[pageref:fig:transformation-function]]),
   whereas $et$ is derived from cite:sun1998reversible. Furthermore, we define
   both $it$ and $et$ for composed operations, which is derived from
   cite:formalOT.

   One alteration has been made. When applying an inclusion transformation on
   two deletions with the same position, the result is $nop$. To reverse this
   effect, $et$ must be able to retrieve the deletion that was omitted (i.e.
   transformed to $nop$). Using an exclusion transformation on $nop$ cannot be
   done, because it contains no information about what character was deleted.
   In cite:sun1998reversible this is handled by keeping a lookup table.
   Instead, we store the information in the $nop$ object itself, by letting
   $nop$ (optionally) contain an operation; its semantics is not changed,
   meaning applying $nop$ has no effect regardless.

   Note that the following equations, defining $it$ and $et$, uses the word
   /otherwise/ as it is used in Maude. It means that if none of the above
   equations covers a particular case, then it is covered by the equation
   tagged with otherwise. This is important for the last case, which would
   match all operations if not for this use of otherwise. $it$ is defined as
   follows:
   #+BEGIN_EXPORT latex
   \begin{align*}
     it(\ins{p1}{c1}, \del{p2}{c2}) &=
     \begin{cases}
       \ins{p1}{c1}   & \text{if } p1 \leq p2 \\
       \ins{p1-1}{c1} & \text{otherwise}
     \end{cases}
     \\
     it(\overbrace{\del{p1}{c1}}^{O_i}, \overbrace{\del{p2}{c2}}^{O_j}) &=
     \begin{cases}
       \del{p1}{c1}                         & \text{if }      p1 < p2 \\
       \del{p1-1}{c1}                       & \text{else if } p1 > p2 \\
       nop(O_i \circ O_j) & \text{otherwise}\\
     \end{cases}
     \\
     it(O_i, O_j \circ O_k) &= it(it(O_i, O_k), O_j) \text{\quad\ \ if $O_j$ is not composed}
     \\
     it(O_i, O_j) &= O_i \text{\qquad\qquad\qquad\quad\ \ otherwise}
   \end{align*}
   #+END_EXPORT
   The exclusion transformation is defined in a similar manner, where a
   position is incremented to reverse the effect of an inclusion
   transformation. In the cases where an inclusion transformation would omit an
   operation, the exclusion transformation retrieves the operation.
   #+BEGIN_EXPORT latex
   \begin{align*}
     et(\ins{p1}{c1}, \del{p2}{c2}) &=
     \begin{cases}
       \ins{p1}{c1}   & \text{if } p1 \leq p2 \\
       \ins{p1+1}{c1} & \text{otherwise}
     \end{cases}
     \\
     et(\del{p1}{c1}, \del{p2}{c2}) &=
     \begin{cases}
       \del{p1}{c1}   & \text{if }      p1 < p2 \\
       \del{p1+1}{c1} & \text{otherwise} \\
     \end{cases}
     \\
     et(nop(O_i \circ O_j), O_j) &= O_i
     \\
     et(O_i, O_j \circ O_k) &= et(et(O_i, O_j), O_k) \text{\quad\ \ if $O_j$ is not composed}
     \\
     et(O_i, O_j) &= O_i \text{\qquad\qquad\qquad\quad\ \ \ otherwise}
   \end{align*}
   #+END_EXPORT
   These transformation functions are used to "fix up" the history after a new
   event has been added. The inclusion transformations assumes that two
   operations were generated from the same state (i.e. the same buffer)
   cite:sun1998reversible, but this is not always the case. To deal with these
   cases, exclusion transformations is used to "reset" the operation to a
   agreed upon state, then perform inclusion transformations on this operation,
   and finally, we perform the inclusion transformations for the effects that
   were excluded.

   Given an event $E = \tuple{O, t, m, u}$ the events that will have effected
   $O$ can be found. These are the events with a smaller time stamp than $m$,
   or have the same user $u$ that occur at an earlier point in the history. The
   event must be "reset" to an agreed upon state, which is decided by the event
   with the smallest token which is concurrent with $E$. In order to use
   transformations on multiple events, the operations of a history can be
   composed using the $compose$ function. It is defined as:
   #+BEGIN_EXPORT latex
   \begin{alignat*}{2}
     &compose(nil) &&= nop\\
     &compose(\tuple{O, t, m, u}\ H) &&= O \circ compose(H)
   \end{alignat*}
   #+END_EXPORT
   We define a function $fix$ which takes a history and returns a "fixed up"
   version of the history:

   #+BEGIN_EXPORT latex
   \begin{align*}
     &fix(nil) = nil \\
     &fix(\tuple{O, t, m, u}\ H) = \tuple{O_{fixed}, t, m, u}\ H'\\
     &\begin{aligned}
        \text{where }
        &H'      &&= fix(H) \\
        &E       &&= \tuple{O, t, m, u}\\
        &H_c     &&= \text{filter $H'$, only keep events that are concurrent with $E$}\\  % filter(\tuple{O, t, n, u}, H') \\
        %% &t_{min}  &&= \text{get the smallest token from events in $H_c$}\\
        %% &O_e     &&= \text{compose operations that have effected $O$ (with token $t_{min}$ or greater)}\\
        &O_e     &&= \text{compose operations that have effected $O$}\\
        &O_{fixed} &&= it(it(et(O, O_e), compose(H_c)), O_e) \\
      \end{aligned}&&
   \end{align*}
   #+END_EXPORT
   By making sure the $fix$ function is applied to the history after each
   insertion, we ensure that composing the entire history can always be safely
   applied to the initial buffer. What remains is to ensure that each client
   eventually will apply the operations of the history.

** Ensuring Consistency

   After having gone into great depths on how to construct a history, the
   question of getting all clients to conform to this history still remains.
   This section concludes the specification of the server-side algorithm, and
   shows how the history, and properties of editing operations, are leveraged
   to guarantee eventual consistency. The only nondeterministic behavior at the
   server is the reception of a message; this section describes the server's
   /reaction/ to incoming messages.

   Messages from the server are on exactly the same form as messages from a
   client, namely a $msg(O, t, s)$ where $O$ is an operation, $t$ is a token
   and $s$ is a sequence number. When a client receives a message, the
   operation is only applied if the sequence number of the message $s$ is equal
   to the client's local sequence number. If the client applies the operation,
   then it is guaranteed to be consistent with the history at time $t$. Being
   consistent with the history at time $t$ is defined as: Compose the history
   as it was when the server's state token was $t$; if this operation is
   applied to the initial buffer and the resulting buffer is equal to the
   client's buffer, then the client is consistent with the history at time $t$.

   On each reception the server sends a response to every connected client. The
   server constructs two operations, one to the client who sent the message and
   another to every other client. The token is the same in every message. The
   sequence number may vary for each client.

*** Sequence Number Scheme

    Remember that a client always increments its sequence number after it
    performs an operation or receives a message from the server. Say we have a
    set of users $U$ who identify each connected client. The server keeps a
    sequence number $s_u \in \mathbb N$ for each participant $u \in U$,
    initialized at zero.

    When a message is received from a client identified by $u \in U$, the
    server sends messages to every connected client, each of which contains a
    sequence number. For each client identified by the users in $u' \in U
    \setminus \{u\}$, the stored sequence number $s_{u'}$ is used, and
    incremented after the message is sent. It is incremented because the client
    will increment its sequence number at reception of the message, and will
    therefore expect a higher sequence number the next time it receives a
    message.

    #+BEGIN_EXPORT latex
    \begin{wrapfigure}[21]{r}{0pt}
      \centering
      \begin{tikzpicture}[>=stealth, shorten >= 1pt, node distance=1em, scale=1]
        \tikzstyle{vertex} = [circle, scale=0.3]
        \tikzstyle{O_0} = [vertex, fill=black!30!green]
        \tikzstyle{O_1} = [vertex, fill=black!30!blue]
        \tikzstyle{O_2} = [vertex, fill=black!30!red]

        \tikzstyle{to} = [-{Stealth[scale=1]}]
        \tikzstyle{toO_0} = [to, color=black!30!green]
        \tikzstyle{toO_1} = [to, color=black!30!blue]
        \tikzstyle{toO_2} = [to, color=black!30!red]

        \tikzstyle{op} = [near start, above=-3pt, sloped, text=black, font=\scriptsize]

        %% Server receives operations in this order
        \node[font=\scriptsize] (s) at (4, 7.5) {$S$};
        \coordinate (se) at (4, 0) {};

        \node[O_0, below = 2em of s, label={[font=\scriptsize, align=center]right:$s_u = 0$\\\\$s_u = 2$}] (s1) {};

        \node[O_1, below = 4.5em of s1, label={[font=\scriptsize, align=center]right:\\\\$s_u = 4$}] (s2) {};
        \node[O_2, below = of s2, label={[font=\scriptsize, align=center]right:\\\\$s_u = 6$}] (s3) {};
        \node[O_0, below = of s3, label={[font=\scriptsize, align=center]right:\\\\$s_u = 8$}] (s4) {};

        \node[O_1, below = 6em of s4, label={[font=\scriptsize, align=center]right:\\\\$s_u = 10$}] (s5) {};

        %% User 0 generates/receives in this order
        \node[font=\scriptsize] (u0) at (0, 7.5) {$u_0$};
        \node (u0e) at (0, 0) {};

        %% \node[O_0, below = 1em of u0, label={[font=\scriptsize, align=center]left:0\\\\1}] (u00) {};
        %% \node[O_0, below = 2em of u00, label={[font=\scriptsize, align=center]left:\\\\2}] (u01) {};

        %% \node[O_1, below = 1em of u01, label={[font=\scriptsize, align=center]left:\\\\3}] (u02) {};
        %% \node[O_2, below = of u02, label={[font=\scriptsize, align=center]left:\\\\4}] (u03) {};
        %% \node[O_0, below = of u03, label={[font=\scriptsize, align=center]left:\\\\5}] (u04) {};

        %% \node[O_1, below = 3em of u04, label={[font=\scriptsize, align=center]left:\\\\6}] (u05) {};
        %% \node[O_2, below = of u05, label={[font=\scriptsize, align=center]left:\\\\7}] (u06) {};
        %% \node[O_0, below = of u06, label={[font=\scriptsize, align=center]left:\\\\8}] (u07) {};

        %% \node[O_1, below = 1em of u07, label={[font=\scriptsize, align=center]left:\\\\9}] (u08) {};
        %% \node[O_1, below = 2em of u08, label={[font=\scriptsize, align=center]left:\\\\10}] (u09) {};
        \node[O_0, below = 1em of u0, label={[fill=white, font=\tiny, align=center]above left:0}] (dummy) {};
        \node[O_0, below = 1em of u0, label={[fill=white, font=\tiny, align=center]below left:1}] (u00) {};
        \node[O_0, below = 2em of u00, label={[fill=white, font=\tiny, align=center]below left:2}] (u01) {};

        \node[O_1, below = 1em of u01, label={[fill=white, font=\tiny, align=center]below left:3}] (u02) {};
        \node[O_2, below = of u02, label={[fill=white, font=\tiny, align=center]below left:4}] (u03) {};
        \node[O_0, below = of u03, label={[fill=white, font=\tiny, align=center]below left:5}] (u04) {};

        \node[O_1, below = 3em of u04, label={[fill=white, font=\tiny, align=center]below left:6}] (u05) {};
        \node[O_2, below = of u05, label={[fill=white, font=\tiny, align=center]below left:7}] (u06) {};
        \node[O_0, below = of u06, label={[fill=white, font=\tiny, align=center]below left:8}] (u07) {};

        \node[O_1, below = 1em of u07, label={[fill=white, font=\tiny, align=center]below left:9}] (u08) {};
        \node[O_1, below = 2em of u08, label={[fill=white, font=\tiny, align=center]below left:10}] (u09) {};

        \begin{pgfonlayer}{bg} % select the background layer
          \draw[to, color=black!30] (s) -- (se);
          \draw[to, color=black!30] (u0) -- (u0e);

          %% From client
          \draw[toO_0] (u00) -- (s1) node [op] {$s = 0$};
          \draw[toO_1] (u02) -- (s2) node [op] {$s = 2$};
          \draw[toO_2] (u03) -- (s3) node [op] {$s = 3$};
          \draw[toO_0] (u04) -- (s4) node [op] {$s = 4$};
          \draw[toO_1] (u08) -- (s5) node [op] {$s = 8$};
          %% \draw[toO_0] (u00) -- (s1) node [op, pos=0.25] {$msg(O_0, 0, 0)$};
          %% \draw[toO_1] (u02) -- (s2) node [op, pos=0.25] {$msg(O_1, 2, 2)$};
          %% \draw[toO_2] (u03) -- (s3) node [op, pos=0.25] {$msg(O_2, 2, 3)$};
          %% \draw[toO_0] (u04) -- (s4) node [op, pos=0.25] {$msg(O_3, 2, 4)$};
          %% \draw[toO_1] (u08) -- (s5) node [op, pos=0.25] {$msg(O_4, 5, 8)$};

          %% From server
          \draw[toO_0] (s1) -- (u01) node [op, near end] {$s = 1$};
          \draw[toO_1] (s2) -- (u05) node [op, near end] {$s = 3$};
          \draw[toO_2] (s3) -- (u06) node [op, near end] {$s = 5$};
          \draw[toO_0] (s4) -- (u07) node [op, near end] {$s = 7$};
          \draw[toO_1] (s5) -- (u09) node [op, near end] {$s = 9$};

          %% \draw[toO_0] (s1) -- (u01) node [op, pos=0.75] {$msg(O_0', 2, 1)$};
          %% \draw[toO_1] (s2) -- (u05) node [op, pos=0.75] {$msg(O_1', 3, 3)$};
          %% \draw[toO_2] (s3) -- (u06) node [op, pos=0.75] {$msg(O_2', 4, 5)$};
          %% \draw[toO_0] (s4) -- (u07) node [op, pos=0.75] {$msg(O_3', 5, 7)$};
          %% \draw[toO_1] (s5) -- (u09) node [op, pos=0.75] {$msg(O_4', 6, 9)$};
        \end{pgfonlayer}
      \end{tikzpicture}
      \caption{Sequence number scheme.}
      \label{fig:seqno-scheme}
    \end{wrapfigure}
    #+END_EXPORT

    When a message $msg(O, t, s)$ is received from a client identified by $u$,
    then the response to this client will contain a sequence number determined
    by the function $nextSeq$:
    #+BEGIN_EXPORT latex
    \begin{align*}
      nextSeq(s_u, s) = s_u + 1 + (s_u - s)
    \end{align*}
    #+END_EXPORT
    If there is no conflict then $s = s_u$, and so the response will just be
    the sequence number of the message incremented by one. It is incremented by
    one because sending the messages will have caused the client to increment
    its sequence number. If there is a conflict, then $u$ must have performed
    one or more operations between the time the server sent the last message
    and the client received it. The difference $s_u - s$ is the precise number
    of operations that $u$ has performed in this time span. Because each of
    these operations has caused the client's sequence number to increase, the
    difference is added in order to match the sequence number of the client.

    After the server has sent a response to the client, $s_u$ is set to $s_u =
    nextSeq(s_u, s) + 1$. The extra one is added because the reception of the
    message will (again) cause the client's sequence number to be incremented.

    The main benefits of this scheme are that it remains very simple on the
    client side (seeing that it only increments after every send or receive)
    and that it guarantees that clients do not perform operations from the
    server which are based on outdated information. Instead, the client rejects
    messages for the duration of a conflict with the server. The disadvantage
    is that the system is not responsive during long lasting conflicts, which
    may arise if a user, for instance, holds down a button on her keyboard for
    a long time. However, it seems reasonable to assume that such situations
    are unlikely to occur, and even less likely to cause problems in practical
    uses of the system.

*** Constructing Operations

    When the server receives a message $msg(O, t, s)$ two operations are
    constructed; one for the client who sent the message, and one for all the
    other clients. We will discuss the message that is sent to all other
    clients first.

    If the message was sent by a client identified by $u \in U$ and the message
    is received at time $m$, then it is assumed that all clients identified by
    some $u' \in U \setminus \{u\}$ is consistent with the history at time $m$.
    The event $\tuple{O, t, m, u}$ is added to the history $H$, constructing a
    new history $H'$. A new message is constructed on the basis of $H$ and
    $H'$.

    If the new event is added to the beginning of the history (i.e. the most
    recent), then the constructed operation will always be $O$ itself. Let us
    say $O$ is in conflict with another operation $O_i$, with a lower position,
    then $O$ must applied before the operation with the lower position is
    applied. Since it is assumed that the clients have already applied $O_i$,
    this must be undone before. When this is done, $O$ may be applied followed
    by $O_i$.

    A function $until$ takes a history and a token, finds the earliest event
    that arrived at time greater or equal to the given token. It is defined as
    follows:
    #+BEGIN_EXPORT latex
    \begin{align*}
      &until(nil, t) = nil\\
      &until(H\ \tuple{O, t', m, u}, t) =
      \begin{cases}
        H\ \tuple{O, t', m, u} & \text{if } m \geq t\\
        until(H, t) & \text{otherwise}
      \end{cases}
    \end{align*}
    #+END_EXPORT
    Now we can define a function $makeOp$, which takes two histories and a
    token. It is presumably called with the history $H$ (as it was at time $m$,
    before the new event was added), and the history with the new event added
    $H'$, along with the token $t$. It is defined as follows:
    #+BEGIN_EXPORT latex
    \[ makeOp(H', H, t) = compose(until(H', t)) \circ compose(until(H, t))^{-1} \]
    #+END_EXPORT
    This operation will first undo operations that occurred at time $t$ or
    later, followed by the operations from the updated history (at time $t$ or
    later). As we discussed in [[Invertibility]], redundant operations on the form
    $O_i^{-1} \circ O_i$ can be omitted, which should be done (but is not
    strictly necessary) before the operation is sent.

    The message $msg(makeOp(H', H, t), m+1, s_{u'})$ is sent to all clients
    identified by some $u' \in U \setminus \{u\}$, where $s_{u'}$ may vary
    depending on the recipient. For each of these clients, the server keeps a
    mapping from $u'$ to a list of pairs, containing an operation and a
    token [fn:4]. The operation and token is added to the head of this list
    after sending the message.

    The second case to consider is what to send to the client, identified by
    $u$, that originally sent the message $msg(O, t, s)$. If there is no
    conflict, then the constructed operation is always $nop$. It is important
    to note that if a conflict has arisen, it can only be because the client
    has performed operations in the time between the server last sent it a
    message, and the time the client received it. The token $t$ indicates that
    the client was consistent with the history at time $t$.
    # The token $t$ shows at what point the client last accepted a message from
    # the server (i.e. received and did not reject).

    Because every operation (along with a token indicating what time it was
    sent) that is sent to the client is stored, the operations the client have
    rejected is retrievable. It has rejected all operations with a
    corresponding token that is strictly greater than $t$. These operations
    have to be represented in the response.

    The idea is to always make the client undo the operation $O$, then perform
    all the operations that it has rejected, and finally perform the operation
    that is sent to every other client (the operation constructed by $makeOp$).
    If there is no conflict, then the operation constructed by $makeOp$ is
    simply $O$ and there are no operations stored operations to compose; the
    resulting operation is $O \circ O^{-1}$ which is equal to $nop$.

    A simple helper function $rejected$ is used. It takes a list of pairs
    (where each pair contains an operation and a token) $R$ and a token $t$.
    The function returns the pairs with token strictly greater than $t$.
    Composing the resulting list is analogous to composing a history. The
    operation sent to the client who sent the message $msg(O, t, s)$ is given
    by a function $makeResponse$ that takes four arguments: The received
    operation $O$, the operation $makeOp(H', H, t)$, the list that contains
    rejected operations (along with the corresponding tokens) and the token $t$
    as argument.
    #+BEGIN_EXPORT latex
    \[ makeResponse(O, O', R, t) = O' \circ compose(rejected(R, t)) \circ O^{-1} \]
    #+END_EXPORT
    This operation can safely be applied by the client who sent the message
    $msg(O, t, s)$, and will make the client consistent with the history at
    time $m+1$.

    The last remaining detail is regarding the list of rejected operations
    (along with the corresponding token). The operation from $makeResponse$
    ensures that previously rejected operations are performed; it is very
    important not to perform these rejected operations again if a new conflict
    arises. To solve this problem, the list is replaced with a singleton list
    which only contains the operation constructed by $makeResponse$ and the
    token $m+1$.

**** A Summarizing Example

     Let us revisit the example from Figure [[ref:fig:non-trivial-complete]], where
     we include the operations that are sent to each client. The events
     received on the server is:
     #+BEGIN_EXPORT latex
     \begin{align*}
       E_0 &= \tuple{O_0, t_0, m_0, u_0} = \tuple{\ins{0}{a}, 0, 1, u_0} \\
       E_1 &= \tuple{O_1, t_1, m_1, u_1} = \tuple{\ins{1}{b}, 0, 2, u_1} \\
       E_2 &= \tuple{O_2, t_2, m_2, u_2} = \tuple{\ins{0}{c}, 2, 3, u_2}
     \end{align*}
     #+END_EXPORT
     The server decides on an ordering $E_1 \prec E_0 \prec E_2$, which means
     that all clients must perform the operation $O_2 \circ O_0 \circ O_1$. By
     composing all operations sent to a given client, we can calculate what
     operation they perform.
    #+BEGIN_EXPORT latex
    \begin{figure}[h]
      \centering
      \begin{tikzpicture}[>=stealth, shorten >= 5pt, node distance=4em, scale=1]
        \tikzstyle{vertex} = [circle, scale=0.5]
        \tikzstyle{O_0} = [vertex, fill=black!30!green]
        \tikzstyle{O_1} = [vertex, fill=black!30!blue]
        \tikzstyle{O_2} = [vertex, fill=black!30!red]

        \tikzstyle{to} = [-{Stealth[scale=1.2]}]
        \tikzstyle{toO_0} = [to, color=black!30!green]
        \tikzstyle{toO_1} = [to, color=black!30!blue]
        \tikzstyle{toO_2} = [to, color=black!30!red]

        \tikzstyle{op} = [near end, above=-3pt, sloped, text=black, font=\small]

        %% Server receives operations in this order
        \node (s) at (0, 11) {$S$};
        \coordinate (se) at (0, -1) {};
        \node[O_0, below = 2em of s,   label=left:{$\small\overbrace{\langle O_0, 0, 1, u_2 \rangle}^{E_0}$}] (s1) {};
        \node[O_1, below = 6em of s1,  label=left:{$\small\overbrace{\langle O_1, 0, 2, u_0 \rangle}^{E_1}$}] (s2) {};
        \node[O_2, above = 12em of se, label=left:{$\small\overbrace{\langle O_2, 2, 3, u_1 \rangle}^{E_2}$}] (s3) {};

        %% %% Time
        %% \node (t) at (-2, 9.5){};
        %% \coordinate (te) at (-2, 0.2) {};

        %% User 0 generates/receives in this order
        \node (u0) at (6, 11) {$u_0$};
        \node (u0e) at (6, -1) {%% $\texttt{cbfa}$
        };
        \node[O_1, below = 6em of u0] (u01) {};
        \node[O_0, below = 2em of u01] (u00r) {}; % cross out
        \node[O_1, below = 3em of u00r] (u01a) {};
        \node[O_2, above = 10em of u0e] (u02a) {};

        %% User 1 generates/receives in this order
        \node (u1) at (8.5, 11) {$u_1$};
        \node (u1e) at (8.5, -1) {%% $\texttt{cbfa}$
        };
        \node[O_0, below = 4.5em of u1] (u10a) {};
        \node[O_2, below = 8em of u10a] (u12) {};
        \node[O_1, below = of u12] (u11r) {}; % cross out
        \node[O_2, above = 2em of u1e] (u12a) {};

        %% User 2 generates/receives in this order
        \node (u2) at (10, 11) {$u_2$};
        \node (u2e) at (10, -1) {%% $\texttt{cbfa}$
        };
        \node[O_0, below = 1em of u2] (u20) {};
        \node[O_0, below = 6em of u20] (u20a) {};
        \node[O_1, below = 2.5em of u20a] (u21a) {};
        \node[O_2, above = 6em of u2e] (u22a) {};

        \begin{pgfonlayer}{bg} % select the background layer
          %\draw[to, color=black!30, text=black] (t) -- (te) node [midway, fill=white] {time};
          \draw[to, color=black!30] (s) -- (s1)  -- (s2)  -- (s3) -- (se);
          \draw[to, color=black!30] (u0) -- (u01) -- (u00r) -- (u01a) -- (u02a) -- (u0e);
          \draw[to, color=black!30] (u1) -- (u10a) -- (u12) -- (u11r) -- (u12a) -- (u1e);
          \draw[to, color=black!30] (u2) -- (u20) -- (u20a) -- (u21a) -- (u22a) -- (u2e);

          % Life of O_0
          \draw[toO_0] (u20) -- (s1) node [op] {$\overbrace{\ins{0}{b}}^{O_0}$};
          \draw[toO_0] (s1) -- (u00r) node [op, midway] {$O_0$};
          \draw[toO_0] (s1) -- (u10a) node [op] {$O_0$};
          \draw[toO_0] (s1) -- (u20a) node [op] {$nop$};

          % Life of O_1
          \draw[toO_1] (u01) -- (s2) node [op] {$\overbrace{\ins{1}{a}}^{O_1}$};
          \draw[toO_1] (s2) -- (u01a) node [op] {$O_0$};
          \draw[toO_1] (s2) -- (u11r) node [op, midway] {$O_0 \circ O_1 \circ O_0^{-1}$};
          \draw[toO_1] (s2) -- (u21a) node [op] {$O_0 \circ O_1 \circ O_0^{-1}$};

          % Life of O_2
          \draw[toO_2] (u12) -- (s3) node [op] {$\overbrace{\ins{0}{c}}^{O_2}$};
          \draw[toO_2] (s3) -- (u02a) node [op] {$O_2$};
          \draw[toO_2] (s3) -- (u12a) node [op] {$O_2 \circ \overbrace{O_0 \circ O_1 \circ O_0^{-1}}^{\text{rejected}} \circ O_2^{-1}$};
          \draw[toO_2] (s3) -- (u22a) node [op] {$O_2$};
        \end{pgfonlayer}
      \end{tikzpicture}
      \caption{The events are ordered $E_1 \prec E_0 \prec E_2$.}
      \label{fig:non-trivial-complete}
    \end{figure}
    #+END_EXPORT

     From the perspective of $u_0$:
     - $O_1$ is generated,
     - $O_0$ is received,
     - $O_2$ is received.
     The composition of these operations yields the operation $O_2 \circ O_0
     \circ O_1$.

     From the perspective of $u_1$:
     - $O_0$ is received,
     - $O_2$ is generated,
     - $O_0 \circ O_1 \circ O_0^{-1}$ is received, but rejected,
     - $O_2 \circ O_0 \circ O_1 \circ O_0^{-1} \circ O_2^{-1}$ is received.
     The composition of the operations (excluding the rejected operation)
     yields:
     #+BEGIN_EXPORT latex
     \begin{align*}
       O_2 \circ O_0 \circ O_1 \circ O_0^{-1} \circ \overbrace{O_2^{-1} \circ O_2}^{nop} \circ O_0 &= \\
       O_2 \circ O_0 \circ O_1 \circ \overbrace{O_0^{-1} \circ O_0}^{nop} &= O_2 \circ O_0 \circ O_1
     \end{align*}
     #+END_EXPORT

     Lastly, from the perspective of $u_2$:
     - $O_0$ is generated,
     - $O_0 \circ O_1 \circ O_0^{-1}$ is received,
     - $O_2$ is received.
     The composition of the operations yields:
     #+BEGIN_EXPORT latex
     \begin{align*}
       O_2 \circ O_0 \circ O_1 \circ \overbrace{O_0^{-1} \circ O_0}^{nop} &= O_2 \circ O_0 \circ O_1
     \end{align*}
     #+END_EXPORT

** Summary

   This chapter is in essence a comprehensive walk through of the equations of
   the Maude specification that are related to the server-side of the
   specification. The reception of a message is the only nondeterministic
   behavior at the server; this is expressed as a single rewriting rule in
   Maude. This rule calls the functions we have described in the preceding
   sections.

   #+BEGIN_EXPORT latex
   \begin{figure}[h]
   \centering
   \begin{verbatim}
   crl [server-receive] :
       < U | out-queue : (Q msg(O, T, N)),
             in-queue  : Q' >
       < server | history : H, state : M, sites : (U |-> Q'', US) >
     =>
       < U | out-queue : Q,
             in-queue  : (msg(O'', s M, S) Q') >
       < server | history : H', state : s M, sites : US' >
       (send O' to US)
     if  H'  := fix(put(O T M U, H)) /\
         O'  := makeOp(H', H, T) /\
         S   := nextSeq(Q'', N) /\
         O'' := makeResponse(O, O', Q'', T) /\
         US' := (U |-> msg(O'', s M, s S), US) .
   \end{verbatim}
   \caption{The rule expresses the reaction to the reception of a message.}
   \label{fig:maude-rule}
   \end{figure}
   #+END_EXPORT

   The rewriting rule in Figure [[ref:fig:maude-rule]] concisely summarizes
   this chapter, as it describes the /reaction/ to the reception of a message.
   The reception of a message is modeled as the server nondeterministically
   picking a message off of the end of the message outgoing queue of a client.
   It adds a response message to the incoming queue to the client. The
   expression =(send O' to US)= similarly adds a message containing the
   operation =O'= on all the other clients incoming queues with the correct
   sequence number.

   The =sites= field is a mapping from users to the information the server
   stores about each client. Each site consists of a list of messages, which
   contains messages that might be rejected by the client; note that the
   sequence number is incremented by one in order to comply with the sequence
   number scheme (Section [[Sequence Number Scheme]]). Also note that the rule
   is expressed as a /conditional/ rule =crl= in order to achieve the effects
   of a /let/-expression, commonly found in functional programming languages.

   In this chapter we have seen how the server orders events in a way that
   ensures that causality violation does not occur, and minimizes the need for
   transformation functions. We have demonstrated that this is not sufficient,
   and show how inclusion and exclusion transformation functions can be applied
   to produce a history which can dictate a safe order of which operations can
   be applied. Lastly, we have seen how consistency is ensured by constructing
   operations which can be applied by clients, leaving them consistent with the
   constructed history.

[fn:3] The rules stated here are slightly simplified from those in the actual
Maude specification.
[fn:4] In the Maude specification, each user maps to a list of messages. It
contains the message that was sent, but where the sequence number $s_{u'}$ is
incremented by one. This is because the sequence number $s_{u'} + 1$ has to be
stored somewhere, as discussed in [[Sequence Number Scheme]], and a list of
messages was already present in the specification, in order to model message
queues.

* Model Checking the Specification

  The main advantage of writing a /formal/ specification of a system is the
  possibility of analyzing properties of the system in an automated manner. We
  are convinced that using such tools have led us to detect problems with the
  algorithm that we otherwise would not, and provided useful output to further
  aid our understanding of the problem. In addition, it has provided us with
  confidence the algorithm is robust.

  For this thesis, we have chosen to apply a well known technique for formal
  verification, called model checking[fn:5]. Maude has good support for
  performing model checking, via its =search= command
  cite:DBLP:conf/maude/2007, and an LTL (Linear Temporal Logic) model checker
  cite:Eker2004162. We have taken a practical approach to model checking, using
  it as a tool to aid the development of the algorithm. In this chapter we will
  present how we have used it, and how we have been able to use the results of
  the model checker to enhance the algorithm.

  In previous chapters, we have seen numerous examples of scenarios which could
  lead to inconsistencies unless certain measures are taken. All of these
  examples have been found using the Maude LTL model checker.

** Always Eventually Consistent

   Our goal for the algorithm is that it must guarantee /eventual consistency/
   cite:Vogels:2009:EC:1435417.1435432. It is typically used in the context of
   data replication. In the context of real-time collaborative editing,
   eventual consistency means that "if all users stop typing, then eventually
   they will all be looking at the same buffer". It is a weak consistency
   model, in the sense that it allows for an /inconsistency window/, meaning
   that clients can be out of sync for a period of time.

   Our motivation for using such a weak consistency model is that it is a
   reasonable minimum requirement for a real-time collaborative system.
   However, it does not provide any guarantees with regards to preserving /user
   intent/. If eventual consistency was the only requirement for our system,
   then our system could simply tell every client to delete the contents of
   their buffer at every change; this is obviously not a satisfactory solution.

   We have not formalized any requirements with regards to user intent, and
   rather taken a more intuitive approach. As we demonstrated in Chapter
   [[Server-side Specification]], ensuring that conflicting operations with a
   higher position are applied before operations with a lower position
   preserves the users intentions. We choose to assume that this is by far the
   most likely scenario, as it seems hard to imagine that users will find it
   fruitful to persistently try to edit the exact same point of the buffer.
   This does not mean that we completely ignore the case where this situation
   would occur. The two requirements we set for such situations is that they do
   not break consistency, and do not result in instructing the clients to
   perform an operation which operates outside the bounds of their buffer.

   We use LTL (Linear Temporal Logic) to formally express the property /always
   eventually consistent/. A temporal logic is a tool for reasoning about time,
   where, in LTL, time is simply represented as a sequence of states. The words
   /always/ and /eventually/ expresses temporal properties over sequences of
   states, while /consistent/ is a property which states that all buffers in
   the system are equal.

** Expressing Consistency in Maude

   The Maude model checker module cite:Eker2004162 provides a sort =Prop=; a
   term of the sort =Prop= is a property. We define a function symbol
   =consistent= which is of the sort =Prop= (and does not take any arguments).
   The /semantics/ of a property is defined by equations using the operator
   =|==, which takes a state and a property. A state is simply a term which
   represents all the components of the system, including the clients and the
   server.

   A state being =consistent= is defined as "all buffers in the system are
   equal to each other". This is expressed by using a function that gathers all
   buffers in a given state, adding them to a set, and checking if the size of
   this set is (less than or) equal to one. We allow for an empty set, because
   a system with no clients is considered consistent. The property is formally
   specified as:

   #+BEGIN_EXAMPLE
       eq C |= consistent = | buffers(C) | <= 1 .
       eq C |= consistent = false [owise] .
   #+END_EXAMPLE

   The equations state that a state =C= is a model for the property
   =consistent= if the size of a set containing all the buffers in the state is
   less than or equal to one. In all other cases, =C= is not a model for the
   property =consistent=.

** Model Checking in Maude

   Model checking is performed by supplying an initial state and a property. An
   initial state of our system is defined by a function =init= that takes three
   optional arguments; the initial buffer, the number of clients and the number
   of operations that can occur during a session. Called with no arguments it
   returns a state with an initially empty buffer, two clients and three
   operations, and reduces to the following term:

   #+BEGIN_EXAMPLE
   < server | history : nil,
              state : 1,
              sites : (user 0 |-> msg(nop, 0, 0),
                       user 1 |-> msg(nop, 0, 0)) >

   < user 0 | buffer : nil,
              seqno : 0,
              token : 0,
              in-queue : nil,
              out-queue : nil >

   < user 1 | buffer : nil,
              seqno : 0,
              token : 0,
              in-queue : nil,
              out-queue : nil >
   #+END_EXAMPLE

   It contains terms that represent server and two clients. The server consists
   of a history, a state token and a mapping from users to the server's
   information about the clients; the information it keeps is a list of
   rejected messages. We can perform model checking on this initial state, by
   calling the =modelCheck= function. The following expression immediately
   returns /true/:

   #+BEGIN_EXAMPLE
   reduce modelCheck(init, consistent) .
   #+END_EXAMPLE

   The reason for this is that the clients' buffers are identical, and so the
   initial state is consistent; there is no need to check any other states,
   because no temporal connectives has been added. We have leveraged two
   temporal connectives, namely /always/, symbolized by =[]=, and /eventually/,
   symbolized by =<>=.

   The connective /always/ takes a property, and its semantics is (informally)
   defined as "the property holds in this state, and all future states".
   Similarly, /eventually/ takes a property, and its semantics is (informally)
   defined as "the property holds in this state, or in some future state".

   Our system should be /eventually consistent/, but just checking if the
   initial term models the property =<> consistent= is not sufficient. This is
   because, initially, all buffers are equal, and so the property holds "in
   this, or some future state". The property =[]<> consistent= will ensure that
   the system will /from every state/ reach a consistent state at some point in
   time.

   The vast majority of the experiments we have conducted has been on the form:
   #+BEGIN_EXAMPLE
   reduce modelCheck(init B N M, []<> consistent) .
   #+END_EXAMPLE
   where =B=, =N= and =M= determines the buffer, number of clients and number
   of operation. The experiment can reduce to =true=, indicating that the
   system is eventually consistent within the given bounds. If the property
   does not hold, the model checker provides a counter example which shows a
   sequence of states that lead to an inconsistency. Lastly, the computation
   may not terminate within a reasonable amount of time consume or too much
   memory, which leaves us with an inconclusive result.

   Some other experiments have been conducted using the =search= command, which
   preforms a breadth-first search of the state space from an initial state,
   until it matches a given pattern and satisfies an (optional) condition. The
   pattern is just a term with variables, and the condition may refer to these
   variables. This has been chosen in favor of using the LTL model checker
   where the property could easily be expressed as a pattern, and where we knew
   what to look for. Stated differently, we utilized the =search= command like
   one might utilize a debugging tool, trying to narrow down what caused a bug
   detected by the LTL model checker.

** Experiments

   The number of reachable states from an initial state depends on the size of
   the initial buffer, the number of clients and the number of operations. It
   grows exponentially with regards to the number of characters in the buffer;
   allowing insertions makes the buffer grow further, and so, increasing the
   number of operations causes the state space to grow drastically. We do not
   consider our endeavor especially successful with regards to verifying the
   system /effectively/.

   #+NAME: experiments
   #+CAPTION: Model checking has verified eventual consistency with the following bounds.
   | Initial buffer size | Clients | Operations | CPU time                      |
   |---------------------+---------+------------+-------------------------------|
   |                   0 |       2 |          3 | 0.3 seconds                   |
   |                   1 |       2 |          3 | 2.4 seconds                   |
   |                   1 |       3 |          3 | 22.8 seconds                  |
   |                   2 |       3 |          3 | 2 minutes 25 seconds          |
   |                   1 |       4 |          3 | 2 minutes 58 seconds          |
   |                   1 |       2 |          4 | 10 minutes 20 seconds         |
   |                   3 |       3 |          3 | 12 minutes 7 seconds          |
   |                   3 |       4 |          3 | 3 hours 8 minutes 18 seconds  |
   |                   2 |       2 |          4 | 3 hours 41 minutes 25 seconds |

   The experiments from Table [[experiments]], have been run on [[http://www.uio.no/english/services/it/research/hpc/abel/][The Abel computer
   cluster]], allowing us to run multiple experiments simultaneously. The
   computations are memory intensive jobs, which is why we decided on getting
   access to the cluster. Note that Maude is single threaded, so we were not
   able to leverage the many cores available in the cluster for single
   computations.

   We have naturally tried to increase the bounds found in Table [[experiments]],
   but the experiments have not terminated within a week of computation, or
   exceeded the $16\text{GB}$ memory limit. Though a non-terminating
   computation does not prove anything, but it means that no counterexample was
   found within reasonable time.

   Lastly, we want to emphasize that we consider the experiments that produced
   counter examples, which are in a vast majority, to have been of great value
   to the development of the algorithm. Sadly, we cannot document these to the
   same degree as the ones that did not produce a counter example. This is
   because that, for a long time, the specification was under rapid
   development, and counter examples were produced within a short amount of
   time on a local computer. It was first when the specification started
   showing real promise that we needed to access more computing power in order
   to produce counter examples. We have been able to correct all errors that
   have been found by the model checker, and have not been able to produce
   further counter examples.

** Processing Counter Examples

   Model checking provides a counter example if the system does not conform to
   a given property; these counter examples have been extremely valuable for
   understanding what caused some particular problem. A counter example is
   represented as a sequence of states, starting from a given initial state and
   ending in some inconsistent state.

   By default, all Maude terms are separated by a single space, which for large
   terms quickly becomes difficult to read. The user can specify a format,
   which can greatly improve the readability of terms. The initial state showed
   in Section [[Model Checking in Maude]] exemplifies how we have chosen to
   represent a state in the system. In the representation of a state, all lines
   contain some piece of information we were interested in.

   The counter examples provided by the model checker typically span hundreds
   of lines, which makes them difficult to process. It is very useful to only
   look at /changes/ between two given states.

   Because each line in a state represents some specific part of the system, a
   simple program has been written to extract the difference between
   consecutive states. We found this program immensely useful, as it generally
   reduces the size of the output by a factor between 2 and 3, and contained
   much less visual noise.

   Our experience is that spending some time optimizing the visual
   representation of the output from the model checker greatly improves its
   usefulness, from a purely practical point of view.

[fn:5] For a good introduction to model checking, see
cite:Clarke:2000:MC:332656.

* Implementation of Shared Buffer

  Shared Buffer has been implemented by first writing a formal specification,
  and then writing a program that conforms to that specification. Care has been
  taken to write the specification in a way that eases the process of
  translating the specification to a programming language. This has mainly been
  done through minimizing the use of features specific to Maude, and specifying
  the algorithm at a fairly low level of abstraction. The act of implementing
  the system can be viewed as a test to see how well we have achieved this.

  We provide a prototype implementation of a real-time collaborative system,
  where the server is written in Clojure and a client is developed as an
  extension for the text editor Emacs. The full source code of the Emacs
  extension is found in Appendix [[Shared Buffer for Emacs --- Source Code]]. As
  for the server source code, the core is found in Appendix [[Shared Buffer
  Server --- Source Code]], but not the complete implementation. The parts that
  are direct translations of functions covered thoroughly in Chapter
  [[Server-side Specification]] are not included, as well as some utility
  functions.

  Note that the implementation is in a prototype stage, where some control
  mechanisms covered in Chapter [[Server-side Specification]] have not yet been
  implemented. This is due to time limitations, as there has been made changes
  to the specification close to the submission of the thesis.

  This chapter attempts to bridge the gap between the specification and the
  implementation, and present solutions to problems that are not present in the
  abstract model of the system.

** Editing Sessions

   The server can handle multiple independent editing sessions, all of which
   are identified by a key. A client can either join a session by providing a
   key, or the server will create a new session with a random generated key. If
   the client specifies a key which is not associated with any existing editing
   session, a new session is created which is identified by the specified key.
   The editing session exists as long as there are connected clients associated
   with the session.

   For a client to join an editing session it must first establish a connection
   to the server. After a connection is established, the client sends a
   =connect-request= message, optionally specifying a session key. The client
   may not perform any operations until it receives the first message from the
   server. If no session key was provided, or the session did not already
   exist, then this is a =connect-response= message, containing a random
   generated session key. If the client joins an ongoing session, it receives
   one or more operations which will make it consistent with the other clients.
   After the first message is received, the client is considered initialized,
   and it may start to perform operations.

   Because the server does not keep a copy of the buffer, the buffer must be
   fetched from an initialized client. This means that a client needs to be
   able to send its entire buffer on the server's request. Conflicts can arise
   during this process, which is discussed in Section [[Conflicts During Client
   Initialization]]. This is a design choice made in order to lower the memory
   consumption on the server. If we would later regret this decision, it would
   not be difficult to implement a "silent client" on the server (i.e. one that
   receives, but never generates operations), and always fetch the buffer from
   this particular client.

   The server can handle changes in multiple editing sessions concurrently,
   because they are completely independent. Changes in the /same/ editing
   session must be handled completely synchronously on the server.

** Wire Protocol

   Communication between a client and the server is done through WebSockets,
   which is a two-way communication protocol based on TCP cite:rfc6455. It is
   chosen in order to achieve interoperability with modern browsers, as well as
   many programming languages. As WebSockets are TCP-based, it guarantees that
   data is not damaged, delivered in order and without duplication cite:rfc793.

   Messages are sent using the JSON object encoding format cite:RFC7159 as
   UTF-8-encoded strings. A JSON object is a collection of key/value pairs,
   where a key is a string, and a value can be a string, a number, a JSON
   object, an array, =true=, =false= or =null=.

   Every message between clients and the server has a key =type=; its
   associated value determines the type of the message. A message may have
   several additional keys, depending on the message type. We first describe
   what each message of a given message type contains; this is specified in
   Tables [[msg-connect-request]] -- [[msg-buffer-resp]]. Some of the message types
   refers to an operation (of type object), which is specified in Table
   [[op-spec]].

   #+ATTR_LATEX: :placement [H]
   #+NAME: msg-connect-request
   #+CAPTION: Specification for messages of type =connect-request=.
   | Key       | Type   | Description                               |
   |-----------+--------+-------------------------------------------|
   | =session= | string | A string identifying a session (optional) |

   #+ATTR_LATEX: :placement [H]
   #+NAME: msg-connect-response
   #+CAPTION: Specification for messages of type =connect-response=.
   | Key       | Type   | Description                    |
   |-----------+--------+--------------------------------|
   | =session= | string | A string identifying a session |

   #+ATTR_LATEX: :placement [H]
   #+NAME: msg-operation
   #+CAPTION: Specification for messages of type =operation=.
   | Key         | Type   | Value description              |
   |-------------+--------+--------------------------------|
   | =operation= | object | An operation                   |
   | =session=   | string | A string identifying a session |
   | =seqno=     | number | The sequence number            |
   | =token=     | number | The state token number         |

   #+ATTR_LATEX: :placement [H]
   #+NAME: msg-operations
   #+CAPTION: Specification for messages of type =operations=.
   | Key          | Type   | Value description              |
   |--------------+--------+--------------------------------|
   | =operations= | array  | An array of operations         |
   | =session=    | string | A string identifying a session |
   | =seqno=      | number | The sequence number            |
   | =token=      | number | The state token number         |

   #+ATTR_LATEX: :placement [H]
   #+NAME: msg-buffer-req
   #+CAPTION: Specification for messages of type =buffer-request=.
   | Key          | Type   | Value description              |
   |--------------+--------+--------------------------------|
   | =session=    | string | A string identifying a session |

   #+ATTR_LATEX: :placement [H]
   #+NAME: msg-buffer-resp
   #+CAPTION: Specification for messages of type =buffer-response=.
   | Key         | Type   | Value description              |
   |-------------+--------+--------------------------------|
   | =operation= | object | An operation                   |
   | =session=   | string | A string identifying a session |
   | =token=     | number | The state token number         |

   #+ATTR_LATEX: :placement [H]
   #+NAME: op-spec
   #+CAPTION: Specification of operation objects.
   | Key   | Type   | Description                                  |
   |-------+--------+----------------------------------------------|
   | =ins= | string | The inserted string, present if =del= is not |
   | =del= | string | The deleted string, present if =ins= is not  |
   | =pos= | number | The position of the operation                |

   The diagram in Figure [[fig:client-message-flow]] describes the flow of messages
   from a client's perspective. It captures how a client must send a
   =connect-request= to get out of an uninitialized state, and must wait until
   it receives a message from the server, before it is ready to generate and
   receive operations. States that are labeled "Process", are there to show how
   most events (like a user typing or a message is received) require some sort
   of reaction, and that this must be completed before the client is free to
   continue typing or receiving messages.

   #+BEGIN_SRC dot :file client.eps :cmdline -Teps
      digraph finite_state_machine {
              node [shape = ellipse, fixedsize=true, width=1.2];
              1 [label="Process"];
              2 [label="Process"];
              3 [label="Process"];

              Ready -> 1 [label = "user types", minlen="4.0"];
              1 -> Ready [label = "send(operation)", minlen="4.0"];

              Ready -> 2 [label = "receive(operations)", minlen="4.0"];
              2 -> Ready [label = "apply operations", minlen="4.0"];

              Ready -> 3 [label = "receive(buffer-request)", minlen="2.0"];
              3 -> Ready [label = "  send(buffer-response)", minlen="2.0"];

              Uninitialized -> Wait [ label = "send(connect-request)"];
              Wait -> Ready [ label = "receive(connect-responce)", minlen="2.0"];
              Wait -> Ready [ label = "  receive(operations)", minlen="2.0"];

              {rank=same Wait Uninitialized}
              {rank=same 1 Ready 2}
      }
   #+END_SRC
   #+CAPTION: Client message flow diagram.
   #+LABEL: fig:client-message-flow
   #+RESULTS:
   [[file:client.eps]]

   A similar diagram is provided in Figure [[fig:server-message-flow]] to show how
   different messages trigger different responses from the server.

   #+BEGIN_SRC dot :file server.eps :cmdline -Teps
   digraph finite_state_machine {
           node [shape = ellipse, fixedsize=true, width=1.2];

           1 [label="Process"];
           2 [label="Process"];
           3 [label="Process"];

           Ready -> 1 [label = "  receive(connect-request)"]
           1 -> Ready [label = "send(connect-response)"]
           1 -> Ready [label = " send(buffer-request)"]

           Ready -> 2 [label = "receive(operation)"]
           2 -> Ready [label = "send(operations)"]

           Ready -> 3 [label = "receive(buffer-response)"]
           3 -> Ready [label = "  send(operations)"]
   }
   #+END_SRC
   #+CAPTION: Server message flow diagram.
   #+LABEL: fig:server-message-flow
   #+RESULTS:
   [[file:server.eps]]

** Conflicts During Client Initialization

   In the specification we assumed that the connected clients stayed constant
   throughout an editing session. The system needs to support clients
   connecting during an ongoing editing session, which needs to be handled in
   the implementation. Because the server does not have its own copy of the
   buffer, the buffer must be fetched from a client. This can happen during a
   conflict, which poses a problem.

   #+BEGIN_EXPORT latex
   \begin{figure}[h]
     \centering
     \begin{tikzpicture}[>=stealth, shorten >= 5pt, node distance=4em, scale=1]
       \tikzstyle{vertex} = [circle, scale=0.5]
       \tikzstyle{O_0} = [vertex, fill=black!30!green]
       \tikzstyle{O_1} = [vertex, fill=black!30!blue]
       \tikzstyle{O_2} = [vertex, fill=black!30!red]

       \tikzstyle{to} = [-{Stealth[scale=1.2]}]
       \tikzstyle{toO_0} = [to, color=black!30!green]
       \tikzstyle{toO_1} = [to, color=black!30!blue]
       \tikzstyle{toO_2} = [to, color=black!30!red]

       \tikzstyle{op} = [midway, above=-3pt, sloped, text=black, font=\small]

       %% Server receives operations in this order
       \node (s) at (4, 6) {$S$};
       \coordinate (se) at (4, 0) {};
       \node[O_0, below = 2em of s,] (s1) {};
       \node[O_1, below = 2em of s1,] (s2) {};
       \node[O_2, below = 2em of s2,] (s3) {};
       \node[O_1, below = 3em of s3,] (s4) {};

       %% User 0 generates/receives in this order
       \node (u0) at (10, 6) {$u_0$};
       \node (u0e) at (10, 0) {};
       \node[O_2, below = 2em of u0,] (u01) {};
       \node[O_0, below = 2em of u01,] (u02) {};
       \node[O_1, below = 3em of u02,] (u03) {};
       \node[O_2, below = 2em of u03,] (u04) {};

       %% User 1 generates/receives in this order
       \node (u1) at (7, 6) {$u_1$};
       \node (u1e) at (7, 0) {};
       \node[O_0, below = 1em of u1,] (u10) {};

       %% User 2 generates/receives in this order
       \node (u2) at (0, 6) {$u_{new}$};
       \node (u2e) at (0, 0) {};
       \node[O_1, below = 2em of u2] (u20) {};
       \node[O_1, below = 10em of u20] (u21) {};

       \begin{pgfonlayer}{bg} % select the background layer
         \draw[to, color=black!30] (s) -- (se);
         \draw[to, color=black!30] (u0) -- (u0e);
         \draw[to, color=black!30] (u1) -- (u1e);
         \draw[to, color=black!30] (u2)  -- (u2e);

         % Life of O_0
         \draw[toO_0] (u10) -- (s1) node [op, near end] {$O_0$};
         \draw[toO_0] (s1) -- (u02) node [op, pos=0.6] {$O_0$};

         % Life of O_1
         \draw[toO_1] (u20) -- (s2) node [op] {\texttt{connect-request}};
         \draw[toO_1] (s2) -- (u03) node [op, pos=0.72] {\texttt{buffer-request}};
         \draw[toO_1] (u03) -- (s4) node [op, near end] {$O_a$};
         \draw[toO_1] (u03) -- (s4) node [op, draw=none, near end, below=-2pt] {\texttt{buffer-response}};
         \draw[toO_1] (s4) -- (u21) node [op] {$O_1 \circ O_0 \circ O_1^{-1} \circ O_a$};
         \draw[toO_1] (s4) -- (u21) node [op, draw=none, below=-2pt] {\texttt{operations}};
         \draw [decorate,shorten >=0pt,decoration={brace, amplitude=10pt}] (u21.west) -- (u20.west) node [midway,xshift=-0.8cm] {\footnotesize wait};

         % Life of O_2
         \draw[toO_2] (u01) -- (s3) node [op, pos=0.6] {$O_1$};
         \draw[toO_2] (s3) -- (u04) node [op, pos=0.35] {$O_1 \circ O_0 \circ O_1^{-1}$};
       \end{pgfonlayer}
     \end{tikzpicture}
     \caption{Client initialization.}
     \label{fig:init-conflict}
   \end{figure}
    #+END_EXPORT

    When a client connects to an editing session, it is important that it waits
    until it receives the first message from the server; this is in order to
    avoid conflicts between the uninformed client and the server. This is a
    reasonable restriction because if the client connects to an ongoing editing
    session, we deem it unlikely that the client can provide useful
    contributions to the buffer before having received the buffer. Before the
    server sends this first message to the client, the client is said to be
    /uninitialized/.

    The server arbitrarily chooses an initialized client, and sends it a
    message of type =send-buffer=. On reception, the client immediately
    responds with a message of type =buffer=, containing the =session=, the
    current =token= and an operation $O_a$ which is an insertion at position
    zero with the entire contents of the buffer. It is not, however, guaranteed
    that the buffer is sent from a consistent state.

    Remember from Section [[Constructing Operations]], that the server keeps a list
    of (possibly) rejected operations, each corresponding to a token for every
    client. When the server receives the =buffer= message, containing $O_a$, it
    constructs an operation which contains $O_a$ and the operations needed to
    make the new client consistent with the current state. These operations are
    gathered by calling the $rejected$ function with the list of rejected
    operations associated with the client that sent the =buffer= message, along
    with the token from the message. A function $makeInitialOp$, which is
    similar to $makeResponse$ from Section [[Constructing Operations]], is defined
    as follows:

    #+BEGIN_EXPORT latex
    \[ makeInitialOp(O_a, R, t) = compose(rejected(R, t)) \circ O_a \]
    #+END_EXPORT

    Where $O_a$ is the operation that inserts the entire buffer, $R$ is the
    list of operations (with corresponding tokens), and $t$ is the token from
    the =buffer= message (i.e. the token at the time the =buffer= message was
    sent). A message containing a constructed operation (using $makeInitialOp$)
    is sent along with the server's current token and sequence number 0 to the
    new client, and it is set to initialized. Such a scenario is visualized in
    Figure ref:fig:init-conflict (note that responses to $u_1$ is omitted).

    This solution is present in the prototype implementation.

** Sequence and Token Numbers

   There are two important considerations with regards to the sequence number
   scheme. One is that a sequence number should only be incremented on the
   client side when a sequence number is included in the message, i.e. when it
   generates or receives operations. This means that the sequence should for
   instance /not/ be incremented at the client when it sends a message with
   type =buffer=.

   The other consideration is with regards to that many languages keep an upper
   bound to the size of an integer. A number in JSON can be arbitrarily large,
   so it is feasible to let sequence and token numbers to grow arbitrarily
   large. Clojure supports arbitrarily large integers, so this is a possibility
   on the server side. But because we do not know what languages will implement
   the protocol we cannot assume that this is easily available for all
   implementation languages.

   For instance, Emacs Lisp integers have an upper bound of $2^{29}-1$ (on
   32-bit platforms)cite:gnu-emacs. Assuming that there is only one participant
   who types at 80 words per minute cite:ostrach1997typing (which is higher
   than the average typist) and words are of length six on average, then this
   user could type continuously for over a year before a problem occurs. On a
   64-bit platform, they may type continuously for (roughly) as long as the sun
   has existed. The time it takes will decrease as more users connect to the
   editing session, but it still seems like a low-priority issue, and is
   therefore not solved in the prototype implementation.

   For sequence numbers, the problem could be easily solved by using modulo
   arithmetic and some chosen $n$ (for instance $2^{16}$). The only relation
   used with the sequence number is the equality relation, and so, by always
   applying modulo $n$ after calculating a sequence number then equality is
   ensured, assuming no conflicts are of size $2^{16}-1$ or greater. This would
   have to be done at both the server and the clients.

   The token numbers are compared with the less than relation, which is not
   preserved simply by using modulo arithmetic. In TCP this is solved by using
   the following definition for less than: "If $s$ and $t$ are timestamp
   values, $s < t$ if $0 < (t - s) < 2^{31}$, computed in unsigned 32-bit
   arithmetic"cite:RFC1323. A similar scheme could be included in Shared
   Buffer, but choosing some lower bound in order to support Emacs (and
   potentially other languages). This can be achieved without adding any
   additional complexity on the client side, because the client only sets the
   token it receives from the server.

** Implementing Shared Buffer for Emacs

   A minimal client is written in /Emacs Lisp/, which is a programming language
   embedded in the text editor /Emacs/. Having a Lisp interpreter as a part of
   the running program makes Emacs uniquely extendable, as code can be
   evaluated at run time, changing the behavior of Emacs without needing to
   recompile, or even restart the program. The implementation of Shared Buffer
   is at a very manageable size around 250 lines of Emacs Lisp code (where 100+
   lines are documentation). This section covers the main considerations in
   writing a client for Emacs, and can be seen as an example on how to
   implement the protocol in an existing editor.

   In Emacs, every piece of text is located in a buffer (often associated with
   some file). It is important that Shared Buffer is enabled for a single
   buffer at the time, if not, the changes made in other buffers would be
   communicated to the server, which would quickly break consistency. The idea
   of a buffer-local variable is important, as it allows for a single variable
   to have different values depending of the current buffer.

   Shared Buffer stores its state in four buffer-local variables: A key that
   identifies an editing session, a reference to the socket for communicating
   with the server, a sequence number and a token number. The key is only set
   when starting a new editing session, or if a =connect= message is received
   from the server. The socket is only set when starting a new editing session.
   The sequence and token number is set according to the specification (Section
   [[Client-side Specification]]).

   For communication with the server, two libraries are utilized, namely
   [[https://elpa.gnu.org/packages/websocket.html][WebSockets]] and [[http://git.savannah.gnu.org/cgit/emacs.git/tree/lisp/json.el][JSON]] (which is built in). The WebSockets library provides a
   function for opening a connection to a given host, which can take functions
   as argument which are called on different events on the socket. The JSON
   library provides functions for encoding a native Emacs Lisp data structure
   to a JSON string, and similarly read JSON strings, which returns an Emacs
   Lisp data structure. Together, these libraries provide a very simple
   interface for communicating with the server.

   The main challenge is to detect all changes in the buffer. In Emacs, a
   /hook/ refers to a variable that contains a list of functions that are
   triggered by certain events. Emacs provides two hooks that are called before
   and after every change. A function for sending insertions is added to the
   =after-change-hook= and a function for sending deletions is added to the
   =before-change-hook=. Insertions must be detected /after/ it has been
   performed, in order to retrieve the text that was inserted, and similarly,
   deletions must be detected /before/ the change in order to retrieve the text
   that was deleted.

   The documentation for change hooks clearly state that "These hook variables
   let you arrange to take notice of all changes in all buffers (or in a
   particular buffer, if you make them buffer-local)"cite:stallman2015gnu. This
   is not completely true, due to the existence of a variable
   =inhibit-modification-hooks=. If this variable is set to a true value, then
   the change hooks are not executed, which poses a problem for Shared Buffer
   because /all/ changes must be detected. Some functions that binds this
   variable have caused problems with the current implementation of Shared
   Buffer.

   We contacted the [[http://lists.gnu.org/archive/html/emacs-devel/2016-07/msg00721.html][emacs-devel mailing list]] asking whether this was intended,
   because it breaks the guarantee that the change hooks should provide. Stefan
   Monnier, a seasoned Emacs developer gave the following reply:

   #+BEGIN_QUOTE
   Making "real" modifications to the buffer while binding
   inhibit-modification-hooks to a non-nil value sounds like a bug.
   #+END_QUOTE

   This gives the impression that using these hooks should be a viable option,
   and so we have not made efforts to get around this problem. The variable is
   toggled around 50 times in the Emacs source code, so submitting bug reports
   where the usage causes problems seems like a manageable task. It is worth
   noting that Emacs has a large ecosystem of external packages, and exploring
   all of these seems like a daunting task. It is possible to keep a list of
   functions that are known to set the variable in a way that interferes with
   Shared Buffer, and disable these during a shared editing session --- this is
   assuming that the number functions is reasonably small.

   We have two suggestions to alternative approaches. One is to rely on the
   undo-history that is stored in Emacs, in addition to keeping track of which
   changes have been communicated to the server. Another is to take regular
   "snapshots" of the buffer, and breaking the difference between a snapshot
   and the next into operations, which can then be communicated to the server.
   Bot of these may be viable alternatives for other editors that might not
   provide something similar to change hooks.

   It is worth noting that Emacs runs in a single thread; this excludes many
   edge-cases, like what would happen if a message is received at the same time
   as the user generates an operation. This is something that is worth
   considering if one were to implement the protocol in a multithreaded
   environment.

   A small set of functions are added to create an interface for the user;
   these functions are called /interactive/ functions, which can be added to a
   key binding and called using =M-x=, which is Emacs' interface to all
   interactively callable functions. A function =sb-share-buffer= may be called
   to share the current buffer; a session key is randomly generated by the
   server and sent back in a =connect= message; the session key is added to the
   clipboard. To connect to an editing session, a function =sb-join-session= is
   provided, where the user must provide a session key. A function
   =sb-disconnect= simply disconnects the buffer to the shared editing session
   (but leaving the buffer as it was before disconnecting). Lastly,
   =sb-add-key-to-kill-ring= is a function to add the current session key to
   the clipboard ("kill-ring" is Emacs jargon for the clipboard), making it
   easier to share to others. Note that every function is prefixed with the
   abbreviation =sb=, which is an established code convention in Emacs, due to
   it having a single name space for all global variables and functions.

** Implementing Shared Buffer in Clojure

   The main task of implementing Shared Buffer in Clojure is simply translating
   Maude equations to Clojure functions, most of which have been described in
   Chapter [[Server-side Specification]]. This is mostly a straight forward task,
   due to the both being declarative languages.

   Two libraries are leveraged to ease communication with the clients, namely
   [[http://www.http-kit.org/][HTTP Kit]] and [[https://github.com/clojure/data.json][data.json]]. Together they form a very similar interface to the
   Emacs Lisp equivalents (Section [[Implementing Shared Buffer for Emacs]]). The
   main difference is that messages on a WebSocket is received on a /channel/
   (i.e. a blocking queue), and messages from multiple channels can be
   processed concurrently.

*** State Management

   Clojure separates /identity/ and /state/, where an identity is [[http://clojure.org/about/state]["a stable
   logical entity associated with a series of different values over time"]].
   Though mutating variables directly is possible, it is greatly discouraged.
   There are three encouraged ways of dealing with mutating state which can be
   summarized as cite:Fogus:2011:JCT:2018918:
   - *Refs* --- use for synchronous and coordinated state change,
   - *Atoms* --- use for synchronous and uncoordinated state change,
   - *Agents* --- use for asynchronous and uncoordinated state change.
   Shared Buffer follows a common Clojure idiom, which is to keep the entire
   application state inside a single /atom/. Every change to an atom is
   /atomic/, meaning that it never has an intermediate state; either a change
   has happened or it has not. This generally yields a maintainable code base.
   Changes to atoms are mainly done by applying a function to the current state
   of the atom. It is important that the function is /pure/ (i.e. no side
   effects), because it may be called multiple times.

   The state is a nested map, keeping track of the sessions and the connected
   clients, along with a function for shutting down the server. Changes made to
   the state are limited to functions that /inherently/ has side-effects,
   namely the functions that either sends or receives messages. Note that there
   is a correspondence between when we allow state changes in the system, and
   when we used rewrite rules in Maude. If an error occurs in a purely
   functional program, then a stack trace will give a very precise location of
   where the error occurred; either the function is erroneous or it is called
   with a bad argument; limiting the places state change occurs greatly reduces
   the potential locations of the error.

   To get an idea of how the state is structured, we provide an example of a
   state. The state is a nested map, which maps keys to values, and is
   represented by surrounding the pairs with curly braces ={}=. The keys can be
   any value, but often keywords are preferred; they are symbols prefixed with
   =:=, and can be used as functions that look up values in a map. Lists are
   denoted as parenthesized expressions and sets are denoted with curly braces
   prefixed with a hash tag =#{}=. This is an actual state of the system, but
   some values has been replaced with variables for readability:
   #+BEGIN_SRC clojure
   {:sessions {:key1 {:tokens {c1 4, c2 2},
                      :clients #{c2 c1},
                      :token 5,
                      :lock obj1,
                      :history h}},
    :clients {c1 {:id u1,
                  :seqno 6,
                  :session :key1,
                  :initialized true,
                  :ops r1},
              c2 {:id u2,
                  :seqno 7,
                  :session :key1,
                  :initialized true,
                  :ops r2}},
    :server shut-down-function}
   #+END_SRC
   The changes that happen within a single session mush be handled in a
   coordinated way; it is important a change in a session is based on updated
   information. On every receive, a lock associated with a session is held
   until the change is complete. This allows for independent sessions to be
   handled concurrently, with the small exception of making changes to the
   atom. We have tried to minimize the number of changes done to the atom, but
   think that there is still room for improvement here.

*** Operations

    Maude has great support for defining algebraic data-types, which made
    defining operations very simple. In Clojure, most data is built from the
    language primitives, and is largely based on collections. As we showed in
    Section [[Algebraic Properties]], operations under composition is a /monoid/.
    Basing the representation on a monoidal structure gives a guarantee that
    some key properties are preserved.

    Lists under concatenation is a [[https://en.wikibooks.org/wiki/Haskell/Monoids][monoid]]. This motivates the choice of using
    lists as the underlying representation of operations. A singleton operation
    (i.e. insertion or deletion) is a singleton list, containing a map with the
    keys =:ins= or =:del= (exclusively) and =:pos=. The composition function
    simply calls the concatenation function =concat=.

    The empty list represents a $nop$ element. A map which contains a key
    =:nop= is also treated as the $nop$ element[fn:7]; this is because an
    exclusion transformation can generate a $nop$ element, in which case we
    need to store the excluded operation (as discussed in Section [[Transform the
    History]]). Such an operation will only be stored in an event, and a client
    will never observe its existence, because it will be omitted before the
    operation is sent.

    The following function defines the inverse of an operation (Definition
    ref:def:inverse) in Clojure:
    #+BEGIN_SRC clojure
    (defn inv
      "Returns the inverse of x."
      [x]
      (if (seq? x)
        (map inv (reverse x))
        (rename-keys x {:ins :del, :del :ins})))
    #+END_SRC
    It reverses the list, and replaces all =:ins= with =:del= and vise versa.

    Operations constructed by the Clojure-equivalents of $makeOp$ and
    $makeResponse$ can often be simplified by removing adjacent pairs of
    operations that are inverses of each other. In Maude this is easily
    achievable by stating an equation. This has to be done explicitly in
    Clojure.

    The following Clojure function simplifies a given operation in linear
    time[fn:6]. It looks at one element of the list (i.e. a map which
    represents a deletion or insertion) at the time and adds it to the stack
    /unless/ it is a $nop$ element or the inverse of the top of the stack; in
    that case, both the top of the stack and the element will be omitted. It
    can be seen as a special case of [[https://en.wikipedia.org/wiki/Peephole_optimization][peephole optimiaztion]].

    #+BEGIN_SRC clojure
    (defn simplify [op]
      "Reduces op it to a minimal form. It removes nop elements and adjacent
      operations that are inverses of each other."
      (-> (fn [stack o]
            (cond (nop? o) stack
                  (empty? stack) (conj stack o)
                  (inverses? (peek stack) o) (pop stack)
                  :else (conj stack o)))
          (reduce [] op) seq))
    #+END_SRC

    The operations that are sent to the clients are always simplified before
    they are sent. The list is reversed and before sending it to a client. This
    is because it is more natural to traverse a list (or array) form left to
    right at the client, applying operations while traversing. Lastly, the list
    of maps is converted to an array of JSON objects.

** Remaining Work

   The implementation is in an prototype stage. Most importantly, not all
   control mechanisms from Chapter [[Server-side Specification]] has yet been
   implemented. As translating the Maude specification has been quite straight
   forward, we do not foresee any particularly challenging problems with
   completing this, and is why we have prioritized a correct specification
   before a correct implementation.

   By analyzing the specification, and removing the control mechanisms that are
   not yet implemented, then we can give some estimate at how well the
   implementation performs, with regards to consistency. Given two clients and
   three operations working on a buffer of initial size two, then eventual
   consistency is breached in roughly two percent of the states. This is
   assuming that all states are equally likely to be reached. We would argue
   that these situations are even less likely to occur in reality, because it
   would require users to simultaneously perform operations on the same
   position of the buffer.

   There are also a lot of features that would be natural to add to a real-time
   collaborative editor that have not been discussed. For instance, it could be
   very useful to display the cursor of other participants; in addition,
   displaying highlighted regions simplifies communication about the buffer.
   Yet, we want to keep the system minimalistic and not include features that
   could be better solved with a separate tool; an example would be a chat
   feature. Features of this kind is discussed, as they are of little (or no)
   relevance to the main problem, namely ensuring eventual consistency.

*** String-wise Operations

   The protocol allows for inserting and deleting /strings/, yet the
   specification only deals with single characters. We suggest a way of dealing
   with this, which allows us to remain faithful to the specification, in the
   sense that the history will consist of events where each operation contains
   a single character.

   Given an event $\tuple{O, t, m, u} \in \mathbb E$ where $O$ is an operation
   containing a string, rather than a character, we can split the event into
   one event per character. If we assume $i$ is a position, =c= is a character
   and =s= is a string, and let =c s= be a string with =c= as the first
   character, then the idea can be expressed with this equation:
   #+BEGIN_EXPORT latex
   \begin{alignat*}{2}
     &split(\tuple{\ins{i}{c}, t, m, u})    &&= \tuple{\ins{i}{c}, t, m, u}\\
     &split(\tuple{\ins{i}{c\ s}, t, m, u}) &&= \tuple{\ins{i}{c}, t, m, u}\ split(\tuple{\ins{i+1}{s}, t, m, u})\\\\
     &split(\tuple{\del{i}{c}, t, m, u})    &&= \tuple{\del{i}{c}, t, m, u}\\
     &split(\tuple{\del{i}{c\ s}, t, m, u}) &&= \tuple{\del{i}{c}, t, m, u}\ split(\tuple{\del{i}{s}, t, m, u})
   \end{alignat*}
   #+END_EXPORT
   The list of events can be treated one by one, emulating that the client has
   performed the operations in a character-wise fashion. In the specification we
   made sure that $m$ is always unique, but this is in order to always have a
   tie breaker and decide whether an event happened before (Definition
   ref:def:happened-before) another. This is not necessary when all the events
   are performed by the user, because an event by a user can never precede an
   event (that is already present in the history) performed by the same user.

   We implemented this as a proof of concept. Though we are very confident that
   it preserves eventual consistency, it greatly degraded the performance of
   the system, to such a degree that we don't consider it a satisfactory
   solution. It might be possible to optimize this, but instead we want to rely
   on existing solutions to the problem.

   In cite:DBLP:journals/tochi/SunJZYC98 Sun et al. introduced both exclusion
   and inclusion transformation functions for strings. This is a much more
   performant solution which should be preferred in the implementation. Most
   Operational Transformation algorithms work independently from the data that
   is transformed, as long as they satisfies the properties ref:eqn:C1 and
   ref:eqn:C2 (which were introduced in Section [[Discussing Consistency in
   Operational Transformation]]). We see no reason this should not be true for
   Shared Buffer as well. Even though ref:eqn:C2 has been shown not to hold for
   the transformation function of Sun et al., but this only effects fully
   distributed solutions, and should therefore not be a problem for Shared
   Buffer.

*** Agents in Favor of an Atom

    In Section [[State Management]] we described how the state of the program is
    contained in a single atom. An alternative structure, which would relieve
    the need of a lock, is using one agent per session. Every agent keeps a
    queue of functions that will eventually be applied to its current state.
    A problem with this approach is that these agents would need to be placed
    in some piece of mutable state. Generally, reference types (i.e. refs,
    atoms and agents) do not nest well, as computations might be run multiple
    times. Having not been able to find a safe solution to this, we have
    decided to stay with the single atom solution.

*** Acknowledgement Messages

    No acknowledgement messages are needed in Shared Buffer to ensure
    consistency. Yet, without acknowledgement messages, both the history and
    list of rejected messages can continue to grow indefinitely. If all clients
    have successfully received a token $n$ or higher, then they have all
    executed the operations with arrival time $n$ or smaller. This means they
    cannot operate independently from any of these operations, and so, no new
    event will be concurrent with an arrival time smaller than $n$. This allows
    us to safely remove these entries from the history.

    If one client stays silent during a session, there is no way for the server
    to safely remove entries from the history. If we were to introduce regular
    acknowledgement messages from the clients, this would yield substantially
    better performance at the server, as there are multiple linear time
    functions applied to the history every time a message is received.

    As of now, the history is trimmed on the server, but no acknowledgement
    messages are sent. Every message received from a client is an implicit
    acknowledgement, which yields good performance if all the clients are
    active. Some consideration should go into the frequency of the
    acknowledgement messages. A suggestion would be to send an acknowledgement
    when the token number has been raised $n$ times, while the client has
    stayed silent. The $n$ should be chosen on the basis of how much overhead
    sending acknowledgement messages causes, and how large the $n$ needs to be
    before performance on the server is noticeably degraded.

[fn:6] This solution was found after noticing that the problem is almost
identical to a programming challenge we happened to have solved. The exercise
can be found here: https://open.kattis.com/problems/evenup.
[fn:7] Note that a solution where a map containing =:nop= would serve as the
sole identity element would work just as well; however it seemed redundant to
add such an element only to later remove it in the simplification step. This is
why the empty list is treated as an "alternative" identity element.
*** Undo

    The adOPTed-algorithm cite:DBLP:conf/cscw/ResselNG96 tackles the problem of
    undo in a real-time collaborative editor; their idea is to only undo
    operations that are generated locally. The Shared Buffer system does not
    provide any special mechanisms for undo, but specific client
    implementations may provide solutions to this problem; the only requirement
    is that all changes (including undos) are reported to the server.

    This problem would be best handled on the client side, as undo is a
    editor-specific feature. If we were to handle this on the server side, a
    message would need to include information revealing that an operation was
    caused by an undo. Then the server could only add undone operations which
    was originally performed by the same user, and ensure that operations
    generated by other users would be restored. Though it might provide a
    correct end result, it would be a confusing experience for the user, as it
    would need to perform global undos, and trust that remote operations would
    be restored.

    As of now, the Emacs client ignores this problem, which only allows for
    global undo (i.e. undoing both local and remote operations). In Emacs, a
    user can mark a region, and only undo in this region. This means that a
    user can solve this problem manually by marking region they want to undo.
    However, it would be preferable to do this automatically.

    We are not sure if this is achievable without altering the existing undo
    functions in Emacs. Because Emacs supports undoing within a region, there
    must also exist mechanisms for undoing a change which is not the /latest/
    change; it seems plausible to use these mechanisms to "skip" undo entries
    that were generated remotely and achieve a good local undo.

    #+LaTeX:\appendix

* Shared Buffer for Emacs --- Source Code
  #+INCLUDE: ../shared-buffer-clients/shared-buffer-emacs/shared-buffer.el src emacs-lisp
* Shared Buffer Server --- Source Code
  #+INCLUDE: ../shared-buffer-server/src/shared_buffer_server/core.clj src clojure
* Maude Specification --- Source Code
  #+INCLUDE: ../model/shared-buffer-inverse.maude src haskell
  #+LaTeX:\backmatter{}
  #+LaTeX:\printbibliography



* COMMENT Local variables
  # Local Variables:
  # company-mode : nil
  # eval: (make-local-variable 'org-latex-default-packages-alist)
  # eval: (delete '("" "hyperref" nil) org-latex-default-packages-alist)
  # eval: (require 'org-ref)
  # eval: (require 'ob-dot)
  # org-ref-pdf-directory: "~/Dropbox/ifi/master/articles/"
  # dabbrev-check-all-buffers: nil
  # eval: (server-start)
  # eval: (add-hook 'after-save-hook 'org-latex-export-to-latex nil t)
  # eval: (compile "latexmk -pdf -pvc -pdflatex='pdflatex -shell-escape -interaction nonstopmode'")
  # End:
